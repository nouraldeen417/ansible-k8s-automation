2025-05-27 20:27:56,037 p=8527 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-27 20:27:56,463 p=8527 u=root n=ansible INFO| PLAY [Initial server setup for Ansible] ****************************************************************************************************
2025-05-27 20:27:56,491 p=8527 u=root n=ansible INFO| TASK [Example from an Ansible Playbook] ****************************************************************************************************
2025-05-27 20:27:59,812 p=8527 u=root n=ansible INFO| fatal: [worker-01]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 192.168.1.17 port 22: No route to host", "unreachable": true}
2025-05-27 20:28:00,329 p=8527 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 20:28:00,331 p=8527 u=root n=ansible INFO| ok: [master-01]
2025-05-27 20:28:00,333 p=8527 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 20:28:00,334 p=8527 u=root n=ansible INFO| ok: [master-02]
2025-05-27 20:28:00,338 p=8527 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-27 20:28:00,339 p=8527 u=root n=ansible INFO| master-01                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-27 20:28:00,340 p=8527 u=root n=ansible INFO| master-02                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-27 20:28:00,341 p=8527 u=root n=ansible INFO| worker-01                  : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-27 21:15:28,147 p=8860 u=root n=ansible INFO| - Role Build_cluster was created successfully
2025-05-27 21:15:58,525 p=8936 u=root n=ansible INFO| - Role roles/Build_cluster was created successfully
2025-05-27 21:39:26,062 p=9066 u=root n=ansible INFO| - Role roles/swap_manage was created successfully
2025-05-27 21:39:44,737 p=9105 u=root n=ansible INFO| - Role roles/containerd was created successfully
2025-05-27 21:40:40,538 p=9234 u=root n=ansible INFO| - Role roles/k8s_packages was created successfully
2025-05-27 21:40:56,071 p=9273 u=root n=ansible INFO| - Role roles/cluster_init was created successfully
2025-05-27 22:23:50,024 p=10476 u=root n=ansible INFO| - Role roles/common was created successfully
2025-05-27 22:25:04,913 p=10576 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-27 22:25:05,116 p=10576 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-27 22:25:05,172 p=10576 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-27 22:25:13,481 p=10576 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 22:25:13,482 p=10576 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:25:13,492 p=10576 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-27 22:25:14,004 p=10576 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:25:14,041 p=10576 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-27 22:25:14,829 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:25:14,843 p=10576 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-27 22:25:17,606 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:25:17,621 p=10576 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-27 22:25:45,815 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:25:45,827 p=10576 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-27 22:26:14,032 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:26:14,044 p=10576 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-27 22:26:15,169 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:26:15,201 p=10576 u=root n=ansible INFO| TASK [containerd : Restart service containerd, in all cases] *******************************************************************************
2025-05-27 22:26:16,199 p=10576 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:26:16,223 p=10576 u=root n=ansible INFO| TASK [swap_manage : disable swap permanently] **********************************************************************************************
2025-05-27 22:26:16,799 p=10576 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:26:16,813 p=10576 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-27 22:26:16,813 p=10576 u=root n=ansible INFO| master-01                  : ok=9    changed=6    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-27 22:31:58,452 p=10846 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-27 22:31:58,570 p=10846 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-27 22:31:58,581 p=10846 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-27 22:32:02,509 p=10846 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 22:32:02,509 p=10846 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:32:02,521 p=10846 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-27 22:32:02,960 p=10846 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:32:02,983 p=10846 u=root n=ansible INFO| TASK [swap_manage : disable swap permanently] **********************************************************************************************
2025-05-27 22:32:03,415 p=10846 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "missing required arguments: path"}
2025-05-27 22:32:03,416 p=10846 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-27 22:32:03,416 p=10846 u=root n=ansible INFO| master-01                  : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-27 22:46:11,253 p=11056 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-27 22:46:11,392 p=11056 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-27 22:46:11,419 p=11056 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-27 22:46:14,738 p=11056 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 22:46:14,738 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:14,750 p=11056 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-27 22:46:15,199 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:15,225 p=11056 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-27 22:46:15,723 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:15,735 p=11056 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-27 22:46:16,598 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:16,611 p=11056 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-27 22:46:17,266 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:17,278 p=11056 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-27 22:46:18,708 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:18,720 p=11056 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-27 22:46:19,585 p=11056 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:46:19,597 p=11056 u=root n=ansible INFO| TASK [containerd : Restart service containerd, in all cases] *******************************************************************************
2025-05-27 22:46:20,532 p=11056 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:46:20,589 p=11056 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-27 22:46:21,067 p=11056 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:46:21,078 p=11056 u=root n=ansible INFO| TASK [swap_manage : Remove swap from fstab] ************************************************************************************************
2025-05-27 22:46:21,527 p=11056 u=root n=ansible INFO| ok: [master-01] => (item=swap)
2025-05-27 22:46:21,842 p=11056 u=root n=ansible INFO| ok: [master-01] => (item=/swap.img)
2025-05-27 22:46:22,164 p=11056 u=root n=ansible INFO| ok: [master-01] => (item=/swapfile)
2025-05-27 22:46:22,177 p=11056 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-27 22:46:22,177 p=11056 u=root n=ansible INFO| master-01                  : ok=10   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-27 22:51:07,980 p=11256 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-27 22:51:08,106 p=11256 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-27 22:51:08,132 p=11256 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-27 22:51:10,884 p=11256 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-27 22:51:10,885 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:10,896 p=11256 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-27 22:51:11,340 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:11,363 p=11256 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-27 22:51:11,817 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:11,831 p=11256 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-27 22:51:12,719 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:12,731 p=11256 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-27 22:51:13,426 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:13,438 p=11256 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-27 22:51:14,934 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:14,949 p=11256 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-27 22:51:15,934 p=11256 u=root n=ansible INFO| ok: [master-01]
2025-05-27 22:51:15,947 p=11256 u=root n=ansible INFO| TASK [containerd : Restart service containerd, in all cases] *******************************************************************************
2025-05-27 22:51:16,924 p=11256 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:51:16,946 p=11256 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-27 22:51:17,381 p=11256 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:51:17,392 p=11256 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-27 22:51:17,865 p=11256 u=root n=ansible INFO| changed: [master-01]
2025-05-27 22:51:17,877 p=11256 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-27 22:51:17,877 p=11256 u=root n=ansible INFO| master-01                  : ok=10   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 00:22:06,928 p=11545 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 00:22:07,424 p=11545 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 00:22:07,468 p=11545 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 00:22:13,955 p=11545 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 00:22:13,955 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:13,983 p=11545 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 00:22:15,123 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:15,188 p=11545 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 00:22:16,449 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:16,496 p=11545 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 00:22:19,235 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:19,295 p=11545 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 00:22:21,034 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:21,138 p=11545 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 00:22:23,469 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:23,530 p=11545 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 00:22:25,257 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:25,308 p=11545 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 00:22:26,161 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:26,183 p=11545 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 00:22:26,939 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:27,046 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 00:22:28,004 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:22:28,040 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 00:22:30,543 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:30,630 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 00:22:31,693 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:31,736 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 00:22:32,600 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:32,665 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 00:22:34,064 p=11545 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:22:34,086 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 00:23:15,071 p=11545 u=root n=ansible INFO| changed: [master-01] => (item=kubectl)
2025-05-28 00:24:00,300 p=11545 u=root n=ansible INFO| changed: [master-01] => (item=kubelet)
2025-05-28 00:24:38,014 p=11545 u=root n=ansible INFO| changed: [master-01] => (item=kubeadm)
2025-05-28 00:24:38,054 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 00:24:39,692 p=11545 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:24:39,751 p=11545 u=root n=ansible INFO| TASK [k8s_packages : Start service httpd, if not started] **********************************************************************************
2025-05-28 00:24:42,022 p=11545 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not find the requested service httpd: host"}
2025-05-28 00:24:42,029 p=11545 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 00:24:42,032 p=11545 u=root n=ansible INFO| master-01                  : ok=16   changed=7    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 00:30:18,237 p=11948 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 00:30:18,512 p=11948 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 00:30:18,537 p=11948 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 00:30:27,043 p=11948 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 00:30:27,044 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:27,062 p=11948 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 00:30:28,188 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:28,252 p=11948 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 00:30:29,616 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:29,680 p=11948 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 00:30:33,176 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:33,249 p=11948 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 00:30:34,795 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:34,825 p=11948 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 00:30:38,141 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:38,174 p=11948 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 00:30:39,884 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:39,987 p=11948 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 00:30:41,297 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:30:41,368 p=11948 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 00:30:42,311 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:30:42,347 p=11948 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 00:30:43,579 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:30:43,638 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 00:30:44,449 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:44,492 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 00:30:46,594 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:30:46,646 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 00:30:47,528 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:47,586 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 00:30:48,519 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:30:48,556 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 00:30:49,891 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:30:49,933 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 00:31:04,153 p=11948 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 00:31:09,339 p=11948 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 00:31:16,477 p=11948 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 00:31:16,528 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 00:31:17,458 p=11948 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:31:17,517 p=11948 u=root n=ansible INFO| TASK [k8s_packages : Start service httpd, if not started] **********************************************************************************
2025-05-28 00:31:18,971 p=11948 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:31:19,007 p=11948 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 00:31:23,897 p=11948 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "init", "--apiserver-advertise-address=192.168.57.3", "--upload-certs"], "delta": "0:00:02.535133", "end": "2025-05-27 22:08:46.044994", "msg": "non-zero return code", "rc": 1, "start": "2025-05-27 22:08:43.509861", "stderr": "I0527 22:08:44.708648    9090 version.go:261] remote version is much newer: v1.33.1; falling back to: stable-1.32\nerror execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR Port-10250]: Port 10250 is in use\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["I0527 22:08:44.708648    9090 version.go:261] remote version is much newer: v1.33.1; falling back to: stable-1.32", "error execution phase preflight: [preflight] Some fatal errors occurred:", "\t[ERROR Port-10250]: Port 10250 is in use", "[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[init] Using Kubernetes version: v1.32.5\n[preflight] Running pre-flight checks", "stdout_lines": ["[init] Using Kubernetes version: v1.32.5", "[preflight] Running pre-flight checks"]}
2025-05-28 00:31:23,905 p=11948 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 00:31:23,906 p=11948 u=root n=ansible INFO| master-01                  : ok=18   changed=6    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 00:39:46,971 p=12380 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 00:39:47,201 p=12380 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 00:39:47,223 p=12380 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 00:39:54,040 p=12380 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 00:39:54,041 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:39:54,074 p=12380 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 00:39:55,554 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:39:55,685 p=12380 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 00:39:56,960 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:39:57,043 p=12380 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 00:39:59,272 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:39:59,303 p=12380 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 00:40:00,654 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:00,705 p=12380 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 00:40:04,744 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:04,785 p=12380 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 00:40:07,468 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:07,531 p=12380 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 00:40:08,703 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:08,719 p=12380 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 00:40:09,359 p=12380 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:40:09,387 p=12380 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 00:40:10,235 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:10,277 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 00:40:11,220 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:11,246 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 00:40:13,169 p=12380 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:40:13,237 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 00:40:14,237 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:14,292 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 00:40:15,507 p=12380 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:40:15,573 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 00:40:17,776 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:17,852 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 00:40:27,672 p=12380 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 00:40:35,399 p=12380 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 00:40:42,479 p=12380 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 00:40:42,528 p=12380 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 00:40:44,057 p=12380 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:40:44,116 p=12380 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 00:43:50,764 p=12380 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:43:50,788 p=12380 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 00:43:53,648 p=12380 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:43:53,679 p=12380 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 00:43:53,859 p=12380 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-05-28 00:43:53,860 p=12380 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not find or access '/etc/kubernetes/admin.conf' on the Ansible Controller.\nIf you are using a module and expect the file to exist on the remote, see the remote_src option"}
2025-05-28 00:43:53,864 p=12380 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 00:43:53,864 p=12380 u=root n=ansible INFO| master-01                  : ok=19   changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 00:52:13,083 p=12864 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 00:52:13,723 p=12864 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 00:52:13,769 p=12864 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 00:52:22,628 p=12864 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 00:52:22,630 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:22,698 p=12864 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 00:52:24,149 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:24,221 p=12864 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 00:52:25,796 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:25,837 p=12864 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 00:52:29,273 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:29,356 p=12864 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 00:52:31,939 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:31,979 p=12864 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 00:52:36,467 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:36,507 p=12864 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 00:52:38,950 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:38,999 p=12864 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 00:52:40,190 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:40,222 p=12864 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 00:52:41,477 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:41,544 p=12864 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 00:52:43,210 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:43,292 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 00:52:44,455 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:44,520 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 00:52:47,134 p=12864 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:52:47,166 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 00:52:47,900 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:47,960 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 00:52:48,536 p=12864 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:52:48,589 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 00:52:49,953 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:52:49,969 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 00:52:58,207 p=12864 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 00:53:03,400 p=12864 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 00:53:08,789 p=12864 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 00:53:08,812 p=12864 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 00:53:09,808 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:53:09,920 p=12864 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 00:53:10,513 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:53:10,540 p=12864 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 00:53:11,220 p=12864 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:53:11,243 p=12864 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 00:53:12,217 p=12864 u=root n=ansible INFO| changed: [master-01]
2025-05-28 00:53:12,279 p=12864 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 00:53:12,281 p=12864 u=root n=ansible INFO| master-01                  : ok=20   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 00:59:36,335 p=13290 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 00:59:36,859 p=13290 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 00:59:36,907 p=13290 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 00:59:43,893 p=13290 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 00:59:43,893 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:43,925 p=13290 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 00:59:45,361 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:45,451 p=13290 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 00:59:47,030 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:47,107 p=13290 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 00:59:49,542 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:49,585 p=13290 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 00:59:50,903 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:50,965 p=13290 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 00:59:53,685 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:53,728 p=13290 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 00:59:56,404 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:56,475 p=13290 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 00:59:57,909 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:57,969 p=13290 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 00:59:58,774 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 00:59:58,807 p=13290 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 00:59:59,939 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:00,005 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:00:00,750 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:00,820 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:00:03,027 p=13290 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:00:03,065 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 01:00:03,896 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:03,946 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 01:00:05,404 p=13290 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:00:05,445 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 01:00:07,532 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:07,601 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 01:00:14,669 p=13290 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 01:00:22,330 p=13290 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 01:00:30,867 p=13290 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 01:00:30,904 p=13290 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 01:00:31,919 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:32,033 p=13290 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:00:32,792 p=13290 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:00:32,809 p=13290 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:00:33,458 p=13290 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:00:33,477 p=13290 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:00:34,314 p=13290 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:00:34,339 p=13290 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:00:34,340 p=13290 u=root n=ansible INFO| master-01                  : ok=20   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 01:19:06,670 p=13818 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:19:07,274 p=13818 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:19:07,334 p=13818 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:19:13,603 p=13818 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:19:13,604 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:17,492 p=13818 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:19:17,492 p=13818 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:19:17,526 p=13818 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:19:18,681 p=13818 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:19:18,689 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:18,758 p=13818 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:19:19,684 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:19,716 p=13818 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:19:19,731 p=13818 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:19:20,438 p=13818 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "file (/home/ansible-admin/ansible_swap_OFF) is absent, cannot continue", "path": "/home/ansible-admin/ansible_swap_OFF", "state": "absent"}
2025-05-28 01:19:20,485 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:20,507 p=13818 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:19:21,360 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:21,403 p=13818 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:19:22,328 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:22,350 p=13818 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:19:25,097 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:25,133 p=13818 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:19:27,007 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:27,024 p=13818 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:19:31,140 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:31,181 p=13818 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:19:33,810 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:33,876 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:19:34,655 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:34,705 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:19:37,334 p=13818 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:19:37,407 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 01:19:38,118 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:38,138 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 01:19:38,950 p=13818 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:19:38,988 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 01:19:40,952 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:19:40,997 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 01:19:48,809 p=13818 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 01:20:18,588 p=13818 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 01:20:28,219 p=13818 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 01:20:28,265 p=13818 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 01:20:29,286 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:20:29,385 p=13818 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:20:30,191 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:20:30,224 p=13818 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:20:30,942 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:20:30,967 p=13818 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:20:31,942 p=13818 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:20:31,984 p=13818 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:20:33,051 p=13818 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:20:33,087 p=13818 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:20:33,132 p=13818 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:20:33,169 p=13818 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:20:33,169 p=13818 u=root n=ansible INFO| master-01                  : ok=21   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:20:33,170 p=13818 u=root n=ansible INFO| worker-01                  : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 01:22:00,490 p=14358 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:22:00,725 p=14358 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:22:00,748 p=14358 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:22:06,983 p=14358 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:22:06,985 p=14358 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:22:07,639 p=14358 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:22:07,639 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:07,671 p=14358 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:22:08,352 p=14358 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:22:08,376 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:08,422 p=14358 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:22:09,163 p=14358 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:22:09,167 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:09,184 p=14358 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:22:09,871 p=14358 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "file (/home/ansible-admin/ansible_swap_OFF) is absent, cannot continue", "path": "/home/ansible-admin/ansible_swap_OFF", "state": "absent"}
2025-05-28 01:22:09,909 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:09,925 p=14358 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:22:10,724 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:10,759 p=14358 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:22:12,052 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:12,088 p=14358 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:22:14,835 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:14,870 p=14358 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:22:16,766 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:16,800 p=14358 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:22:19,622 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:19,646 p=14358 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:22:21,140 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:21,188 p=14358 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:22:21,983 p=14358 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:22:22,022 p=14358 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:22:24,223 p=14358 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-28 01:25:34,803 p=14638 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:25:35,328 p=14638 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:25:35,378 p=14638 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:25:40,629 p=14638 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:25:40,630 p=14638 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:25:40,767 p=14638 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:25:40,767 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:40,784 p=14638 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:25:41,412 p=14638 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:25:41,447 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:41,495 p=14638 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:25:42,303 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:25:42,343 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:42,359 p=14638 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:25:43,074 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:25:43,098 p=14638 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:25:43,117 p=14638 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:25:43,894 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:44,045 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:25:44,180 p=14638 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:25:45,412 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:45,446 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:25:45,473 p=14638 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:25:47,665 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:25:49,096 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:25:49,177 p=14638 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:25:50,571 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:26:29,831 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:26:29,867 p=14638 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:26:32,741 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:12,819 p=14638 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:27:12,890 p=14638 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:27:15,040 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:15,802 p=14638 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "checksum": "407d1fb0611c26267871bae7fad26786113ce376", "msg": "Unsupported parameters for (ansible.legacy.copy) module: notify. Supported parameters include: _original_basename, attributes, backup, checksum, content, dest, directory_mode, follow, force, group, local_follow, mode, owner, remote_src, selevel, serole, setype, seuser, src, unsafe_writes, validate (attr)."}
2025-05-28 01:27:15,881 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:27:17,524 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:17,596 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:27:20,152 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:20,206 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 01:27:21,344 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:21,386 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 01:27:22,514 p=14638 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:27:22,582 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 01:27:24,841 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:27:24,894 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 01:27:46,188 p=14638 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 01:27:51,731 p=14638 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 01:27:58,906 p=14638 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 01:27:58,942 p=14638 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 01:28:00,050 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:28:00,124 p=14638 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:28:00,942 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:28:00,971 p=14638 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:28:01,714 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:28:01,776 p=14638 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:28:02,660 p=14638 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:28:02,687 p=14638 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:28:04,077 p=14638 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:28:04,129 p=14638 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:28:04,219 p=14638 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:28:04,287 p=14638 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:28:04,288 p=14638 u=root n=ansible INFO| master-01                  : ok=21   changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:28:04,289 p=14638 u=root n=ansible INFO| worker-01                  : ok=9    changed=7    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 01:32:12,484 p=15251 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:32:13,015 p=15251 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:32:13,060 p=15251 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:32:17,923 p=15251 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:32:17,924 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:18,721 p=15251 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:32:18,721 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:18,744 p=15251 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:32:19,675 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:19,780 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:19,882 p=15251 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:32:21,388 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:21,437 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:21,476 p=15251 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:32:22,976 p=15251 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:32:22,998 p=15251 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:32:23,034 p=15251 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:32:24,127 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:24,162 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:24,263 p=15251 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:32:25,119 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:25,195 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:25,229 p=15251 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:32:27,094 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:27,159 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:27,181 p=15251 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:32:28,236 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:28,389 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:28,421 p=15251 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:32:30,888 p=15251 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:32:31,328 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:31,363 p=15251 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:32:33,355 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:33,646 p=15251 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "checksum": "407d1fb0611c26267871bae7fad26786113ce376", "msg": "Unsupported parameters for (ansible.legacy.copy) module: notify. Supported parameters include: _original_basename, attributes, backup, checksum, content, dest, directory_mode, follow, force, group, local_follow, mode, owner, remote_src, selevel, serole, setype, seuser, src, unsafe_writes, validate (attr)."}
2025-05-28 01:32:33,711 p=15251 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:32:34,923 p=15251 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:32:34,996 p=15251 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:32:36,045 p=15251 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-28 01:33:01,117 p=15593 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:33:01,638 p=15593 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:33:01,689 p=15593 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:33:04,890 p=15593 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:33:04,891 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:05,209 p=15593 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:33:05,209 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:05,243 p=15593 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:33:05,907 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:05,924 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:05,971 p=15593 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:33:06,696 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:06,727 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:06,749 p=15593 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:33:07,613 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:07,712 p=15593 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:33:07,742 p=15593 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:33:08,994 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:09,045 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:09,148 p=15593 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:33:10,591 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:10,653 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:10,692 p=15593 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:33:12,741 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:12,773 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:12,809 p=15593 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:33:14,116 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:14,144 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:14,159 p=15593 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:33:16,346 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:16,348 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:16,400 p=15593 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:33:17,757 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:17,951 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:18,042 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:33:18,685 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:33:18,708 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:18,728 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:33:20,649 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:20,651 p=15593 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:33:20,681 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 01:33:21,591 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:21,595 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:21,660 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 01:33:22,265 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:22,320 p=15593 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:33:22,385 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 01:33:23,409 p=15593 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:33:23,471 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:33:23,512 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 01:33:29,879 p=15593 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 01:33:34,587 p=15593 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 01:33:41,199 p=15593 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 01:34:03,862 p=15593 u=root n=ansible INFO| changed: [worker-01] => (item=kubectl)
2025-05-28 01:34:55,809 p=15593 u=root n=ansible INFO| changed: [worker-01] => (item=kubelet)
2025-05-28 01:35:34,320 p=15593 u=root n=ansible INFO| changed: [worker-01] => (item=kubeadm)
2025-05-28 01:35:34,406 p=15593 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 01:35:35,758 p=15593 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:35:37,363 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:35:37,487 p=15593 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:35:37,579 p=15593 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:35:38,500 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:35:38,533 p=15593 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:35:38,621 p=15593 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:35:39,465 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:35:39,501 p=15593 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:35:39,622 p=15593 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:35:40,545 p=15593 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:35:40,622 p=15593 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:35:40,829 p=15593 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:35:42,002 p=15593 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:35:42,041 p=15593 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:35:42,112 p=15593 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:35:43,170 p=15593 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "token", "create", "--print-join-command"], "delta": "0:00:00.102040", "end": "2025-05-27 23:08:09.924113", "msg": "non-zero return code", "rc": 1, "start": "2025-05-27 23:08:09.822073", "stderr": "failed to load admin kubeconfig: open /root/.kube/config: no such file or directory\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["failed to load admin kubeconfig: open /root/.kube/config: no such file or directory", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "", "stdout_lines": []}
2025-05-28 01:35:43,208 p=15593 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:35:43,210 p=15593 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:35:43,211 p=15593 u=root n=ansible INFO| worker-01                  : ok=17   changed=7    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 01:40:05,365 p=16339 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:40:05,611 p=16339 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:40:05,637 p=16339 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:40:10,335 p=16339 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:40:10,335 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:10,731 p=16339 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:40:10,731 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:10,770 p=16339 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 01:40:12,400 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:12,402 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:12,508 p=16339 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 01:40:13,936 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:14,005 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:14,040 p=16339 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 01:40:15,264 p=16339 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:40:15,322 p=16339 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:40:15,362 p=16339 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 01:40:16,398 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:16,399 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:16,450 p=16339 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 01:40:17,227 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:17,243 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:17,270 p=16339 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 01:40:19,293 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:19,298 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:19,322 p=16339 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 01:40:20,433 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:20,568 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:20,604 p=16339 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 01:40:24,262 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:24,817 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:24,833 p=16339 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 01:40:25,699 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:26,022 p=16339 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:40:26,067 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 01:40:26,482 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:26,567 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:26,583 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 01:40:27,679 p=16339 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:40:27,686 p=16339 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:40:27,706 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 01:40:28,100 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:28,114 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:28,138 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 01:40:28,523 p=16339 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:40:28,554 p=16339 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 01:40:28,568 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 01:40:29,215 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:29,294 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:29,307 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 01:40:33,062 p=16339 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 01:40:36,484 p=16339 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 01:40:37,800 p=16339 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 01:40:40,455 p=16339 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 01:40:41,642 p=16339 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 01:40:44,999 p=16339 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 01:40:45,012 p=16339 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 01:40:45,599 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:45,600 p=16339 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:40:45,648 p=16339 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:40:45,695 p=16339 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:40:46,051 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:46,064 p=16339 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:40:46,102 p=16339 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:40:46,486 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:46,499 p=16339 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:40:46,545 p=16339 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:40:47,003 p=16339 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:40:47,021 p=16339 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:40:47,065 p=16339 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:40:47,647 p=16339 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:40:47,663 p=16339 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:40:47,685 p=16339 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:40:48,075 p=16339 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "'{changed:' False, skipped: True, skip_reason: 'Conditional result was False,' false_condition: 'inventory_hostname in groups['\"'\"'master-nodes'\"'\"']}'", "msg": "[Errno 2] No such file or directory: b'{changed:'", "rc": 2, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 01:40:48,095 p=16339 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:40:48,096 p=16339 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:40:48,097 p=16339 u=root n=ansible INFO| worker-01                  : ok=17   changed=4    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 01:48:08,331 p=16925 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:48:08,467 p=16925 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:48:08,494 p=16925 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:48:10,943 p=16925 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:48:10,944 p=16925 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:48:11,065 p=16925 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:48:11,065 p=16925 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:48:11,076 p=16925 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:48:11,109 p=16925 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:48:11,535 p=16925 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:48:11,547 p=16925 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:48:11,580 p=16925 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:48:12,034 p=16925 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:48:12,045 p=16925 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:48:12,078 p=16925 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:48:12,509 p=16925 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:48:12,520 p=16925 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:48:12,561 p=16925 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:48:12,995 p=16925 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:48:13,024 p=16925 u=root n=ansible INFO| TASK [cluster_init : Verify node type] *****************************************************************************************************
2025-05-28 01:48:13,051 p=16925 u=root n=ansible INFO| ok: [master-01] => {
    "msg": "command_result"
}
2025-05-28 01:48:13,067 p=16925 u=root n=ansible INFO| ok: [worker-01] => {
    "msg": "command_result"
}
2025-05-28 01:48:13,088 p=16925 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 01:48:13,120 p=16925 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:48:13,447 p=16925 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "'{changed:' False, skipped: True, skip_reason: 'Conditional result was False,' false_condition: 'inventory_hostname in groups['\"'\"'master-nodes'\"'\"']}'", "msg": "[Errno 2] No such file or directory: b'{changed:'", "rc": 2, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 01:48:13,461 p=16925 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:48:13,462 p=16925 u=root n=ansible INFO| master-01                  : ok=6    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:48:13,462 p=16925 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 01:49:16,160 p=17055 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:49:16,288 p=17055 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:49:16,315 p=17055 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:49:18,601 p=17055 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:49:18,601 p=17055 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:49:18,784 p=17055 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:49:18,784 p=17055 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:49:18,800 p=17055 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:49:18,838 p=17055 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:49:19,350 p=17055 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:49:19,366 p=17055 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:49:19,409 p=17055 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:49:19,883 p=17055 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:49:19,897 p=17055 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:49:19,937 p=17055 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:49:20,412 p=17055 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:49:20,426 p=17055 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:49:20,467 p=17055 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:49:21,496 p=17055 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:49:21,508 p=17055 u=root n=ansible INFO| TASK [cluster_init : Verify node type] *****************************************************************************************************
2025-05-28 01:49:21,536 p=17055 u=root n=ansible INFO| ok: [master-01] => {
    "msg": "command_result.stdout"
}
2025-05-28 01:49:21,548 p=17055 u=root n=ansible INFO| ok: [worker-01] => {
    "msg": "command_result.stdout"
}
2025-05-28 01:49:21,561 p=17055 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 01:49:21,589 p=17055 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:49:21,604 p=17055 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'stdout'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 32, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n    msg: command_result.stdout\n- name: Run command on worker nodes to join the cluster\n  ^ here\n"}
2025-05-28 01:49:21,617 p=17055 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:49:21,617 p=17055 u=root n=ansible INFO| master-01                  : ok=6    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:49:21,617 p=17055 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 01:50:07,429 p=17176 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 01:50:07,555 p=17176 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 01:50:07,583 p=17176 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 01:50:09,369 p=17176 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:50:09,369 p=17176 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 01:50:09,548 p=17176 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 01:50:09,549 p=17176 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:50:09,561 p=17176 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 01:50:09,598 p=17176 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:50:10,024 p=17176 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:50:10,038 p=17176 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 01:50:10,083 p=17176 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:50:10,516 p=17176 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:50:10,530 p=17176 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 01:50:10,577 p=17176 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:50:11,008 p=17176 u=root n=ansible INFO| ok: [master-01]
2025-05-28 01:50:11,020 p=17176 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 01:50:11,062 p=17176 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 01:50:11,473 p=17176 u=root n=ansible INFO| changed: [master-01]
2025-05-28 01:50:11,485 p=17176 u=root n=ansible INFO| TASK [cluster_init : Verify node type] *****************************************************************************************************
2025-05-28 01:50:11,520 p=17176 u=root n=ansible INFO| ok: [master-01] => {
    "msg": "kubeadm join 192.168.57.3:6443 --token 0vgm0j.bljyqs5rhfjlii3t --discovery-token-ca-cert-hash sha256:6960ad5268cc75345603b49f20368d64815ce2465a9cbfd4a4da994b6db3c449 "
}
2025-05-28 01:50:11,536 p=17176 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'stdout'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 29, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  when: inventory_hostname in groups['master-nodes']  # Only run on master nodes\n- name: Verify node type\n  ^ here\n"}
2025-05-28 01:50:11,549 p=17176 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 01:50:11,568 p=17176 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 01:50:11,582 p=17176 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 01:50:11,582 p=17176 u=root n=ansible INFO| master-01                  : ok=6    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 01:50:11,582 p=17176 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 02:00:43,586 p=17296 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:00:43,713 p=17296 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:00:43,743 p=17296 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:00:46,360 p=17296 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:00:46,361 p=17296 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:00:46,443 p=17296 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:00:46,444 p=17296 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:00:46,455 p=17296 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:00:46,488 p=17296 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:00:46,897 p=17296 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:00:46,909 p=17296 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:00:46,942 p=17296 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:00:47,378 p=17296 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:00:47,390 p=17296 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:00:47,423 p=17296 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:00:47,837 p=17296 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:00:47,849 p=17296 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:00:47,883 p=17296 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:00:48,296 p=17296 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:00:48,323 p=17296 u=root n=ansible INFO| TASK [cluster_init : Share join command cluster-wide] **************************************************************************************
2025-05-28 02:00:48,344 p=17296 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:00:48,354 p=17296 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'stdout'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 30, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Share join command cluster-wide\n  ^ here\n"}
2025-05-28 02:00:48,365 p=17296 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:00:48,381 p=17296 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:00:48,393 p=17296 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:00:48,393 p=17296 u=root n=ansible INFO| master-01                  : ok=6    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:00:48,393 p=17296 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 02:02:50,045 p=17449 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:02:50,165 p=17449 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:02:50,177 p=17449 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:02:52,779 p=17449 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:02:52,781 p=17449 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:02:52,853 p=17449 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:02:52,854 p=17449 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:02:52,867 p=17449 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:02:52,911 p=17449 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:02:53,324 p=17449 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:02:53,338 p=17449 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:02:53,395 p=17449 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:02:53,825 p=17449 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:02:53,838 p=17449 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:02:53,876 p=17449 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:02:54,359 p=17449 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:02:54,372 p=17449 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:02:54,410 p=17449 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:02:54,840 p=17449 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:02:54,853 p=17449 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:02:54,879 p=17449 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:02:54,895 p=17449 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'master'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 31, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Run command on worker nodes to join the cluster\n  ^ here\n"}
2025-05-28 02:02:54,910 p=17449 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:02:54,911 p=17449 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:02:54,911 p=17449 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 02:09:10,636 p=17590 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:09:10,763 p=17590 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:09:10,793 p=17590 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:09:13,581 p=17590 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:09:13,582 p=17590 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:09:13,690 p=17590 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:09:13,690 p=17590 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:09:13,702 p=17590 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:09:13,742 p=17590 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:09:14,162 p=17590 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:09:14,176 p=17590 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:09:14,219 p=17590 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:09:14,646 p=17590 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:09:14,657 p=17590 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:09:14,691 p=17590 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:09:15,127 p=17590 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:09:15,138 p=17590 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:09:15,168 p=17590 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:09:15,557 p=17590 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:09:15,569 p=17590 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:09:15,613 p=17590 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:09:16,311 p=17590 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:09:16,321 p=17590 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:09:16,342 p=17590 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:09:16,676 p=17590 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "./.k8s_join_command.sh", "msg": "[Errno 2] No such file or directory: b'./.k8s_join_command.sh'", "rc": 2, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:09:16,688 p=17590 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:09:16,688 p=17590 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:09:16,689 p=17590 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:13:06,053 p=17736 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:13:06,179 p=17736 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:13:06,204 p=17736 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:13:08,818 p=17736 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:13:08,819 p=17736 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:13:08,925 p=17736 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:13:08,925 p=17736 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:13:08,938 p=17736 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:13:08,980 p=17736 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:13:09,424 p=17736 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:13:09,436 p=17736 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:13:09,481 p=17736 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:13:09,913 p=17736 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:13:09,926 p=17736 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:13:09,961 p=17736 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:13:10,413 p=17736 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:13:10,425 p=17736 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:13:10,460 p=17736 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:13:10,861 p=17736 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:13:10,872 p=17736 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:13:10,910 p=17736 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'stdout'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 30, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Cache token locally\n  ^ here\n"}
2025-05-28 02:13:11,645 p=17736 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:13:11,657 p=17736 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:13:11,677 p=17736 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:13:11,691 p=17736 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:13:11,691 p=17736 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:13:11,691 p=17736 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 02:14:17,425 p=17870 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:14:17,538 p=17870 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:14:17,562 p=17870 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:14:19,923 p=17870 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:14:19,924 p=17870 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:14:20,052 p=17870 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:14:20,052 p=17870 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:14:20,066 p=17870 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:14:20,114 p=17870 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:14:20,563 p=17870 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:14:20,575 p=17870 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:14:20,619 p=17870 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:14:21,062 p=17870 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:14:21,075 p=17870 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:14:21,111 p=17870 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:14:21,558 p=17870 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:14:21,572 p=17870 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:14:21,609 p=17870 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:14:21,980 p=17870 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:14:21,993 p=17870 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:14:22,037 p=17870 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:14:22,685 p=17870 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:14:22,696 p=17870 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:14:22,720 p=17870 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:14:23,063 p=17870 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "./.k8s_join_command.sh", "msg": "[Errno 2] No such file or directory: b'./.k8s_join_command.sh'", "rc": 2, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:14:23,076 p=17870 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:14:23,076 p=17870 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:14:23,076 p=17870 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:17:57,061 p=18044 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:17:57,184 p=18044 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:17:57,209 p=18044 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:17:59,829 p=18044 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:17:59,830 p=18044 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:17:59,902 p=18044 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:17:59,903 p=18044 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:17:59,915 p=18044 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:17:59,950 p=18044 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:18:00,354 p=18044 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:18:00,365 p=18044 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:18:00,398 p=18044 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:18:00,829 p=18044 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:18:00,841 p=18044 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:18:00,875 p=18044 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:18:01,281 p=18044 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:18:01,293 p=18044 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:18:01,334 p=18044 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:18:01,715 p=18044 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:18:01,726 p=18044 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:18:01,768 p=18044 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:18:02,442 p=18044 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:18:02,454 p=18044 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:18:02,473 p=18044 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:18:03,090 p=18044 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 02:18:03,102 p=18044 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:18:03,129 p=18044 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:18:03,454 p=18044 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "/home/nour/.k8s_join_command.sh", "msg": "[Errno 8] Exec format error: b'/home/nour/.k8s_join_command.sh'", "rc": 8, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:18:03,466 p=18044 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:18:03,466 p=18044 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-28 02:18:03,466 p=18044 u=root n=ansible INFO| worker-01                  : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:20:24,781 p=18212 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:20:24,913 p=18212 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:20:24,940 p=18212 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:20:27,442 p=18212 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:20:27,442 p=18212 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:20:27,521 p=18212 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:20:27,521 p=18212 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:20:27,533 p=18212 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:20:27,565 p=18212 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:20:27,978 p=18212 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:20:27,990 p=18212 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:20:28,037 p=18212 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:20:28,474 p=18212 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:20:28,486 p=18212 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:20:28,533 p=18212 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:20:28,962 p=18212 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:20:28,973 p=18212 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:20:29,008 p=18212 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:20:29,370 p=18212 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:20:29,382 p=18212 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:20:29,420 p=18212 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:20:30,002 p=18212 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:20:30,014 p=18212 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:20:30,046 p=18212 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:20:30,653 p=18212 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 02:20:30,664 p=18212 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:20:30,689 p=18212 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:20:31,374 p=18212 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "/home/nour/.k8s_join_command.sh", "msg": "[Errno 8] Exec format error: b'/home/nour/.k8s_join_command.sh'", "rc": 8, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:20:31,386 p=18212 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:20:31,386 p=18212 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-28 02:20:31,387 p=18212 u=root n=ansible INFO| worker-01                  : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:22:42,314 p=18385 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:22:42,441 p=18385 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:22:42,470 p=18385 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:22:45,151 p=18385 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:22:45,152 p=18385 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:22:45,299 p=18385 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:22:45,300 p=18385 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:22:45,311 p=18385 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:22:45,350 p=18385 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:22:45,767 p=18385 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:22:45,782 p=18385 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:22:45,838 p=18385 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:22:46,284 p=18385 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:22:46,298 p=18385 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:22:46,339 p=18385 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:22:46,778 p=18385 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:22:46,790 p=18385 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:22:46,831 p=18385 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:22:47,236 p=18385 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:22:47,247 p=18385 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:22:47,283 p=18385 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:22:47,863 p=18385 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:22:47,875 p=18385 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:22:47,896 p=18385 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:22:48,509 p=18385 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 02:22:48,521 p=18385 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:22:48,548 p=18385 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:22:48,861 p=18385 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "/home/nour/.k8s_join_command.sh", "msg": "[Errno 8] Exec format error: b'/home/nour/.k8s_join_command.sh'", "rc": 8, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:22:48,873 p=18385 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:22:48,874 p=18385 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-28 02:22:48,874 p=18385 u=root n=ansible INFO| worker-01                  : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:24:19,519 p=18554 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:24:19,651 p=18554 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:24:19,678 p=18554 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:24:22,244 p=18554 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:24:22,245 p=18554 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:24:22,282 p=18554 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:24:22,282 p=18554 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:24:22,298 p=18554 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:24:22,345 p=18554 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:24:22,764 p=18554 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:24:22,776 p=18554 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:24:22,817 p=18554 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:24:23,243 p=18554 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:24:23,256 p=18554 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:24:23,298 p=18554 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:24:23,740 p=18554 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:24:23,752 p=18554 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:24:23,797 p=18554 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:24:24,196 p=18554 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:24:24,208 p=18554 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:24:24,253 p=18554 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:24:24,841 p=18554 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:24:24,852 p=18554 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:24:24,874 p=18554 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:24:25,461 p=18554 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 02:24:25,473 p=18554 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:24:25,497 p=18554 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:24:25,814 p=18554 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "/home/nour/.k8s_join_command.txt", "msg": "[Errno 13] Permission denied: b'/home/nour/.k8s_join_command.txt'", "rc": 13, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:24:25,827 p=18554 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:24:25,827 p=18554 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-28 02:24:25,827 p=18554 u=root n=ansible INFO| worker-01                  : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:26:02,009 p=18722 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:26:02,130 p=18722 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:26:02,156 p=18722 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:26:04,602 p=18722 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:26:04,603 p=18722 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:26:04,825 p=18722 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:26:04,825 p=18722 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:26:04,837 p=18722 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:26:04,872 p=18722 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:26:05,303 p=18722 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:26:05,316 p=18722 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:26:05,353 p=18722 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:26:05,819 p=18722 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:26:05,833 p=18722 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:26:05,876 p=18722 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:26:06,318 p=18722 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:26:06,330 p=18722 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:26:06,372 p=18722 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:26:06,743 p=18722 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:26:06,754 p=18722 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:26:06,798 p=18722 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:26:07,437 p=18722 u=root n=ansible INFO| changed: [master-01 -> localhost]
2025-05-28 02:26:07,449 p=18722 u=root n=ansible INFO| TASK [cluster_init : Cache token locally] **************************************************************************************************
2025-05-28 02:26:07,475 p=18722 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:26:08,106 p=18722 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 02:26:08,118 p=18722 u=root n=ansible INFO| TASK [cluster_init : Run command on worker nodes to join the cluster] **********************************************************************
2025-05-28 02:26:08,148 p=18722 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:26:08,472 p=18722 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "cmd": "/home/nour/.k8s_join_command.txt", "msg": "[Errno 13] Permission denied: b'/home/nour/.k8s_join_command.txt'", "rc": 13, "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-28 02:26:08,483 p=18722 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:26:08,484 p=18722 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-28 02:26:08,484 p=18722 u=root n=ansible INFO| worker-01                  : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 02:29:09,101 p=18895 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:29:09,219 p=18895 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:29:09,251 p=18895 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:29:11,675 p=18895 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:29:11,676 p=18895 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:29:11,863 p=18895 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:29:11,863 p=18895 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:11,874 p=18895 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:29:11,919 p=18895 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:12,352 p=18895 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:12,364 p=18895 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:29:12,401 p=18895 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:12,840 p=18895 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:12,853 p=18895 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:29:12,900 p=18895 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:13,355 p=18895 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:13,368 p=18895 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:29:13,408 p=18895 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:13,827 p=18895 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:29:13,839 p=18895 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 02:29:13,864 p=18895 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:29:13,890 p=18895 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'join_command'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 44, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Join cluster directly (No file needed)\n  ^ here\n"}
2025-05-28 02:29:13,904 p=18895 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:29:13,905 p=18895 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:29:13,905 p=18895 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 02:29:42,103 p=19045 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 02:29:42,234 p=19045 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 02:29:42,257 p=19045 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 02:29:43,958 p=19045 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:29:43,958 p=19045 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 02:29:44,066 p=19045 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 02:29:44,066 p=19045 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:44,077 p=19045 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 02:29:44,113 p=19045 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:44,589 p=19045 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:44,600 p=19045 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 02:29:44,636 p=19045 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:45,104 p=19045 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:45,118 p=19045 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 02:29:45,152 p=19045 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:45,599 p=19045 u=root n=ansible INFO| ok: [master-01]
2025-05-28 02:29:45,612 p=19045 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 02:29:45,656 p=19045 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 02:29:46,043 p=19045 u=root n=ansible INFO| changed: [master-01]
2025-05-28 02:29:46,056 p=19045 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 02:29:46,082 p=19045 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 02:34:07,296 p=19045 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "192.168.57.3:6443", "--token", "2q1c14.u5unrsh62suo82de", "--discovery-token-ca-cert-hash", "sha256:6960ad5268cc75345603b49f20368d64815ce2465a9cbfd4a4da994b6db3c449"], "delta": "0:04:00.779968", "end": "2025-05-28 00:02:04.646498", "msg": "non-zero return code", "rc": 1, "start": "2025-05-27 23:58:03.866530", "stderr": "W0527 23:58:03.905992   11285 checks.go:1077] [preflight] WARNING: Couldn't create the interface used for talking to the container runtime: failed to create new CRI runtime service: validate service connection: validate CRI v1 runtime API for endpoint \"unix:///var/run/containerd/containerd.sock\": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService\nerror execution phase kubelet-start: The HTTP call equal to 'curl -sSL http://127.0.0.1:10248/healthz' returned error: Get \"http://127.0.0.1:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused\n\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["W0527 23:58:03.905992   11285 checks.go:1077] [preflight] WARNING: Couldn't create the interface used for talking to the container runtime: failed to create new CRI runtime service: validate service connection: validate CRI v1 runtime API for endpoint \"unix:///var/run/containerd/containerd.sock\": rpc error: code = Unimplemented desc = unknown service runtime.v1.RuntimeService", "error execution phase kubelet-start: The HTTP call equal to 'curl -sSL http://127.0.0.1:10248/healthz' returned error: Get \"http://127.0.0.1:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused", "", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[preflight] Running pre-flight checks\n[preflight] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s\n[kubelet-check] The kubelet is not healthy after 4m0.000593868s\n\nUnfortunately, an error has occurred:\n\tThe HTTP call equal to 'curl -sSL http://127.0.0.1:10248/healthz' returned error: Get \"http://127.0.0.1:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused\n\n\nThis error is likely caused by:\n\t- The kubelet is not running\n\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)\n\nIf you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:\n\t- 'systemctl status kubelet'\n\t- 'journalctl -xeu kubelet'", "stdout_lines": ["[preflight] Running pre-flight checks", "[preflight] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.", "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"", "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"", "[kubelet-start] Starting the kubelet", "[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s", "[kubelet-check] The kubelet is not healthy after 4m0.000593868s", "", "Unfortunately, an error has occurred:", "\tThe HTTP call equal to 'curl -sSL http://127.0.0.1:10248/healthz' returned error: Get \"http://127.0.0.1:10248/healthz\": dial tcp 127.0.0.1:10248: connect: connection refused", "", "", "This error is likely caused by:", "\t- The kubelet is not running", "\t- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)", "", "If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:", "\t- 'systemctl status kubelet'", "\t- 'journalctl -xeu kubelet'"]}
2025-05-28 02:34:07,310 p=19045 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 02:34:07,311 p=19045 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 02:34:07,311 p=19045 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 14:29:02,630 p=2357 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:29:03,239 p=2357 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 14:29:03,342 p=2357 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 14:29:07,904 p=2357 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:29:07,904 p=2357 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:09,621 p=2357 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:29:09,621 p=2357 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:09,651 p=2357 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 14:29:09,684 p=2357 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:29:10,069 p=2357 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:10,079 p=2357 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 14:29:10,110 p=2357 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:29:10,546 p=2357 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:10,559 p=2357 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 14:29:10,593 p=2357 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:29:11,042 p=2357 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:11,053 p=2357 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 14:29:11,085 p=2357 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:29:14,029 p=2357 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:29:14,040 p=2357 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 14:29:14,061 p=2357 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 14:29:17,009 p=2357 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "192.168.57.3:6443", "--token", "lhgz7f.3zfhdi2i7zrffcf1", "--discovery-token-ca-cert-hash", "sha256:6960ad5268cc75345603b49f20368d64815ce2465a9cbfd4a4da994b6db3c449"], "delta": "0:00:02.648113", "end": "2025-05-28 11:29:16.979382", "msg": "non-zero return code", "rc": 1, "start": "2025-05-28 11:29:14.331269", "stderr": "error execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists\n\t[ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: [preflight] Some fatal errors occurred:", "\t[ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists", "\t[ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists", "[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[preflight] Running pre-flight checks", "stdout_lines": ["[preflight] Running pre-flight checks"]}
2025-05-28 14:29:17,022 p=2357 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 14:29:17,022 p=2357 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 14:29:17,022 p=2357 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 14:29:30,662 p=2528 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:29:31,129 p=2528 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 14:29:31,145 p=2528 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 14:29:32,657 p=2528 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:29:32,659 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:32,811 p=2528 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:29:32,811 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:32,822 p=2528 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 14:29:33,304 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:33,311 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:33,341 p=2528 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 14:29:33,806 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:33,808 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:33,819 p=2528 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 14:29:34,245 p=2528 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:29:34,261 p=2528 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:29:34,272 p=2528 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 14:29:34,796 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:34,798 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:34,830 p=2528 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 14:29:35,350 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:35,362 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:35,375 p=2528 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 14:29:37,149 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:37,271 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:37,281 p=2528 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 14:29:38,126 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:38,207 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:38,217 p=2528 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 14:29:46,601 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:46,708 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:46,719 p=2528 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 14:29:47,728 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:47,860 p=2528 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:29:47,891 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 14:29:48,244 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:48,282 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:48,293 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 14:29:49,491 p=2528 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:29:49,496 p=2528 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:29:49,507 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 14:29:49,865 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:49,875 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:49,886 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 14:29:50,257 p=2528 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:29:50,280 p=2528 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:29:50,291 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 14:29:50,910 p=2528 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:29:50,994 p=2528 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:29:51,008 p=2528 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 14:30:31,721 p=2528 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 14:30:48,418 p=2528 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 14:30:59,069 p=2528 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 14:30:59,193 p=2528 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 14:31:03,989 p=2528 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-28 14:39:44,164 p=3121 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:39:44,271 p=3121 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 14:39:44,282 p=3121 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 14:39:46,600 p=3121 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:39:46,601 p=3121 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:39:47,788 p=3121 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:39:47,788 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:47,797 p=3121 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 14:39:48,298 p=3121 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:39:48,335 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:48,346 p=3121 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 14:39:49,192 p=3121 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:39:49,296 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:49,307 p=3121 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 14:39:49,933 p=3121 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:39:49,972 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:49,982 p=3121 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 14:39:51,583 p=3121 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:39:58,537 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:58,547 p=3121 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 14:39:59,406 p=3121 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:39:59,879 p=3121 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:39:59,925 p=3121 u=root n=ansible INFO| RUNNING HANDLER [containerd : Restart service containerd] **********************************************************************************
2025-05-28 14:40:00,814 p=3121 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:40:00,816 p=3121 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 14:40:00,816 p=3121 u=root n=ansible INFO| master-01                  : ok=6    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 14:40:00,816 p=3121 u=root n=ansible INFO| worker-01                  : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 14:40:36,417 p=3345 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:40:36,470 p=3345 u=root n=ansible ERROR| ERROR! role definitions must contain a role name

The error appears to be in '/root/ansible/build_k8s_cluster/site.yml': line 11, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

      tags: build
    - meta: flush_handlers  # Forces handlers to run NOW
      ^ here

2025-05-28 14:42:15,251 p=3374 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:42:15,399 p=3374 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 14:42:15,413 p=3374 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 14:42:17,840 p=3374 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:42:17,840 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:18,948 p=3374 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:42:18,949 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:18,959 p=3374 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 14:42:19,389 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:19,392 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:19,422 p=3374 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 14:42:19,874 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:19,877 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:19,893 p=3374 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 14:42:20,364 p=3374 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:42:20,368 p=3374 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:42:20,378 p=3374 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 14:42:20,797 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:20,813 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:20,843 p=3374 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 14:42:21,267 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:21,321 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:21,332 p=3374 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 14:42:22,094 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:22,252 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:22,264 p=3374 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 14:42:22,946 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:23,058 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:23,069 p=3374 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 14:42:24,564 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:24,606 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:24,617 p=3374 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 14:42:25,344 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:25,473 p=3374 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:42:25,486 p=3374 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 14:42:25,496 p=3374 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 14:42:25,505 p=3374 u=root n=ansible INFO| RUNNING HANDLER [containerd : Restart service containerd] **********************************************************************************
2025-05-28 14:42:26,346 p=3374 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:42:26,376 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 14:42:26,721 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:26,724 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:26,734 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 14:42:27,798 p=3374 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:42:27,803 p=3374 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:42:27,814 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 14:42:28,134 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:28,175 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:28,188 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 14:42:28,539 p=3374 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:42:28,554 p=3374 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:42:28,564 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 14:42:29,169 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:29,181 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:29,192 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 14:42:32,074 p=3374 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 14:42:32,313 p=3374 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 14:42:34,869 p=3374 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 14:42:35,147 p=3374 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 14:42:37,649 p=3374 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 14:42:43,803 p=3374 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 14:42:43,815 p=3374 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 14:42:44,279 p=3374 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:42:44,457 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:44,488 p=3374 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 14:42:44,516 p=3374 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:42:44,816 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:44,830 p=3374 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 14:42:44,865 p=3374 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:42:45,177 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:45,189 p=3374 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 14:42:45,221 p=3374 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:42:45,577 p=3374 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:42:45,588 p=3374 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 14:42:45,621 p=3374 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:42:48,579 p=3374 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:42:48,592 p=3374 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 14:42:48,613 p=3374 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 14:42:49,055 p=3374 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "192.168.57.3:6443", "--token", "q1fz5l.ek4o7ylcji88jdmq", "--discovery-token-ca-cert-hash", "sha256:6960ad5268cc75345603b49f20368d64815ce2465a9cbfd4a4da994b6db3c449"], "delta": "0:00:00.138879", "end": "2025-05-28 11:42:49.019815", "msg": "non-zero return code", "rc": 1, "start": "2025-05-28 11:42:48.880936", "stderr": "error execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists\n\t[ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: [preflight] Some fatal errors occurred:", "\t[ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists", "\t[ERROR FileAvailable--etc-kubernetes-pki-ca.crt]: /etc/kubernetes/pki/ca.crt already exists", "[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[preflight] Running pre-flight checks", "stdout_lines": ["[preflight] Running pre-flight checks"]}
2025-05-28 14:42:49,066 p=3374 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 14:42:49,066 p=3374 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 14:42:49,067 p=3374 u=root n=ansible INFO| worker-01                  : ok=18   changed=5    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 14:53:20,369 p=3969 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 14:53:20,529 p=3969 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 14:53:20,544 p=3969 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 14:53:22,856 p=3969 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:53:22,857 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:22,905 p=3969 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 14:53:22,906 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:22,915 p=3969 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 14:53:23,350 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:23,353 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:23,382 p=3969 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 14:53:23,879 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:23,879 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:23,889 p=3969 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 14:53:24,348 p=3969 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:53:24,361 p=3969 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:53:24,372 p=3969 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 14:53:24,831 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:24,835 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:24,866 p=3969 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 14:53:25,303 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:25,304 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:25,315 p=3969 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 14:53:26,022 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:26,122 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:26,134 p=3969 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 14:53:26,845 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:26,858 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:26,870 p=3969 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 14:53:28,299 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:28,299 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:28,311 p=3969 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 14:53:29,062 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:29,065 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:29,079 p=3969 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 14:53:29,088 p=3969 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 14:53:29,114 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 14:53:29,528 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:29,546 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:29,557 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 14:53:30,596 p=3969 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:53:30,602 p=3969 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:53:30,614 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 14:53:30,949 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:30,962 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:30,974 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 14:53:31,316 p=3969 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:53:31,329 p=3969 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:53:31,345 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 14:53:31,984 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:31,995 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:32,006 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 14:53:34,922 p=3969 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 14:53:35,021 p=3969 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 14:53:38,007 p=3969 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 14:53:38,194 p=3969 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 14:53:41,004 p=3969 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 14:53:41,303 p=3969 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 14:53:41,322 p=3969 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 14:53:41,999 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:42,013 p=3969 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 14:53:42,052 p=3969 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 14:53:42,093 p=3969 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:53:42,556 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:42,569 p=3969 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 14:53:42,606 p=3969 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:53:42,925 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:42,939 p=3969 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 14:53:42,974 p=3969 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:53:43,479 p=3969 u=root n=ansible INFO| ok: [master-01]
2025-05-28 14:53:43,492 p=3969 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 14:53:43,537 p=3969 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 14:53:43,978 p=3969 u=root n=ansible INFO| changed: [master-01]
2025-05-28 14:53:43,991 p=3969 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 14:53:44,012 p=3969 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 14:53:46,913 p=3969 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 14:53:46,940 p=3969 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 14:53:46,940 p=3969 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 14:53:46,941 p=3969 u=root n=ansible INFO| worker-01                  : ok=18   changed=4    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-05-28 15:07:08,937 p=4540 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:07:09,287 p=4540 u=root n=ansible ERROR| ERROR! conflicting action statements: ansible.builtin.command, creates

The error appears to be in '/root/ansible/build_k8s_cluster/roles/cluster_init/tasks/main.yml': line 33, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: Join cluster directly (No file needed)
  ^ here

2025-05-28 15:07:20,476 p=4568 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:07:20,882 p=4568 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 15:07:20,922 p=4568 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 15:07:26,686 p=4568 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:07:26,686 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:26,924 p=4568 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:07:26,925 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:26,953 p=4568 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 15:07:28,116 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:28,168 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:28,256 p=4568 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 15:07:29,452 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:29,516 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:29,552 p=4568 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 15:07:30,813 p=4568 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:07:30,862 p=4568 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:07:30,894 p=4568 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 15:07:32,095 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:32,146 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:32,234 p=4568 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 15:07:33,482 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:33,495 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:33,526 p=4568 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 15:07:35,798 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:35,837 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:35,868 p=4568 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 15:07:37,735 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:37,825 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:37,882 p=4568 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 15:07:41,835 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:41,877 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:41,909 p=4568 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 15:07:43,898 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:43,948 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:43,986 p=4568 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:07:44,012 p=4568 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:07:44,094 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 15:07:45,163 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:45,167 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:45,200 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 15:07:47,320 p=4568 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:07:47,329 p=4568 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:07:47,358 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 15:07:48,226 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:48,262 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:48,292 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 15:07:49,325 p=4568 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:07:49,353 p=4568 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:07:49,386 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 15:07:51,134 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:07:51,208 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:07:51,259 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 15:07:58,448 p=4568 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 15:07:58,672 p=4568 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 15:08:05,865 p=4568 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 15:08:06,208 p=4568 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 15:08:13,250 p=4568 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 15:08:13,940 p=4568 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 15:08:13,992 p=4568 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 15:08:15,144 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:08:15,188 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:08:15,268 p=4568 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 15:08:15,358 p=4568 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:08:16,134 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:08:16,168 p=4568 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 15:08:16,247 p=4568 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:08:17,071 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:08:17,142 p=4568 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 15:08:17,275 p=4568 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:08:18,440 p=4568 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:08:18,473 p=4568 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 15:08:18,553 p=4568 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:08:19,621 p=4568 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:08:19,653 p=4568 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 15:08:19,701 p=4568 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:08:20,564 p=4568 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:08:20,627 p=4568 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 15:08:20,628 p=4568 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 15:08:20,629 p=4568 u=root n=ansible INFO| worker-01                  : ok=18   changed=3    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-05-28 15:15:36,026 p=5266 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:15:36,560 p=5266 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 15:15:36,612 p=5266 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 15:15:40,700 p=5266 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-28 15:16:32,139 p=5360 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:16:32,582 p=5360 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 15:16:32,627 p=5360 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 15:16:36,405 p=5360 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:16:36,406 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:36,743 p=5360 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:16:36,744 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:36,784 p=5360 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 15:16:37,952 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:37,959 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:38,051 p=5360 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 15:16:39,300 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:39,314 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:39,344 p=5360 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 15:16:40,646 p=5360 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:16:40,662 p=5360 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:16:40,693 p=5360 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 15:16:41,882 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:41,913 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:41,997 p=5360 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 15:16:43,259 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:43,307 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:43,340 p=5360 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 15:16:45,531 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:45,593 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:45,626 p=5360 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 15:16:47,485 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:47,602 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:47,634 p=5360 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 15:16:51,539 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:51,603 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:51,638 p=5360 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 15:16:53,739 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:53,834 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:53,871 p=5360 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:16:53,900 p=5360 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:16:53,983 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 15:16:54,965 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:55,005 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:55,034 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 15:16:57,323 p=5360 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:16:57,325 p=5360 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:16:57,356 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 15:16:58,260 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:16:58,267 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:16:58,299 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 15:16:59,289 p=5360 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:16:59,291 p=5360 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:16:59,327 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 15:17:01,002 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:17:01,034 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:17:01,064 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 15:17:15,504 p=5360 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 15:17:18,999 p=5360 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 15:17:23,175 p=5360 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 15:17:26,105 p=5360 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 15:17:30,549 p=5360 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 15:17:32,862 p=5360 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 15:17:32,897 p=5360 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] ************************************************************************************************
2025-05-28 15:17:34,117 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:17:34,128 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:17:34,213 p=5360 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 15:17:34,298 p=5360 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:17:35,063 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:17:35,095 p=5360 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 15:17:35,173 p=5360 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:17:36,080 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:17:36,118 p=5360 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 15:17:36,211 p=5360 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:17:37,425 p=5360 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:17:37,458 p=5360 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 15:17:37,546 p=5360 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:17:38,683 p=5360 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:17:38,716 p=5360 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 15:17:38,771 p=5360 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:17:39,852 p=5360 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:17:39,905 p=5360 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] *****************************************************************************
2025-05-28 15:17:42,460 p=5360 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Failed to import the required Python library (kubernetes) on k8s-worker-01's Python /usr/bin/python3.10. Please read the module documentation and install it in the appropriate location. If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter"}
2025-05-28 15:17:42,659 p=5360 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Failed to import the required Python library (kubernetes) on k8s-master-01's Python /usr/bin/python3.10. Please read the module documentation and install it in the appropriate location. If the required library is installed, but Ansible is using the wrong Python interpreter, please consult the documentation on ansible_python_interpreter"}
2025-05-28 15:17:42,662 p=5360 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 15:17:42,663 p=5360 u=root n=ansible INFO| master-01                  : ok=21   changed=4    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-28 15:17:42,664 p=5360 u=root n=ansible INFO| worker-01                  : ok=18   changed=3    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 15:19:10,994 p=6072 u=root n=ansible INFO| Starting galaxy collection install process
2025-05-28 15:19:15,217 p=6072 u=root n=ansible INFO| Nothing to do. All requested collections are already installed. If you want to reinstall them, consider using `--force`.
2025-05-28 15:22:30,747 p=6138 u=root n=ansible INFO| Starting galaxy collection install process
2025-05-28 15:22:31,368 p=6138 u=root n=ansible INFO| Nothing to do. All requested collections are already installed. If you want to reinstall them, consider using `--force`.
2025-05-28 15:22:37,731 p=6166 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:22:38,169 p=6166 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 15:22:38,214 p=6166 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 15:22:44,543 p=6166 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:22:44,549 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:44,896 p=6166 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:22:44,897 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:44,924 p=6166 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] *******************************************************************************************
2025-05-28 15:22:46,108 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:46,148 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:46,239 p=6166 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] **********************************************************************************************
2025-05-28 15:22:47,481 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:47,499 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:47,530 p=6166 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] *****************************************************************************************
2025-05-28 15:22:48,738 p=6166 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:22:48,782 p=6166 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:22:48,819 p=6166 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] **********************************************************************
2025-05-28 15:22:50,110 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:50,134 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:50,185 p=6166 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ***************************************************************************************************
2025-05-28 15:22:51,337 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:51,374 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:51,403 p=6166 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] *****************************************************************************************************
2025-05-28 15:22:53,752 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:53,824 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:53,861 p=6166 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] **********************************************************************************
2025-05-28 15:22:55,816 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:55,850 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:55,879 p=6166 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] *************************************************************************************
2025-05-28 15:22:59,790 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:22:59,851 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:22:59,890 p=6166 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ***********************************************************************************
2025-05-28 15:23:01,940 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:01,991 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:02,022 p=6166 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:23:02,049 p=6166 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ***********************************
2025-05-28 15:23:02,126 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] ********************************************************************************************
2025-05-28 15:23:03,034 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:03,070 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:03,103 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ******************************************************************************************
2025-05-28 15:23:05,371 p=6166 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:23:05,382 p=6166 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:23:05,427 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] **********************************************************************************************
2025-05-28 15:23:06,426 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:06,436 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:06,478 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] ****************************************************************************************************
2025-05-28 15:23:07,511 p=6166 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:23:07,540 p=6166 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:23:07,570 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] ****************************************************************************************
2025-05-28 15:23:09,377 p=6166 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:09,404 p=6166 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:09,430 p=6166 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ******************************************************************
2025-05-28 15:23:16,587 p=6166 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 15:23:16,919 p=6166 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 15:23:23,200 p=6166 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 15:23:24,196 p=6166 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 15:23:30,059 p=6166 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-28 15:23:40,969 p=6751 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:23:41,283 p=6751 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ***********************************************************************************************************
2025-05-28 15:23:41,338 p=6751 u=root n=ansible INFO| TASK [Gathering Facts] *********************************************************************************************************************
2025-05-28 15:23:45,292 p=6751 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:23:45,293 p=6751 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:45,519 p=6751 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of
another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:23:45,520 p=6751 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:45,551 p=6751 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] *******************************************************************************************
2025-05-28 15:23:45,650 p=6751 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:23:46,737 p=6751 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:46,771 p=6751 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] *********************************************************************************************
2025-05-28 15:23:46,867 p=6751 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:23:48,002 p=6751 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:48,046 p=6751 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ******************************************************************************
2025-05-28 15:23:48,141 p=6751 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:23:49,358 p=6751 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:23:49,391 p=6751 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] **************************************************************************
2025-05-28 15:23:49,464 p=6751 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:23:50,400 p=6751 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:23:50,437 p=6751 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] *******************************************************************************
2025-05-28 15:23:50,482 p=6751 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:23:51,333 p=6751 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:23:51,372 p=6751 u=root n=ansible INFO| TASK [cluster_init : Install pip (if missing)] *********************************************************************************************
2025-05-28 15:25:13,628 p=7091 u=root n=ansible INFO| - Role roles/cluster_network was created successfully
2025-05-28 15:25:22,706 p=7112 u=root n=ansible INFO| - Role roles/cluster_status was created successfully
2025-05-28 15:26:12,525 p=6751 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:26:22,653 p=6751 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:26:22,716 p=6751 u=root n=ansible INFO| TASK [cluster_init : Install kubernetes package] *******************************************************************************************
2025-05-28 15:26:45,340 p=6751 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:26:45,969 p=6751 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:26:46,009 p=6751 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] *****************************************************************************
2025-05-28 15:26:49,209 p=6751 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:26:49,211 p=6751 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:26:49,862 p=6751 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:26:49,864 p=6751 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:26:49,868 p=6751 u=root n=ansible INFO| PLAY RECAP *********************************************************************************************************************************
2025-05-28 15:26:49,869 p=6751 u=root n=ansible INFO| master-01                  : ok=7    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-28 15:26:49,871 p=6751 u=root n=ansible INFO| worker-01                  : ok=4    changed=2    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 15:29:50,529 p=7429 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:29:50,833 p=7429 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 15:29:50,891 p=7429 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 15:29:58,132 p=7429 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:29:58,133 p=7429 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:29:58,377 p=7429 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:29:58,378 p=7429 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:29:58,407 p=7429 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-28 15:29:58,492 p=7429 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:29:59,661 p=7429 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:29:59,692 p=7429 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] **************************************************************************************
2025-05-28 15:29:59,781 p=7429 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:30:00,904 p=7429 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:30:00,937 p=7429 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ***********************************************************************
2025-05-28 15:30:01,023 p=7429 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:30:02,173 p=7429 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:30:02,205 p=7429 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] *******************************************************************
2025-05-28 15:30:02,291 p=7429 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:30:03,520 p=7429 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:30:03,551 p=7429 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] ************************************************************************
2025-05-28 15:30:03,609 p=7429 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:30:04,452 p=7429 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:30:04,486 p=7429 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] **********************************************************************
2025-05-28 15:30:07,375 p=7429 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:30:07,377 p=7429 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:30:07,442 p=7429 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:30:07,443 p=7429 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:30:07,445 p=7429 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 15:30:07,447 p=7429 u=root n=ansible INFO| master-01                  : ok=5    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-28 15:30:07,448 p=7429 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-05-28 15:32:04,432 p=7671 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:32:04,731 p=7671 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 15:32:04,791 p=7671 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 15:32:10,661 p=7671 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:32:10,662 p=7671 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:32:10,805 p=7671 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:32:10,805 p=7671 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:32:10,835 p=7671 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-28 15:32:10,931 p=7671 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:32:12,145 p=7671 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:32:12,177 p=7671 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] **************************************************************************************
2025-05-28 15:32:12,263 p=7671 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:32:13,545 p=7671 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:32:13,579 p=7671 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ***********************************************************************
2025-05-28 15:32:13,665 p=7671 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:32:14,790 p=7671 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:32:14,831 p=7671 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] *******************************************************************
2025-05-28 15:32:14,910 p=7671 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:32:15,913 p=7671 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:32:15,947 p=7671 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] ************************************************************************
2025-05-28 15:32:16,002 p=7671 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:32:16,909 p=7671 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:32:16,941 p=7671 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] **********************************************************************
2025-05-28 15:32:17,016 p=7671 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:32:19,731 p=7671 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:32:19,733 p=7671 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:32:19,797 p=7671 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 15:32:19,799 p=7671 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-28 15:32:19,800 p=7671 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-05-28 15:49:00,134 p=8077 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:49:00,459 p=8077 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 15:49:00,518 p=8077 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 15:49:07,010 p=8077 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:49:07,011 p=8077 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:49:08,008 p=8077 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:49:08,008 p=8077 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:49:08,042 p=8077 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-28 15:49:08,178 p=8077 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:49:09,452 p=8077 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:49:09,497 p=8077 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] **************************************************************************************
2025-05-28 15:49:09,587 p=8077 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:49:10,976 p=8077 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:49:11,007 p=8077 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ***********************************************************************
2025-05-28 15:49:11,099 p=8077 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:49:12,583 p=8077 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:49:12,638 p=8077 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] *******************************************************************
2025-05-28 15:49:12,750 p=8077 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:49:15,725 p=8077 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:49:15,765 p=8077 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] ************************************************************************
2025-05-28 15:49:15,819 p=8077 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:49:16,982 p=8077 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:49:17,019 p=8077 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] **********************************************************************
2025-05-28 15:49:17,101 p=8077 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:49:24,429 p=8077 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:49:24,499 p=8077 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 15:49:24,500 p=8077 u=root n=ansible INFO| master-01                  : ok=6    changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 15:49:24,500 p=8077 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-05-28 15:49:59,317 p=8304 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:49:59,661 p=8304 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 15:49:59,719 p=8304 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 15:50:04,142 p=8304 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:50:04,143 p=8304 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:50:05,000 p=8304 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:50:05,001 p=8304 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:50:05,050 p=8304 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-28 15:50:05,149 p=8304 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:50:06,524 p=8304 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:50:06,547 p=8304 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] **************************************************************************************
2025-05-28 15:50:06,619 p=8304 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:50:07,935 p=8304 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:50:07,982 p=8304 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ***********************************************************************
2025-05-28 15:50:08,068 p=8304 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:50:09,237 p=8304 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:50:09,277 p=8304 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] *******************************************************************
2025-05-28 15:50:09,365 p=8304 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:50:11,416 p=8304 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:50:11,455 p=8304 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] ************************************************************************
2025-05-28 15:50:11,519 p=8304 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:50:12,645 p=8304 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:50:12,683 p=8304 u=root n=ansible INFO| TASK [cluster_init : Apply weave net manifest to the cluster.] **********************************************************************
2025-05-28 15:50:12,767 p=8304 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:50:17,420 p=8304 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:50:17,498 p=8304 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 15:50:17,499 p=8304 u=root n=ansible INFO| master-01                  : ok=6    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-28 15:50:17,500 p=8304 u=root n=ansible INFO| worker-01                  : ok=2    changed=0    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-05-28 15:57:12,186 p=8536 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 15:57:12,666 p=8536 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 15:57:12,714 p=8536 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 15:57:19,454 p=8536 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:57:19,455 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:19,974 p=8536 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 15:57:19,975 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:20,009 p=8536 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 15:57:21,217 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:21,248 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:21,285 p=8536 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 15:57:25,035 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:25,083 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:25,128 p=8536 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-28 15:57:30,440 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:31,987 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:32,089 p=8536 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-28 15:57:33,276 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:33,281 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:33,322 p=8536 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-28 15:57:34,692 p=8536 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:57:34,738 p=8536 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:57:34,782 p=8536 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-28 15:57:36,092 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:36,120 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:36,223 p=8536 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-28 15:57:37,601 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:37,607 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:37,653 p=8536 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-28 15:57:40,419 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:40,431 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:40,474 p=8536 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-28 15:57:42,462 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:42,476 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:42,519 p=8536 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-28 15:57:46,121 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:46,130 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:46,171 p=8536 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-28 15:57:48,333 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:48,366 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:48,441 p=8536 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-28 15:57:48,502 p=8536 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-28 15:57:48,607 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-28 15:57:49,549 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:49,598 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:49,638 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-28 15:57:51,798 p=8536 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:57:51,801 p=8536 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:57:51,838 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] ***************************************************************************************
2025-05-28 15:57:52,807 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:52,826 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:52,863 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] *********************************************************************************************
2025-05-28 15:57:53,871 p=8536 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:57:53,907 p=8536 u=root n=ansible INFO| changed: [worker-01]
2025-05-28 15:57:53,945 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] *********************************************************************************
2025-05-28 15:57:55,847 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:57:55,862 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:57:55,921 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ***********************************************************
2025-05-28 15:58:21,073 p=8536 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-28 15:58:28,112 p=8536 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-28 15:58:31,115 p=8536 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-28 15:58:36,486 p=8536 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-28 15:58:38,254 p=8536 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-28 15:58:43,736 p=8536 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-28 15:58:43,774 p=8536 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] *****************************************************************************************
2025-05-28 15:58:44,996 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:58:45,022 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:58:45,123 p=8536 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-28 15:58:45,217 p=8536 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:58:46,024 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:58:46,085 p=8536 u=root n=ansible INFO| TASK [cluster_init : Create a .kube directory] **************************************************************************************
2025-05-28 15:58:46,206 p=8536 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:58:47,013 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:58:47,054 p=8536 u=root n=ansible INFO| TASK [cluster_init : Copy file admin.conf to .kube directory] ***********************************************************************
2025-05-28 15:58:47,151 p=8536 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:58:48,527 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:58:48,594 p=8536 u=root n=ansible INFO| TASK [cluster_init : Run kubeadm token create and capture output] *******************************************************************
2025-05-28 15:58:48,744 p=8536 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:58:51,987 p=8536 u=root n=ansible INFO| changed: [master-01]
2025-05-28 15:58:52,030 p=8536 u=root n=ansible INFO| TASK [cluster_init : Join cluster directly (No file needed)] ************************************************************************
2025-05-28 15:58:52,095 p=8536 u=root n=ansible INFO| skipping: [master-01]
2025-05-28 15:58:53,108 p=8536 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 15:58:53,227 p=8536 u=root n=ansible INFO| TASK [cluster_network : Apply weave net manifest to the cluster.] *******************************************************************
2025-05-28 15:58:53,320 p=8536 u=root n=ansible INFO| skipping: [worker-01]
2025-05-28 15:58:58,731 p=8536 u=root n=ansible INFO| ok: [master-01]
2025-05-28 15:58:58,838 p=8536 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-28 15:59:02,149 p=8536 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:59:02,156 p=8536 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:59:02,232 p=8536 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 15:59:02,233 p=8536 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 15:59:02,238 p=8536 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 15:59:02,239 p=8536 u=root n=ansible INFO| master-01                  : ok=24   changed=4    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-28 15:59:02,240 p=8536 u=root n=ansible INFO| worker-01                  : ok=20   changed=3    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-05-28 16:00:52,211 p=9412 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 16:00:52,516 p=9412 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 16:00:52,572 p=9412 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 16:00:59,916 p=9412 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:00:59,917 p=9412 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 16:01:00,622 p=9412 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:01:00,623 p=9412 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:01:00,662 p=9412 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-28 16:01:03,611 p=9412 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 16:01:03,613 p=9412 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 16:01:03,762 p=9412 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:01:03,832 p=9412 u=root n=ansible INFO| TASK [cluster_status : Gather system pods] ******************************************************************************************
2025-05-28 16:01:06,682 p=9412 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:01:06,782 p=9412 u=root n=ansible INFO| TASK [cluster_status : debug] *******************************************************************************************************
2025-05-28 16:01:06,927 p=9412 u=root n=ansible INFO| ok: [master-01] => {
    "nodes.resources": [
        {
            "apiVersion": "v1",
            "kind": "Node",
            "metadata": {
                "annotations": {
                    "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                    "node.alpha.kubernetes.io/ttl": "0",
                    "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                },
                "creationTimestamp": "2025-05-27T22:20:08Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-master-01",
                    "kubernetes.io/os": "linux",
                    "node-role.kubernetes.io/control-plane": "",
                    "node.kubernetes.io/exclude-from-external-load-balancers": ""
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:beta.kubernetes.io/arch": {},
                                    "f:beta.kubernetes.io/os": {},
                                    "f:kubernetes.io/arch": {},
                                    "f:kubernetes.io/hostname": {},
                                    "f:kubernetes.io/os": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:07Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                },
                                "f:labels": {
                                    "f:node-role.kubernetes.io/control-plane": {},
                                    "f:node.kubernetes.io/exclude-from-external-load-balancers": {}
                                }
                            }
                        },
                        "manager": "kubeadm",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:12Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:node.alpha.kubernetes.io/ttl": {}
                                }
                            },
                            "f:spec": {
                                "f:taints": {}
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T12:36:01Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"NetworkUnavailable\"}": {
                                        ".": {},
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-utils",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:52Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:allocatable": {
                                    "f:memory": {}
                                },
                                "f:capacity": {
                                    "f:memory": {}
                                },
                                "f:conditions": {
                                    "k:{\"type\":\"DiskPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"MemoryPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"PIDPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {}
                                    }
                                },
                                "f:images": {},
                                "f:nodeInfo": {
                                    "f:bootID": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T13:00:30Z"
                    }
                ],
                "name": "k8s-master-01",
                "resourceVersion": "17054",
                "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
            },
            "spec": {
                "taints": [
                    {
                        "effect": "NoSchedule",
                        "key": "node-role.kubernetes.io/control-plane"
                    }
                ]
            },
            "status": {
                "addresses": [
                    {
                        "address": "192.168.57.3",
                        "type": "InternalIP"
                    },
                    {
                        "address": "k8s-master-01",
                        "type": "Hostname"
                    }
                ],
                "allocatable": {
                    "cpu": "2",
                    "ephemeral-storage": "10836873199",
                    "hugepages-2Mi": "0",
                    "memory": "1908476Ki",
                    "pods": "110"
                },
                "capacity": {
                    "cpu": "2",
                    "ephemeral-storage": "11758760Ki",
                    "hugepages-2Mi": "0",
                    "memory": "2010876Ki",
                    "pods": "110"
                },
                "conditions": [
                    {
                        "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                        "lastTransitionTime": "2025-05-28T12:49:52Z",
                        "message": "Weave pod has set this",
                        "reason": "WeaveIsUp",
                        "status": "False",
                        "type": "NetworkUnavailable"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has sufficient memory available",
                        "reason": "KubeletHasSufficientMemory",
                        "status": "False",
                        "type": "MemoryPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has no disk pressure",
                        "reason": "KubeletHasNoDiskPressure",
                        "status": "False",
                        "type": "DiskPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has sufficient PID available",
                        "reason": "KubeletHasSufficientPID",
                        "status": "False",
                        "type": "PIDPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-28T12:35:57Z",
                        "message": "kubelet is posting ready status",
                        "reason": "KubeletReady",
                        "status": "True",
                        "type": "Ready"
                    }
                ],
                "daemonEndpoints": {
                    "kubeletEndpoint": {
                        "Port": 10250
                    }
                },
                "images": [
                    {
                        "names": [
                            "registry.k8s.io/etcd@sha256:c6a9d11cc5c04b114ccdef39a9265eeef818e3d02f5359be035ae784097fdec5",
                            "registry.k8s.io/etcd:3.5.16-0"
                        ],
                        "sizeBytes": 57680541
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                            "docker.io/rajchaudhuri/weave-kube:2.9.0"
                        ],
                        "sizeBytes": 37163311
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                            "registry.k8s.io/kube-proxy:v1.32.5"
                        ],
                        "sizeBytes": 30891891
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-apiserver@sha256:0bee1bf751fe06009678c0cde7545443ba3a8d2edf71cea4c69cbb5774b9bf47",
                            "registry.k8s.io/kube-apiserver:v1.32.5"
                        ],
                        "sizeBytes": 28794611
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-controller-manager@sha256:79bcf2f5e614c336c02dcea9dfcdf485d7297aed6a21239a99c87f7164f9baca",
                            "registry.k8s.io/kube-controller-manager:v1.32.5"
                        ],
                        "sizeBytes": 26384363
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-scheduler@sha256:f0f39d8b9808c407cacb3a46a5a9ce4d4a4a7cf3b674ba4bd221f5bc90051d2a",
                            "registry.k8s.io/kube-scheduler:v1.32.5"
                        ],
                        "sizeBytes": 20777921
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                            "docker.io/rajchaudhuri/weave-npc:2.9.0"
                        ],
                        "sizeBytes": 18834204
                    },
                    {
                        "names": [
                            "registry.k8s.io/coredns/coredns@sha256:9caabbf6238b189a65d0d6e6ac138de60d6a1c419e5a341fbbb7c78382559c6e",
                            "registry.k8s.io/coredns/coredns:v1.11.3"
                        ],
                        "sizeBytes": 18562039
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a",
                            "registry.k8s.io/pause:3.10"
                        ],
                        "sizeBytes": 320368
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                            "registry.k8s.io/pause:3.8"
                        ],
                        "sizeBytes": 311286
                    }
                ],
                "nodeInfo": {
                    "architecture": "amd64",
                    "bootID": "b2d9d6b0-d348-4135-8d11-0229e84037fa",
                    "containerRuntimeVersion": "containerd://1.7.27",
                    "kernelVersion": "5.15.0-140-generic",
                    "kubeProxyVersion": "v1.32.5",
                    "kubeletVersion": "v1.32.5",
                    "machineID": "61af482aeb01497cabf71b9509d80e9a",
                    "operatingSystem": "linux",
                    "osImage": "Ubuntu 22.04.5 LTS",
                    "systemUUID": "70b18ffc-8d96-a04a-b976-e3e9849d9333"
                }
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Node",
            "metadata": {
                "annotations": {
                    "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                    "node.alpha.kubernetes.io/ttl": "0",
                    "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                },
                "creationTimestamp": "2025-05-28T11:53:46Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-worker-01",
                    "kubernetes.io/os": "linux"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:node.alpha.kubernetes.io/ttl": {}
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                }
                            }
                        },
                        "manager": "kubeadm",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:beta.kubernetes.io/arch": {},
                                    "f:beta.kubernetes.io/os": {},
                                    "f:kubernetes.io/arch": {},
                                    "f:kubernetes.io/hostname": {},
                                    "f:kubernetes.io/os": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"NetworkUnavailable\"}": {
                                        ".": {},
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-utils",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:52Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"DiskPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"MemoryPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"PIDPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {}
                                    }
                                },
                                "f:images": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T13:00:05Z"
                    }
                ],
                "name": "k8s-worker-01",
                "resourceVersion": "17021",
                "uid": "3a8c1725-8d5f-4a8d-8d12-c7de58b1d1a4"
            },
            "spec": {},
            "status": {
                "addresses": [
                    {
                        "address": "192.168.57.5",
                        "type": "InternalIP"
                    },
                    {
                        "address": "k8s-worker-01",
                        "type": "Hostname"
                    }
                ],
                "allocatable": {
                    "cpu": "2",
                    "ephemeral-storage": "10836873199",
                    "hugepages-2Mi": "0",
                    "memory": "1908476Ki",
                    "pods": "110"
                },
                "capacity": {
                    "cpu": "2",
                    "ephemeral-storage": "11758760Ki",
                    "hugepages-2Mi": "0",
                    "memory": "2010876Ki",
                    "pods": "110"
                },
                "conditions": [
                    {
                        "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                        "lastTransitionTime": "2025-05-28T12:49:52Z",
                        "message": "Weave pod has set this",
                        "reason": "WeaveIsUp",
                        "status": "False",
                        "type": "NetworkUnavailable"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has sufficient memory available",
                        "reason": "KubeletHasSufficientMemory",
                        "status": "False",
                        "type": "MemoryPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has no disk pressure",
                        "reason": "KubeletHasNoDiskPressure",
                        "status": "False",
                        "type": "DiskPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has sufficient PID available",
                        "reason": "KubeletHasSufficientPID",
                        "status": "False",
                        "type": "PIDPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T12:36:06Z",
                        "message": "kubelet is posting ready status",
                        "reason": "KubeletReady",
                        "status": "True",
                        "type": "Ready"
                    }
                ],
                "daemonEndpoints": {
                    "kubeletEndpoint": {
                        "Port": 10250
                    }
                },
                "images": [
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                            "docker.io/rajchaudhuri/weave-kube:2.9.0"
                        ],
                        "sizeBytes": 37163311
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                            "registry.k8s.io/kube-proxy:v1.32.5"
                        ],
                        "sizeBytes": 30891891
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                            "docker.io/rajchaudhuri/weave-npc:2.9.0"
                        ],
                        "sizeBytes": 18834204
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                            "registry.k8s.io/pause:3.8"
                        ],
                        "sizeBytes": 311286
                    }
                ],
                "nodeInfo": {
                    "architecture": "amd64",
                    "bootID": "35ce9634-e5e1-42bd-ba6c-146ed9a05af7",
                    "containerRuntimeVersion": "containerd://1.7.27",
                    "kernelVersion": "5.15.0-140-generic",
                    "kubeProxyVersion": "v1.32.5",
                    "kubeletVersion": "v1.32.5",
                    "machineID": "61af482aeb01497cabf71b9509d80e9a",
                    "operatingSystem": "linux",
                    "osImage": "Ubuntu 22.04.5 LTS",
                    "systemUUID": "160ee565-8887-f745-88a2-04510d4f73af"
                }
            }
        }
    ]
}
2025-05-28 16:01:06,979 p=9412 u=root n=ansible INFO| TASK [cluster_status : debug] *******************************************************************************************************
2025-05-28 16:01:07,988 p=9412 u=root n=ansible INFO| ok: [master-01] => {
    "system_pods.resources": [
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-27T22:20:19Z",
                "generateName": "coredns-668d6bf9bc-",
                "labels": {
                    "k8s-app": "kube-dns",
                    "pod-template-hash": "668d6bf9bc"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:k8s-app": {},
                                    "f:pod-template-hash": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"014cd9f9-4fdb-4de7-88c7-89a6c244ecbe\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:podAntiAffinity": {
                                        ".": {},
                                        "f:preferredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"coredns\"}": {
                                        ".": {},
                                        "f:args": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:ports": {
                                            ".": {},
                                            "k:{\"containerPort\":53,\"protocol\":\"TCP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            },
                                            "k:{\"containerPort\":53,\"protocol\":\"UDP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            },
                                            "k:{\"containerPort\":9153,\"protocol\":\"TCP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            }
                                        },
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:limits": {
                                                ".": {},
                                                "f:memory": {}
                                            },
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {},
                                                "f:memory": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:allowPrivilegeEscalation": {},
                                            "f:capabilities": {
                                                ".": {},
                                                "f:add": {},
                                                "f:drop": {}
                                            },
                                            "f:readOnlyRootFilesystem": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/coredns\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:nodeSelector": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {},
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"config-volume\"}": {
                                        ".": {},
                                        "f:configMap": {
                                            ".": {},
                                            "f:defaultMode": {},
                                            "f:items": {},
                                            "f:name": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:19Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-scheduler",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:57:30Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"10.40.0.0\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:50:05Z"
                    }
                ],
                "name": "coredns-668d6bf9bc-dt62r",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "coredns-668d6bf9bc",
                        "uid": "014cd9f9-4fdb-4de7-88c7-89a6c244ecbe"
                    }
                ],
                "resourceVersion": "16169",
                "uid": "0a931bcb-38ca-4468-b463-348252bbbfcc"
            },
            "spec": {
                "affinity": {
                    "podAntiAffinity": {
                        "preferredDuringSchedulingIgnoredDuringExecution": [
                            {
                                "podAffinityTerm": {
                                    "labelSelector": {
                                        "matchExpressions": [
                                            {
                                                "key": "k8s-app",
                                                "operator": "In",
                                                "values": [
                                                    "kube-dns"
                                                ]
                                            }
                                        ]
                                    },
                                    "topologyKey": "kubernetes.io/hostname"
                                },
                                "weight": 100
                            }
                        ]
                    }
                },
                "containers": [
                    {
                        "args": [
                            "-conf",
                            "/etc/coredns/Corefile"
                        ],
                        "image": "registry.k8s.io/coredns/coredns:v1.11.3",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 5,
                            "httpGet": {
                                "path": "/health",
                                "port": 8080,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 60,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "coredns",
                        "ports": [
                            {
                                "containerPort": 53,
                                "name": "dns",
                                "protocol": "UDP"
                            },
                            {
                                "containerPort": 53,
                                "name": "dns-tcp",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 9153,
                                "name": "metrics",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/ready",
                                "port": 8181,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {
                            "limits": {
                                "memory": "170Mi"
                            },
                            "requests": {
                                "cpu": "100m",
                                "memory": "70Mi"
                            }
                        },
                        "securityContext": {
                            "allowPrivilegeEscalation": false,
                            "capabilities": {
                                "add": [
                                    "NET_BIND_SERVICE"
                                ],
                                "drop": [
                                    "ALL"
                                ]
                            },
                            "readOnlyRootFilesystem": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/coredns",
                                "name": "config-volume",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-84qzs",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "Default",
                "enableServiceLinks": true,
                "nodeName": "k8s-master-01",
                "nodeSelector": {
                    "kubernetes.io/os": "linux"
                },
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000000000,
                "priorityClassName": "system-cluster-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "coredns",
                "serviceAccountName": "coredns",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "key": "CriticalAddonsOnly",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node-role.kubernetes.io/control-plane"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "items": [
                                {
                                    "key": "Corefile",
                                    "path": "Corefile"
                                }
                            ],
                            "name": "coredns"
                        },
                        "name": "config-volume"
                    },
                    {
                        "name": "kube-api-access-84qzs",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:53Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:36:02Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:50:04Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:50:04Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:36:01Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://f67b71c7e3b3141b461d98e2ff68eae536999505810aedcd7195aba33c6a16d5",
                        "image": "registry.k8s.io/coredns/coredns:v1.11.3",
                        "imageID": "registry.k8s.io/coredns/coredns@sha256:9caabbf6238b189a65d0d6e6ac138de60d6a1c419e5a341fbbb7c78382559c6e",
                        "lastState": {},
                        "name": "coredns",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:53Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/coredns",
                                "name": "config-volume",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-84qzs",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "10.40.0.0",
                "podIPs": [
                    {
                        "ip": "10.40.0.0"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T12:36:02Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-27T22:20:19Z",
                "generateName": "coredns-668d6bf9bc-",
                "labels": {
                    "k8s-app": "kube-dns",
                    "pod-template-hash": "668d6bf9bc"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:k8s-app": {},
                                    "f:pod-template-hash": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"014cd9f9-4fdb-4de7-88c7-89a6c244ecbe\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:podAntiAffinity": {
                                        ".": {},
                                        "f:preferredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"coredns\"}": {
                                        ".": {},
                                        "f:args": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:ports": {
                                            ".": {},
                                            "k:{\"containerPort\":53,\"protocol\":\"TCP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            },
                                            "k:{\"containerPort\":53,\"protocol\":\"UDP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            },
                                            "k:{\"containerPort\":9153,\"protocol\":\"TCP\"}": {
                                                ".": {},
                                                "f:containerPort": {},
                                                "f:name": {},
                                                "f:protocol": {}
                                            }
                                        },
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:limits": {
                                                ".": {},
                                                "f:memory": {}
                                            },
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {},
                                                "f:memory": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:allowPrivilegeEscalation": {},
                                            "f:capabilities": {
                                                ".": {},
                                                "f:add": {},
                                                "f:drop": {}
                                            },
                                            "f:readOnlyRootFilesystem": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/coredns\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:nodeSelector": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {},
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"config-volume\"}": {
                                        ".": {},
                                        "f:configMap": {
                                            ".": {},
                                            "f:defaultMode": {},
                                            "f:items": {},
                                            "f:name": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:19Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-scheduler",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:57:30Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"10.40.0.1\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:50:06Z"
                    }
                ],
                "name": "coredns-668d6bf9bc-frn8k",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "ReplicaSet",
                        "name": "coredns-668d6bf9bc",
                        "uid": "014cd9f9-4fdb-4de7-88c7-89a6c244ecbe"
                    }
                ],
                "resourceVersion": "16177",
                "uid": "04c57f6c-e35a-4dc0-8fc6-06fec83d54f2"
            },
            "spec": {
                "affinity": {
                    "podAntiAffinity": {
                        "preferredDuringSchedulingIgnoredDuringExecution": [
                            {
                                "podAffinityTerm": {
                                    "labelSelector": {
                                        "matchExpressions": [
                                            {
                                                "key": "k8s-app",
                                                "operator": "In",
                                                "values": [
                                                    "kube-dns"
                                                ]
                                            }
                                        ]
                                    },
                                    "topologyKey": "kubernetes.io/hostname"
                                },
                                "weight": 100
                            }
                        ]
                    }
                },
                "containers": [
                    {
                        "args": [
                            "-conf",
                            "/etc/coredns/Corefile"
                        ],
                        "image": "registry.k8s.io/coredns/coredns:v1.11.3",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 5,
                            "httpGet": {
                                "path": "/health",
                                "port": 8080,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 60,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 5
                        },
                        "name": "coredns",
                        "ports": [
                            {
                                "containerPort": 53,
                                "name": "dns",
                                "protocol": "UDP"
                            },
                            {
                                "containerPort": 53,
                                "name": "dns-tcp",
                                "protocol": "TCP"
                            },
                            {
                                "containerPort": 9153,
                                "name": "metrics",
                                "protocol": "TCP"
                            }
                        ],
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "path": "/ready",
                                "port": 8181,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {
                            "limits": {
                                "memory": "170Mi"
                            },
                            "requests": {
                                "cpu": "100m",
                                "memory": "70Mi"
                            }
                        },
                        "securityContext": {
                            "allowPrivilegeEscalation": false,
                            "capabilities": {
                                "add": [
                                    "NET_BIND_SERVICE"
                                ],
                                "drop": [
                                    "ALL"
                                ]
                            },
                            "readOnlyRootFilesystem": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/coredns",
                                "name": "config-volume",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-7x9vd",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "Default",
                "enableServiceLinks": true,
                "nodeName": "k8s-master-01",
                "nodeSelector": {
                    "kubernetes.io/os": "linux"
                },
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000000000,
                "priorityClassName": "system-cluster-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "coredns",
                "serviceAccountName": "coredns",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "key": "CriticalAddonsOnly",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node-role.kubernetes.io/control-plane"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists",
                        "tolerationSeconds": 300
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "items": [
                                {
                                    "key": "Corefile",
                                    "path": "Corefile"
                                }
                            ],
                            "name": "coredns"
                        },
                        "name": "config-volume"
                    },
                    {
                        "name": "kube-api-access-7x9vd",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:54Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:36:02Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:50:06Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:50:06Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:36:02Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://9c957b09785ca5375b8e8ff222e0ecece7241ab3bfa55f0b3f2b33e8f60fd070",
                        "image": "registry.k8s.io/coredns/coredns:v1.11.3",
                        "imageID": "registry.k8s.io/coredns/coredns@sha256:9caabbf6238b189a65d0d6e6ac138de60d6a1c419e5a341fbbb7c78382559c6e",
                        "lastState": {},
                        "name": "coredns",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:53Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/coredns",
                                "name": "config-volume",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-7x9vd",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "10.40.0.1",
                "podIPs": [
                    {
                        "ip": "10.40.0.1"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T12:36:02Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "annotations": {
                    "kubeadm.kubernetes.io/etcd.advertise-client-urls": "https://192.168.57.3:2379",
                    "kubernetes.io/config.hash": "ccbd0a659a93a8861a46471c7b474d58",
                    "kubernetes.io/config.mirror": "ccbd0a659a93a8861a46471c7b474d58",
                    "kubernetes.io/config.seen": "2025-05-27T22:19:31.674329998Z",
                    "kubernetes.io/config.source": "file"
                },
                "creationTimestamp": "2025-05-27T22:20:11Z",
                "labels": {
                    "component": "etcd",
                    "tier": "control-plane"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:kubeadm.kubernetes.io/etcd.advertise-client-urls": {},
                                    "f:kubernetes.io/config.hash": {},
                                    "f:kubernetes.io/config.mirror": {},
                                    "f:kubernetes.io/config.seen": {},
                                    "f:kubernetes.io/config.source": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:component": {},
                                    "f:tier": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"261b64aa-acc9-4ade-b1e4-2f5aebf9ecff\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:containers": {
                                    "k:{\"name\":\"etcd\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {},
                                                "f:memory": {}
                                            }
                                        },
                                        "f:startupProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/kubernetes/pki/etcd\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/var/lib/etcd\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeName": {},
                                "f:priority": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seccompProfile": {
                                        ".": {},
                                        "f:type": {}
                                    }
                                },
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"etcd-certs\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"etcd-data\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:11Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:22:40Z"
                    }
                ],
                "name": "etcd-k8s-master-01",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "v1",
                        "controller": true,
                        "kind": "Node",
                        "name": "k8s-master-01",
                        "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
                    }
                ],
                "resourceVersion": "8759",
                "uid": "6c6dc256-43f0-4568-8580-68929bf0ec88"
            },
            "spec": {
                "containers": [
                    {
                        "command": [
                            "etcd",
                            "--advertise-client-urls=https://192.168.57.3:2379",
                            "--cert-file=/etc/kubernetes/pki/etcd/server.crt",
                            "--client-cert-auth=true",
                            "--data-dir=/var/lib/etcd",
                            "--experimental-initial-corrupt-check=true",
                            "--experimental-watch-progress-notify-interval=5s",
                            "--initial-advertise-peer-urls=https://192.168.57.3:2380",
                            "--initial-cluster=k8s-master-01=https://192.168.57.3:2380",
                            "--key-file=/etc/kubernetes/pki/etcd/server.key",
                            "--listen-client-urls=https://127.0.0.1:2379,https://192.168.57.3:2379",
                            "--listen-metrics-urls=http://127.0.0.1:2381",
                            "--listen-peer-urls=https://192.168.57.3:2380",
                            "--name=k8s-master-01",
                            "--peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt",
                            "--peer-client-cert-auth=true",
                            "--peer-key-file=/etc/kubernetes/pki/etcd/peer.key",
                            "--peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt",
                            "--snapshot-count=10000",
                            "--trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt"
                        ],
                        "image": "registry.k8s.io/etcd:3.5.16-0",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 8,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/livez",
                                "port": 2381,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "name": "etcd",
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/readyz",
                                "port": 2381,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 1,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "resources": {
                            "requests": {
                                "cpu": "100m",
                                "memory": "100Mi"
                            }
                        },
                        "startupProbe": {
                            "failureThreshold": 24,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/readyz",
                                "port": 2381,
                                "scheme": "HTTP"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/lib/etcd",
                                "name": "etcd-data"
                            },
                            {
                                "mountPath": "/etc/kubernetes/pki/etcd",
                                "name": "etcd-certs"
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-master-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seccompProfile": {
                        "type": "RuntimeDefault"
                    }
                },
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/etc/kubernetes/pki/etcd",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "etcd-certs"
                    },
                    {
                        "hostPath": {
                            "path": "/var/lib/etcd",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "etcd-data"
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:45Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:11Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:11Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://90557990952f6adff01334e5c476c47b100cf31f90c72ff20954f1aa4ee474b0",
                        "image": "registry.k8s.io/etcd:3.5.16-0",
                        "imageID": "registry.k8s.io/etcd@sha256:c6a9d11cc5c04b114ccdef39a9265eeef818e3d02f5359be035ae784097fdec5",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://f772d9ce3d58c3466dbc19496aed7452fdd8badeea742e3d009ec9d1777764f0",
                                "exitCode": 255,
                                "finishedAt": "2025-05-28T11:21:29Z",
                                "reason": "Unknown",
                                "startedAt": "2025-05-27T22:19:41Z"
                            }
                        },
                        "name": "etcd",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:21:45Z"
                            }
                        }
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T11:21:40Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "annotations": {
                    "kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint": "192.168.57.3:6443",
                    "kubernetes.io/config.hash": "11ceaf3e3a0276ef2fa8291289229ac3",
                    "kubernetes.io/config.mirror": "11ceaf3e3a0276ef2fa8291289229ac3",
                    "kubernetes.io/config.seen": "2025-05-27T22:19:31.674346137Z",
                    "kubernetes.io/config.source": "file"
                },
                "creationTimestamp": "2025-05-27T22:20:11Z",
                "labels": {
                    "component": "kube-apiserver",
                    "tier": "control-plane"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint": {},
                                    "f:kubernetes.io/config.hash": {},
                                    "f:kubernetes.io/config.mirror": {},
                                    "f:kubernetes.io/config.seen": {},
                                    "f:kubernetes.io/config.source": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:component": {},
                                    "f:tier": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"261b64aa-acc9-4ade-b1e4-2f5aebf9ecff\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:containers": {
                                    "k:{\"name\":\"kube-apiserver\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:startupProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/etc/kubernetes/pki\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/etc/ssl/certs\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/usr/local/share/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/usr/share/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeName": {},
                                "f:priority": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seccompProfile": {
                                        ".": {},
                                        "f:type": {}
                                    }
                                },
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"ca-certs\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"etc-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"k8s-certs\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"usr-local-share-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"usr-share-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:11Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:22:40Z"
                    }
                ],
                "name": "kube-apiserver-k8s-master-01",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "v1",
                        "controller": true,
                        "kind": "Node",
                        "name": "k8s-master-01",
                        "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
                    }
                ],
                "resourceVersion": "8760",
                "uid": "a3db2b31-8dbf-4df7-9e16-d6439c8391c8"
            },
            "spec": {
                "containers": [
                    {
                        "command": [
                            "kube-apiserver",
                            "--advertise-address=192.168.57.3",
                            "--allow-privileged=true",
                            "--authorization-mode=Node,RBAC",
                            "--client-ca-file=/etc/kubernetes/pki/ca.crt",
                            "--enable-admission-plugins=NodeRestriction",
                            "--enable-bootstrap-token-auth=true",
                            "--etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt",
                            "--etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt",
                            "--etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key",
                            "--etcd-servers=https://127.0.0.1:2379",
                            "--kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt",
                            "--kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key",
                            "--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname",
                            "--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt",
                            "--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key",
                            "--requestheader-allowed-names=front-proxy-client",
                            "--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt",
                            "--requestheader-extra-headers-prefix=X-Remote-Extra-",
                            "--requestheader-group-headers=X-Remote-Group",
                            "--requestheader-username-headers=X-Remote-User",
                            "--secure-port=6443",
                            "--service-account-issuer=https://kubernetes.default.svc.cluster.local",
                            "--service-account-key-file=/etc/kubernetes/pki/sa.pub",
                            "--service-account-signing-key-file=/etc/kubernetes/pki/sa.key",
                            "--service-cluster-ip-range=10.96.0.0/12",
                            "--tls-cert-file=/etc/kubernetes/pki/apiserver.crt",
                            "--tls-private-key-file=/etc/kubernetes/pki/apiserver.key"
                        ],
                        "image": "registry.k8s.io/kube-apiserver:v1.32.5",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 8,
                            "httpGet": {
                                "host": "192.168.57.3",
                                "path": "/livez",
                                "port": 6443,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "name": "kube-apiserver",
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "host": "192.168.57.3",
                                "path": "/readyz",
                                "port": 6443,
                                "scheme": "HTTPS"
                            },
                            "periodSeconds": 1,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "resources": {
                            "requests": {
                                "cpu": "250m"
                            }
                        },
                        "startupProbe": {
                            "failureThreshold": 24,
                            "httpGet": {
                                "host": "192.168.57.3",
                                "path": "/livez",
                                "port": 6443,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/ssl/certs",
                                "name": "ca-certs",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/ca-certificates",
                                "name": "etc-ca-certificates",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/kubernetes/pki",
                                "name": "k8s-certs",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/usr/local/share/ca-certificates",
                                "name": "usr-local-share-ca-certificates",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/usr/share/ca-certificates",
                                "name": "usr-share-ca-certificates",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-master-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seccompProfile": {
                        "type": "RuntimeDefault"
                    }
                },
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/etc/ssl/certs",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "ca-certs"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "etc-ca-certificates"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/kubernetes/pki",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "k8s-certs"
                    },
                    {
                        "hostPath": {
                            "path": "/usr/local/share/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "usr-local-share-ca-certificates"
                    },
                    {
                        "hostPath": {
                            "path": "/usr/share/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "usr-share-ca-certificates"
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:45Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:14Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:14Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://5b3616e1479d65cc0c433532be1ad623bad6f6cad534b70c329f5a02c1bc3c0a",
                        "image": "registry.k8s.io/kube-apiserver:v1.32.5",
                        "imageID": "registry.k8s.io/kube-apiserver@sha256:0bee1bf751fe06009678c0cde7545443ba3a8d2edf71cea4c69cbb5774b9bf47",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://27a4723bfeafad1510157ace5161f567f1547e4bfa8cf2c56850a24b67e26756",
                                "exitCode": 255,
                                "finishedAt": "2025-05-28T11:21:29Z",
                                "reason": "Unknown",
                                "startedAt": "2025-05-27T22:19:41Z"
                            }
                        },
                        "name": "kube-apiserver",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:21:45Z"
                            }
                        }
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T11:21:40Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "annotations": {
                    "kubernetes.io/config.hash": "42f0206714ebf31a0876c7fcb15ebc61",
                    "kubernetes.io/config.mirror": "42f0206714ebf31a0876c7fcb15ebc61",
                    "kubernetes.io/config.seen": "2025-05-27T22:19:31.674354034Z",
                    "kubernetes.io/config.source": "file"
                },
                "creationTimestamp": "2025-05-27T22:20:11Z",
                "labels": {
                    "component": "kube-controller-manager",
                    "tier": "control-plane"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:kubernetes.io/config.hash": {},
                                    "f:kubernetes.io/config.mirror": {},
                                    "f:kubernetes.io/config.seen": {},
                                    "f:kubernetes.io/config.source": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:component": {},
                                    "f:tier": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"261b64aa-acc9-4ade-b1e4-2f5aebf9ecff\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:containers": {
                                    "k:{\"name\":\"kube-controller-manager\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:startupProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/etc/kubernetes/controller-manager.conf\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/etc/kubernetes/pki\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/etc/ssl/certs\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/usr/libexec/kubernetes/kubelet-plugins/volume/exec\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/usr/local/share/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/usr/share/ca-certificates\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeName": {},
                                "f:priority": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seccompProfile": {
                                        ".": {},
                                        "f:type": {}
                                    }
                                },
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"ca-certs\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"etc-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"flexvolume-dir\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"k8s-certs\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"kubeconfig\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"usr-local-share-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"usr-share-ca-certificates\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:11Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:22:40Z"
                    }
                ],
                "name": "kube-controller-manager-k8s-master-01",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "v1",
                        "controller": true,
                        "kind": "Node",
                        "name": "k8s-master-01",
                        "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
                    }
                ],
                "resourceVersion": "8757",
                "uid": "858ac484-663c-4480-9d22-1c526f54d0fd"
            },
            "spec": {
                "containers": [
                    {
                        "command": [
                            "kube-controller-manager",
                            "--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf",
                            "--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf",
                            "--bind-address=127.0.0.1",
                            "--client-ca-file=/etc/kubernetes/pki/ca.crt",
                            "--cluster-name=kubernetes",
                            "--cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt",
                            "--cluster-signing-key-file=/etc/kubernetes/pki/ca.key",
                            "--controllers=*,bootstrapsigner,tokencleaner",
                            "--kubeconfig=/etc/kubernetes/controller-manager.conf",
                            "--leader-elect=true",
                            "--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt",
                            "--root-ca-file=/etc/kubernetes/pki/ca.crt",
                            "--service-account-private-key-file=/etc/kubernetes/pki/sa.key",
                            "--use-service-account-credentials=true"
                        ],
                        "image": "registry.k8s.io/kube-controller-manager:v1.32.5",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 8,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/healthz",
                                "port": 10257,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "name": "kube-controller-manager",
                        "resources": {
                            "requests": {
                                "cpu": "200m"
                            }
                        },
                        "startupProbe": {
                            "failureThreshold": 24,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/healthz",
                                "port": 10257,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/ssl/certs",
                                "name": "ca-certs",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/ca-certificates",
                                "name": "etc-ca-certificates",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/usr/libexec/kubernetes/kubelet-plugins/volume/exec",
                                "name": "flexvolume-dir"
                            },
                            {
                                "mountPath": "/etc/kubernetes/pki",
                                "name": "k8s-certs",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/etc/kubernetes/controller-manager.conf",
                                "name": "kubeconfig",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/usr/local/share/ca-certificates",
                                "name": "usr-local-share-ca-certificates",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/usr/share/ca-certificates",
                                "name": "usr-share-ca-certificates",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-master-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seccompProfile": {
                        "type": "RuntimeDefault"
                    }
                },
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/etc/ssl/certs",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "ca-certs"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "etc-ca-certificates"
                    },
                    {
                        "hostPath": {
                            "path": "/usr/libexec/kubernetes/kubelet-plugins/volume/exec",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "flexvolume-dir"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/kubernetes/pki",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "k8s-certs"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/kubernetes/controller-manager.conf",
                            "type": "FileOrCreate"
                        },
                        "name": "kubeconfig"
                    },
                    {
                        "hostPath": {
                            "path": "/usr/local/share/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "usr-local-share-ca-certificates"
                    },
                    {
                        "hostPath": {
                            "path": "/usr/share/ca-certificates",
                            "type": "DirectoryOrCreate"
                        },
                        "name": "usr-share-ca-certificates"
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:45Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:12Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:12Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://7060a115bb96219a0b1b2ddd4679f0311df17ba4eedf904494bd5dbc50533453",
                        "image": "registry.k8s.io/kube-controller-manager:v1.32.5",
                        "imageID": "registry.k8s.io/kube-controller-manager@sha256:79bcf2f5e614c336c02dcea9dfcdf485d7297aed6a21239a99c87f7164f9baca",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://529b077835f8632f52b34af9f1eedd2a4b4d2fc9e0b980b58485a3c11bd2f609",
                                "exitCode": 255,
                                "finishedAt": "2025-05-28T11:21:29Z",
                                "reason": "Unknown",
                                "startedAt": "2025-05-27T22:19:41Z"
                            }
                        },
                        "name": "kube-controller-manager",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:21:45Z"
                            }
                        }
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T11:21:40Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-27T22:20:19Z",
                "generateName": "kube-proxy-",
                "labels": {
                    "controller-revision-hash": "5987677dc7",
                    "k8s-app": "kube-proxy",
                    "pod-template-generation": "1"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:controller-revision-hash": {},
                                    "f:k8s-app": {},
                                    "f:pod-template-generation": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"e4c54b84-9c3a-4836-87fe-234a760a9905\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:nodeAffinity": {
                                        ".": {},
                                        "f:requiredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"kube-proxy\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"NODE_NAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {},
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/lib/modules\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/var/lib/kube-proxy\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeSelector": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {},
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"kube-proxy\"}": {
                                        ".": {},
                                        "f:configMap": {
                                            ".": {},
                                            "f:defaultMode": {},
                                            "f:name": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"lib-modules\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"xtables-lock\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:19Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:22:40Z"
                    }
                ],
                "name": "kube-proxy-9vbsw",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "kube-proxy",
                        "uid": "e4c54b84-9c3a-4836-87fe-234a760a9905"
                    }
                ],
                "resourceVersion": "8755",
                "uid": "3b1e0485-f093-4d69-a5d6-f02ac630a097"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "k8s-master-01"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "command": [
                            "/usr/local/bin/kube-proxy",
                            "--config=/var/lib/kube-proxy/config.conf",
                            "--hostname-override=$(NODE_NAME)"
                        ],
                        "env": [
                            {
                                "name": "NODE_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            }
                        ],
                        "image": "registry.k8s.io/kube-proxy:v1.32.5",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "kube-proxy",
                        "resources": {},
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/lib/kube-proxy",
                                "name": "kube-proxy"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-7mh48",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-master-01",
                "nodeSelector": {
                    "kubernetes.io/os": "linux"
                },
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "kube-proxy",
                "serviceAccountName": "kube-proxy",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "kube-proxy"
                        },
                        "name": "kube-proxy"
                    },
                    {
                        "hostPath": {
                            "path": "/run/xtables.lock",
                            "type": "FileOrCreate"
                        },
                        "name": "xtables-lock"
                    },
                    {
                        "hostPath": {
                            "path": "/lib/modules",
                            "type": ""
                        },
                        "name": "lib-modules"
                    },
                    {
                        "name": "kube-api-access-7mh48",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:14Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-27T22:20:19Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:28Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:28Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-27T22:20:19Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://5da126e0d79bc11a652f77cfdf1114827f2feb2d40d3b47b34ae854c0135b63d",
                        "image": "registry.k8s.io/kube-proxy:v1.32.5",
                        "imageID": "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://ca8c0131280a3bec9b21086c078ae8f899daee386707aa80a9238824579c1175",
                                "exitCode": 255,
                                "finishedAt": "2025-05-28T11:21:29Z",
                                "reason": "Unknown",
                                "startedAt": "2025-05-27T22:20:20Z"
                            }
                        },
                        "name": "kube-proxy",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:22:27Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/var/lib/kube-proxy",
                                "name": "kube-proxy"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-7mh48",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2025-05-27T22:20:19Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-28T11:53:46Z",
                "generateName": "kube-proxy-",
                "labels": {
                    "controller-revision-hash": "5987677dc7",
                    "k8s-app": "kube-proxy",
                    "pod-template-generation": "1"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:controller-revision-hash": {},
                                    "f:k8s-app": {},
                                    "f:pod-template-generation": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"e4c54b84-9c3a-4836-87fe-234a760a9905\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:nodeAffinity": {
                                        ".": {},
                                        "f:requiredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"kube-proxy\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"NODE_NAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {},
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/lib/modules\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/var/lib/kube-proxy\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeSelector": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {},
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"kube-proxy\"}": {
                                        ".": {},
                                        "f:configMap": {
                                            ".": {},
                                            "f:defaultMode": {},
                                            "f:name": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"lib-modules\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"xtables-lock\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.5\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:54:09Z"
                    }
                ],
                "name": "kube-proxy-mw9t8",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "kube-proxy",
                        "uid": "e4c54b84-9c3a-4836-87fe-234a760a9905"
                    }
                ],
                "resourceVersion": "11249",
                "uid": "9b7e662b-dfc1-4d32-be40-6a492890eb4a"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "k8s-worker-01"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "command": [
                            "/usr/local/bin/kube-proxy",
                            "--config=/var/lib/kube-proxy/config.conf",
                            "--hostname-override=$(NODE_NAME)"
                        ],
                        "env": [
                            {
                                "name": "NODE_NAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            }
                        ],
                        "image": "registry.k8s.io/kube-proxy:v1.32.5",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "kube-proxy",
                        "resources": {},
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/var/lib/kube-proxy",
                                "name": "kube-proxy"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-x4q8b",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-worker-01",
                "nodeSelector": {
                    "kubernetes.io/os": "linux"
                },
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {},
                "serviceAccount": "kube-proxy",
                "serviceAccountName": "kube-proxy",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "configMap": {
                            "defaultMode": 420,
                            "name": "kube-proxy"
                        },
                        "name": "kube-proxy"
                    },
                    {
                        "hostPath": {
                            "path": "/run/xtables.lock",
                            "type": "FileOrCreate"
                        },
                        "name": "xtables-lock"
                    },
                    {
                        "hostPath": {
                            "path": "/lib/modules",
                            "type": ""
                        },
                        "name": "lib-modules"
                    },
                    {
                        "name": "kube-api-access-x4q8b",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:54:09Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:54:09Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:54:09Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://9e06c92be745e678d78143e3da0d4c4b1aca81a703a3101b86435ae34c013fca",
                        "image": "registry.k8s.io/kube-proxy:v1.32.5",
                        "imageID": "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                        "lastState": {},
                        "name": "kube-proxy",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:54:09Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/var/lib/kube-proxy",
                                "name": "kube-proxy"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-x4q8b",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.5",
                "hostIPs": [
                    {
                        "ip": "192.168.57.5"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.5",
                "podIPs": [
                    {
                        "ip": "192.168.57.5"
                    }
                ],
                "qosClass": "BestEffort",
                "startTime": "2025-05-28T11:53:46Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "annotations": {
                    "kubernetes.io/config.hash": "c3d12676caaf8c15c958ff27e96e9c89",
                    "kubernetes.io/config.mirror": "c3d12676caaf8c15c958ff27e96e9c89",
                    "kubernetes.io/config.seen": "2025-05-27T22:19:31.674360279Z",
                    "kubernetes.io/config.source": "file"
                },
                "creationTimestamp": "2025-05-27T22:20:11Z",
                "labels": {
                    "component": "kube-scheduler",
                    "tier": "control-plane"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:kubernetes.io/config.hash": {},
                                    "f:kubernetes.io/config.mirror": {},
                                    "f:kubernetes.io/config.seen": {},
                                    "f:kubernetes.io/config.source": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:component": {},
                                    "f:tier": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"261b64aa-acc9-4ade-b1e4-2f5aebf9ecff\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:containers": {
                                    "k:{\"name\":\"kube-scheduler\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:livenessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:name": {},
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:startupProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:initialDelaySeconds": {},
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/etc/kubernetes/scheduler.conf\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:nodeName": {},
                                "f:priority": {},
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seccompProfile": {
                                        ".": {},
                                        "f:type": {}
                                    }
                                },
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"kubeconfig\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:11Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    ".": {},
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodScheduled\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T11:22:40Z"
                    }
                ],
                "name": "kube-scheduler-k8s-master-01",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "v1",
                        "controller": true,
                        "kind": "Node",
                        "name": "k8s-master-01",
                        "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
                    }
                ],
                "resourceVersion": "8758",
                "uid": "beeb024c-c2de-4dd2-a5c6-e35da6c9458b"
            },
            "spec": {
                "containers": [
                    {
                        "command": [
                            "kube-scheduler",
                            "--authentication-kubeconfig=/etc/kubernetes/scheduler.conf",
                            "--authorization-kubeconfig=/etc/kubernetes/scheduler.conf",
                            "--bind-address=127.0.0.1",
                            "--kubeconfig=/etc/kubernetes/scheduler.conf",
                            "--leader-elect=true"
                        ],
                        "image": "registry.k8s.io/kube-scheduler:v1.32.5",
                        "imagePullPolicy": "IfNotPresent",
                        "livenessProbe": {
                            "failureThreshold": 8,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/livez",
                                "port": 10259,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "name": "kube-scheduler",
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/readyz",
                                "port": 10259,
                                "scheme": "HTTPS"
                            },
                            "periodSeconds": 1,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "resources": {
                            "requests": {
                                "cpu": "100m"
                            }
                        },
                        "startupProbe": {
                            "failureThreshold": 24,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/livez",
                                "port": 10259,
                                "scheme": "HTTPS"
                            },
                            "initialDelaySeconds": 10,
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 15
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/etc/kubernetes/scheduler.conf",
                                "name": "kubeconfig",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirst",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "nodeName": "k8s-master-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seccompProfile": {
                        "type": "RuntimeDefault"
                    }
                },
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/etc/kubernetes/scheduler.conf",
                            "type": "FileOrCreate"
                        },
                        "name": "kubeconfig"
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:45Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:14Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:22:14Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T11:21:40Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://5decdc5035faf735fecc925e21609fcc81b0a7924f169bf9c93a8966f73b3e81",
                        "image": "registry.k8s.io/kube-scheduler:v1.32.5",
                        "imageID": "registry.k8s.io/kube-scheduler@sha256:f0f39d8b9808c407cacb3a46a5a9ce4d4a4a7cf3b674ba4bd221f5bc90051d2a",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://34731a08a766cc7aa90c50946438e176c9003727f4e1bcb7b1751e04e0462729",
                                "exitCode": 255,
                                "finishedAt": "2025-05-28T11:21:29Z",
                                "reason": "Unknown",
                                "startedAt": "2025-05-27T22:19:41Z"
                            }
                        },
                        "name": "kube-scheduler",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T11:21:45Z"
                            }
                        }
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T11:21:40Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-28T12:49:23Z",
                "generateName": "weave-net-",
                "labels": {
                    "controller-revision-hash": "78c59fdb7",
                    "name": "weave-net",
                    "pod-template-generation": "1"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:controller-revision-hash": {},
                                    "f:name": {},
                                    "f:pod-template-generation": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"fa205e0e-66b2-4941-b17b-32b6fd8a3f42\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:nodeAffinity": {
                                        ".": {},
                                        "f:requiredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"weave\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"CHECKPOINT_DISABLE\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:value": {}
                                            },
                                            "k:{\"name\":\"HOSTNAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            },
                                            "k:{\"name\":\"INIT_CONTAINER\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:value": {}
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/host/etc/machine-id\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/host/var/lib/dbus\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/weavedb\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    },
                                    "k:{\"name\":\"weave-npc\"}": {
                                        ".": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"HOSTNAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:initContainers": {
                                    ".": {},
                                    "k:{\"name\":\"weave-init\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {},
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/host/etc\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/host/home\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/host/opt\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/lib/modules\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seLinuxOptions": {}
                                },
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"cni-bin\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-bin2\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-conf\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-machine-id\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"dbus\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"lib-modules\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"weavedb\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"xtables-lock\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T12:49:23Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:initContainerStatuses": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.3\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:58Z"
                    }
                ],
                "name": "weave-net-s8bcf",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "weave-net",
                        "uid": "fa205e0e-66b2-4941-b17b-32b6fd8a3f42"
                    }
                ],
                "resourceVersion": "16157",
                "uid": "02275f7f-5c87-466e-81b5-d89db203099d"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "k8s-master-01"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "command": [
                            "/home/weave/launch.sh"
                        ],
                        "env": [
                            {
                                "name": "INIT_CONTAINER",
                                "value": "true"
                            },
                            {
                                "name": "HOSTNAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            },
                            {
                                "name": "CHECKPOINT_DISABLE",
                                "value": "1"
                            }
                        ],
                        "image": "rajchaudhuri/weave-kube:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave",
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/status",
                                "port": 6784,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m"
                            }
                        },
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/weavedb",
                                "name": "weavedb"
                            },
                            {
                                "mountPath": "/host/var/lib/dbus",
                                "name": "dbus",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/host/etc/machine-id",
                                "name": "cni-machine-id",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true
                            }
                        ]
                    },
                    {
                        "env": [
                            {
                                "name": "HOSTNAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            }
                        ],
                        "image": "rajchaudhuri/weave-npc:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave-npc",
                        "resources": {
                            "requests": {
                                "cpu": "50m"
                            }
                        },
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirstWithHostNet",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "initContainers": [
                    {
                        "command": [
                            "/home/weave/init.sh"
                        ],
                        "image": "rajchaudhuri/weave-kube:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave-init",
                        "resources": {},
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/host/opt",
                                "name": "cni-bin"
                            },
                            {
                                "mountPath": "/host/home",
                                "name": "cni-bin2"
                            },
                            {
                                "mountPath": "/host/etc",
                                "name": "cni-conf"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "nodeName": "k8s-master-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seLinuxOptions": {}
                },
                "serviceAccount": "weave-net",
                "serviceAccountName": "weave-net",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoSchedule",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/var/lib/weave",
                            "type": ""
                        },
                        "name": "weavedb"
                    },
                    {
                        "hostPath": {
                            "path": "/opt",
                            "type": ""
                        },
                        "name": "cni-bin"
                    },
                    {
                        "hostPath": {
                            "path": "/home",
                            "type": ""
                        },
                        "name": "cni-bin2"
                    },
                    {
                        "hostPath": {
                            "path": "/etc",
                            "type": ""
                        },
                        "name": "cni-conf"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/machine-id",
                            "type": ""
                        },
                        "name": "cni-machine-id"
                    },
                    {
                        "hostPath": {
                            "path": "/var/lib/dbus",
                            "type": ""
                        },
                        "name": "dbus"
                    },
                    {
                        "hostPath": {
                            "path": "/lib/modules",
                            "type": ""
                        },
                        "name": "lib-modules"
                    },
                    {
                        "hostPath": {
                            "path": "/run/xtables.lock",
                            "type": "FileOrCreate"
                        },
                        "name": "xtables-lock"
                    },
                    {
                        "name": "kube-api-access-s6zh6",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:26Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:29Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:58Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:58Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:23Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://45ad482f90a8b4a0dedd9a510a57e181c968faac63304fb8df2cd53221c7e9c0",
                        "image": "docker.io/rajchaudhuri/weave-kube:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://31f0319cc7652b38fab25d46ed3ffd7550db3dcfa40f43635ae7641c7fe5dcb4",
                                "exitCode": 1,
                                "finishedAt": "2025-05-28T12:49:33Z",
                                "reason": "Error",
                                "startedAt": "2025-05-28T12:49:32Z"
                            }
                        },
                        "name": "weave",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:45Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/weavedb",
                                "name": "weavedb"
                            },
                            {
                                "mountPath": "/host/var/lib/dbus",
                                "name": "dbus",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/host/etc/machine-id",
                                "name": "cni-machine-id",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    },
                    {
                        "containerID": "containerd://5771e7ef3c5d149c90211773c5dc3531e4e6a293eb5a48cc000be841465bceb7",
                        "image": "docker.io/rajchaudhuri/weave-npc:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                        "lastState": {},
                        "name": "weave-npc",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:44Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.3",
                "hostIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "initContainerStatuses": [
                    {
                        "containerID": "containerd://614d73ef9ed78a401d54a68b853876caa297c0b320ae944d420e9ea98fb7f325",
                        "image": "docker.io/rajchaudhuri/weave-kube:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                        "lastState": {},
                        "name": "weave-init",
                        "ready": true,
                        "restartCount": 0,
                        "started": false,
                        "state": {
                            "terminated": {
                                "containerID": "containerd://614d73ef9ed78a401d54a68b853876caa297c0b320ae944d420e9ea98fb7f325",
                                "exitCode": 0,
                                "finishedAt": "2025-05-28T12:49:27Z",
                                "reason": "Completed",
                                "startedAt": "2025-05-28T12:49:25Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/host/opt",
                                "name": "cni-bin"
                            },
                            {
                                "mountPath": "/host/home",
                                "name": "cni-bin2"
                            },
                            {
                                "mountPath": "/host/etc",
                                "name": "cni-conf"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-s6zh6",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.3",
                "podIPs": [
                    {
                        "ip": "192.168.57.3"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T12:49:24Z"
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Pod",
            "metadata": {
                "creationTimestamp": "2025-05-28T12:49:23Z",
                "generateName": "weave-net-",
                "labels": {
                    "controller-revision-hash": "78c59fdb7",
                    "name": "weave-net",
                    "pod-template-generation": "1"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:generateName": {},
                                "f:labels": {
                                    ".": {},
                                    "f:controller-revision-hash": {},
                                    "f:name": {},
                                    "f:pod-template-generation": {}
                                },
                                "f:ownerReferences": {
                                    ".": {},
                                    "k:{\"uid\":\"fa205e0e-66b2-4941-b17b-32b6fd8a3f42\"}": {}
                                }
                            },
                            "f:spec": {
                                "f:affinity": {
                                    ".": {},
                                    "f:nodeAffinity": {
                                        ".": {},
                                        "f:requiredDuringSchedulingIgnoredDuringExecution": {}
                                    }
                                },
                                "f:containers": {
                                    "k:{\"name\":\"weave\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"CHECKPOINT_DISABLE\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:value": {}
                                            },
                                            "k:{\"name\":\"HOSTNAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            },
                                            "k:{\"name\":\"INIT_CONTAINER\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:value": {}
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:readinessProbe": {
                                            ".": {},
                                            "f:failureThreshold": {},
                                            "f:httpGet": {
                                                ".": {},
                                                "f:host": {},
                                                "f:path": {},
                                                "f:port": {},
                                                "f:scheme": {}
                                            },
                                            "f:periodSeconds": {},
                                            "f:successThreshold": {},
                                            "f:timeoutSeconds": {}
                                        },
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/host/etc/machine-id\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/host/var/lib/dbus\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {},
                                                "f:readOnly": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/weavedb\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    },
                                    "k:{\"name\":\"weave-npc\"}": {
                                        ".": {},
                                        "f:env": {
                                            ".": {},
                                            "k:{\"name\":\"HOSTNAME\"}": {
                                                ".": {},
                                                "f:name": {},
                                                "f:valueFrom": {
                                                    ".": {},
                                                    "f:fieldRef": {}
                                                }
                                            }
                                        },
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {
                                            ".": {},
                                            "f:requests": {
                                                ".": {},
                                                "f:cpu": {}
                                            }
                                        },
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:dnsPolicy": {},
                                "f:enableServiceLinks": {},
                                "f:hostNetwork": {},
                                "f:initContainers": {
                                    ".": {},
                                    "k:{\"name\":\"weave-init\"}": {
                                        ".": {},
                                        "f:command": {},
                                        "f:image": {},
                                        "f:imagePullPolicy": {},
                                        "f:name": {},
                                        "f:resources": {},
                                        "f:securityContext": {
                                            ".": {},
                                            "f:privileged": {}
                                        },
                                        "f:terminationMessagePath": {},
                                        "f:terminationMessagePolicy": {},
                                        "f:volumeMounts": {
                                            ".": {},
                                            "k:{\"mountPath\":\"/host/etc\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/host/home\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/host/opt\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/lib/modules\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            },
                                            "k:{\"mountPath\":\"/run/xtables.lock\"}": {
                                                ".": {},
                                                "f:mountPath": {},
                                                "f:name": {}
                                            }
                                        }
                                    }
                                },
                                "f:priorityClassName": {},
                                "f:restartPolicy": {},
                                "f:schedulerName": {},
                                "f:securityContext": {
                                    ".": {},
                                    "f:seLinuxOptions": {}
                                },
                                "f:serviceAccount": {},
                                "f:serviceAccountName": {},
                                "f:terminationGracePeriodSeconds": {},
                                "f:tolerations": {},
                                "f:volumes": {
                                    ".": {},
                                    "k:{\"name\":\"cni-bin\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-bin2\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-conf\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"cni-machine-id\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"dbus\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"lib-modules\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"weavedb\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    },
                                    "k:{\"name\":\"xtables-lock\"}": {
                                        ".": {},
                                        "f:hostPath": {
                                            ".": {},
                                            "f:path": {},
                                            "f:type": {}
                                        },
                                        "f:name": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T12:49:23Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"ContainersReady\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Initialized\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"PodReadyToStartContainers\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        ".": {},
                                        "f:lastProbeTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                },
                                "f:containerStatuses": {},
                                "f:hostIP": {},
                                "f:hostIPs": {},
                                "f:initContainerStatuses": {},
                                "f:phase": {},
                                "f:podIP": {},
                                "f:podIPs": {
                                    ".": {},
                                    "k:{\"ip\":\"192.168.57.5\"}": {
                                        ".": {},
                                        "f:ip": {}
                                    }
                                },
                                "f:startTime": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:53Z"
                    }
                ],
                "name": "weave-net-wbvmj",
                "namespace": "kube-system",
                "ownerReferences": [
                    {
                        "apiVersion": "apps/v1",
                        "blockOwnerDeletion": true,
                        "controller": true,
                        "kind": "DaemonSet",
                        "name": "weave-net",
                        "uid": "fa205e0e-66b2-4941-b17b-32b6fd8a3f42"
                    }
                ],
                "resourceVersion": "16141",
                "uid": "e7c15493-eb05-43f7-bffd-aab5410be619"
            },
            "spec": {
                "affinity": {
                    "nodeAffinity": {
                        "requiredDuringSchedulingIgnoredDuringExecution": {
                            "nodeSelectorTerms": [
                                {
                                    "matchFields": [
                                        {
                                            "key": "metadata.name",
                                            "operator": "In",
                                            "values": [
                                                "k8s-worker-01"
                                            ]
                                        }
                                    ]
                                }
                            ]
                        }
                    }
                },
                "containers": [
                    {
                        "command": [
                            "/home/weave/launch.sh"
                        ],
                        "env": [
                            {
                                "name": "INIT_CONTAINER",
                                "value": "true"
                            },
                            {
                                "name": "HOSTNAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            },
                            {
                                "name": "CHECKPOINT_DISABLE",
                                "value": "1"
                            }
                        ],
                        "image": "rajchaudhuri/weave-kube:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave",
                        "readinessProbe": {
                            "failureThreshold": 3,
                            "httpGet": {
                                "host": "127.0.0.1",
                                "path": "/status",
                                "port": 6784,
                                "scheme": "HTTP"
                            },
                            "periodSeconds": 10,
                            "successThreshold": 1,
                            "timeoutSeconds": 1
                        },
                        "resources": {
                            "requests": {
                                "cpu": "50m"
                            }
                        },
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/weavedb",
                                "name": "weavedb"
                            },
                            {
                                "mountPath": "/host/var/lib/dbus",
                                "name": "dbus",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/host/etc/machine-id",
                                "name": "cni-machine-id",
                                "readOnly": true
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true
                            }
                        ]
                    },
                    {
                        "env": [
                            {
                                "name": "HOSTNAME",
                                "valueFrom": {
                                    "fieldRef": {
                                        "apiVersion": "v1",
                                        "fieldPath": "spec.nodeName"
                                    }
                                }
                            }
                        ],
                        "image": "rajchaudhuri/weave-npc:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave-npc",
                        "resources": {
                            "requests": {
                                "cpu": "50m"
                            }
                        },
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "dnsPolicy": "ClusterFirstWithHostNet",
                "enableServiceLinks": true,
                "hostNetwork": true,
                "initContainers": [
                    {
                        "command": [
                            "/home/weave/init.sh"
                        ],
                        "image": "rajchaudhuri/weave-kube:2.9.0",
                        "imagePullPolicy": "IfNotPresent",
                        "name": "weave-init",
                        "resources": {},
                        "securityContext": {
                            "privileged": true
                        },
                        "terminationMessagePath": "/dev/termination-log",
                        "terminationMessagePolicy": "File",
                        "volumeMounts": [
                            {
                                "mountPath": "/host/opt",
                                "name": "cni-bin"
                            },
                            {
                                "mountPath": "/host/home",
                                "name": "cni-bin2"
                            },
                            {
                                "mountPath": "/host/etc",
                                "name": "cni-conf"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true
                            }
                        ]
                    }
                ],
                "nodeName": "k8s-worker-01",
                "preemptionPolicy": "PreemptLowerPriority",
                "priority": 2000001000,
                "priorityClassName": "system-node-critical",
                "restartPolicy": "Always",
                "schedulerName": "default-scheduler",
                "securityContext": {
                    "seLinuxOptions": {}
                },
                "serviceAccount": "weave-net",
                "serviceAccountName": "weave-net",
                "terminationGracePeriodSeconds": 30,
                "tolerations": [
                    {
                        "effect": "NoSchedule",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/not-ready",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoExecute",
                        "key": "node.kubernetes.io/unreachable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/disk-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/memory-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/pid-pressure",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/unschedulable",
                        "operator": "Exists"
                    },
                    {
                        "effect": "NoSchedule",
                        "key": "node.kubernetes.io/network-unavailable",
                        "operator": "Exists"
                    }
                ],
                "volumes": [
                    {
                        "hostPath": {
                            "path": "/var/lib/weave",
                            "type": ""
                        },
                        "name": "weavedb"
                    },
                    {
                        "hostPath": {
                            "path": "/opt",
                            "type": ""
                        },
                        "name": "cni-bin"
                    },
                    {
                        "hostPath": {
                            "path": "/home",
                            "type": ""
                        },
                        "name": "cni-bin2"
                    },
                    {
                        "hostPath": {
                            "path": "/etc",
                            "type": ""
                        },
                        "name": "cni-conf"
                    },
                    {
                        "hostPath": {
                            "path": "/etc/machine-id",
                            "type": ""
                        },
                        "name": "cni-machine-id"
                    },
                    {
                        "hostPath": {
                            "path": "/var/lib/dbus",
                            "type": ""
                        },
                        "name": "dbus"
                    },
                    {
                        "hostPath": {
                            "path": "/lib/modules",
                            "type": ""
                        },
                        "name": "lib-modules"
                    },
                    {
                        "hostPath": {
                            "path": "/run/xtables.lock",
                            "type": "FileOrCreate"
                        },
                        "name": "xtables-lock"
                    },
                    {
                        "name": "kube-api-access-rgpdw",
                        "projected": {
                            "defaultMode": 420,
                            "sources": [
                                {
                                    "serviceAccountToken": {
                                        "expirationSeconds": 3607,
                                        "path": "token"
                                    }
                                },
                                {
                                    "configMap": {
                                        "items": [
                                            {
                                                "key": "ca.crt",
                                                "path": "ca.crt"
                                            }
                                        ],
                                        "name": "kube-root-ca.crt"
                                    }
                                },
                                {
                                    "downwardAPI": {
                                        "items": [
                                            {
                                                "fieldRef": {
                                                    "apiVersion": "v1",
                                                    "fieldPath": "metadata.namespace"
                                                },
                                                "path": "namespace"
                                            }
                                        ]
                                    }
                                }
                            ]
                        }
                    }
                ]
            },
            "status": {
                "conditions": [
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:26Z",
                        "status": "True",
                        "type": "PodReadyToStartContainers"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:28Z",
                        "status": "True",
                        "type": "Initialized"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:53Z",
                        "status": "True",
                        "type": "Ready"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:53Z",
                        "status": "True",
                        "type": "ContainersReady"
                    },
                    {
                        "lastProbeTime": null,
                        "lastTransitionTime": "2025-05-28T12:49:24Z",
                        "status": "True",
                        "type": "PodScheduled"
                    }
                ],
                "containerStatuses": [
                    {
                        "containerID": "containerd://254180d4ab5dc71db93e61ffbf333c7219fa97185645216ded422f7de78fde49",
                        "image": "docker.io/rajchaudhuri/weave-kube:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                        "lastState": {
                            "terminated": {
                                "containerID": "containerd://5abdc7ee8e73228067700d8914a227a0dd03cf842d86ac4ac25dc1ef9a702a5b",
                                "exitCode": 1,
                                "finishedAt": "2025-05-28T12:49:29Z",
                                "reason": "Error",
                                "startedAt": "2025-05-28T12:49:29Z"
                            }
                        },
                        "name": "weave",
                        "ready": true,
                        "restartCount": 1,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:41Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/weavedb",
                                "name": "weavedb"
                            },
                            {
                                "mountPath": "/host/var/lib/dbus",
                                "name": "dbus",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/host/etc/machine-id",
                                "name": "cni-machine-id",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    },
                    {
                        "containerID": "containerd://5c53111fe28237b9543e16695d0054129c0f1ba79a5cb0d37db7155bda81c705",
                        "image": "docker.io/rajchaudhuri/weave-npc:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                        "lastState": {},
                        "name": "weave-npc",
                        "ready": true,
                        "restartCount": 0,
                        "started": true,
                        "state": {
                            "running": {
                                "startedAt": "2025-05-28T12:49:40Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "hostIP": "192.168.57.5",
                "hostIPs": [
                    {
                        "ip": "192.168.57.5"
                    }
                ],
                "initContainerStatuses": [
                    {
                        "containerID": "containerd://59525ef6f3b20d2ce8d64c3ca0e47209bd7804df132e649e6a622dbc196a5b56",
                        "image": "docker.io/rajchaudhuri/weave-kube:2.9.0",
                        "imageID": "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                        "lastState": {},
                        "name": "weave-init",
                        "ready": true,
                        "restartCount": 0,
                        "started": false,
                        "state": {
                            "terminated": {
                                "containerID": "containerd://59525ef6f3b20d2ce8d64c3ca0e47209bd7804df132e649e6a622dbc196a5b56",
                                "exitCode": 0,
                                "finishedAt": "2025-05-28T12:49:26Z",
                                "reason": "Completed",
                                "startedAt": "2025-05-28T12:49:25Z"
                            }
                        },
                        "volumeMounts": [
                            {
                                "mountPath": "/host/opt",
                                "name": "cni-bin"
                            },
                            {
                                "mountPath": "/host/home",
                                "name": "cni-bin2"
                            },
                            {
                                "mountPath": "/host/etc",
                                "name": "cni-conf"
                            },
                            {
                                "mountPath": "/lib/modules",
                                "name": "lib-modules"
                            },
                            {
                                "mountPath": "/run/xtables.lock",
                                "name": "xtables-lock"
                            },
                            {
                                "mountPath": "/var/run/secrets/kubernetes.io/serviceaccount",
                                "name": "kube-api-access-rgpdw",
                                "readOnly": true,
                                "recursiveReadOnly": "Disabled"
                            }
                        ]
                    }
                ],
                "phase": "Running",
                "podIP": "192.168.57.5",
                "podIPs": [
                    {
                        "ip": "192.168.57.5"
                    }
                ],
                "qosClass": "Burstable",
                "startTime": "2025-05-28T12:49:24Z"
            }
        }
    ]
}
2025-05-28 16:01:08,042 p=9412 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 16:01:08,042 p=9412 u=root n=ansible INFO| master-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 16:01:08,043 p=9412 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 16:03:51,712 p=9619 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 16:03:52,003 p=9619 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 16:03:52,055 p=9619 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 16:03:57,595 p=9619 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:03:57,596 p=9619 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 16:03:57,979 p=9619 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:03:57,980 p=9619 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:03:58,020 p=9619 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-28 16:04:00,961 p=9619 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 16:04:00,963 p=9619 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 16:04:01,250 p=9619 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:04:01,296 p=9619 u=root n=ansible INFO| TASK [cluster_status : debug] *******************************************************************************************************
2025-05-28 16:04:01,419 p=9619 u=root n=ansible INFO| ok: [master-01] => {
    "nodes.resources": [
        {
            "apiVersion": "v1",
            "kind": "Node",
            "metadata": {
                "annotations": {
                    "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                    "node.alpha.kubernetes.io/ttl": "0",
                    "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                },
                "creationTimestamp": "2025-05-27T22:20:08Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-master-01",
                    "kubernetes.io/os": "linux",
                    "node-role.kubernetes.io/control-plane": "",
                    "node.kubernetes.io/exclude-from-external-load-balancers": ""
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:beta.kubernetes.io/arch": {},
                                    "f:beta.kubernetes.io/os": {},
                                    "f:kubernetes.io/arch": {},
                                    "f:kubernetes.io/hostname": {},
                                    "f:kubernetes.io/os": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:07Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                },
                                "f:labels": {
                                    "f:node-role.kubernetes.io/control-plane": {},
                                    "f:node.kubernetes.io/exclude-from-external-load-balancers": {}
                                }
                            }
                        },
                        "manager": "kubeadm",
                        "operation": "Update",
                        "time": "2025-05-27T22:20:12Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:node.alpha.kubernetes.io/ttl": {}
                                }
                            },
                            "f:spec": {
                                "f:taints": {}
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T12:36:01Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"NetworkUnavailable\"}": {
                                        ".": {},
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-utils",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:52Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:allocatable": {
                                    "f:memory": {}
                                },
                                "f:capacity": {
                                    "f:memory": {}
                                },
                                "f:conditions": {
                                    "k:{\"type\":\"DiskPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"MemoryPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"PIDPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {}
                                    }
                                },
                                "f:images": {},
                                "f:nodeInfo": {
                                    "f:bootID": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T13:00:30Z"
                    }
                ],
                "name": "k8s-master-01",
                "resourceVersion": "17054",
                "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
            },
            "spec": {
                "taints": [
                    {
                        "effect": "NoSchedule",
                        "key": "node-role.kubernetes.io/control-plane"
                    }
                ]
            },
            "status": {
                "addresses": [
                    {
                        "address": "192.168.57.3",
                        "type": "InternalIP"
                    },
                    {
                        "address": "k8s-master-01",
                        "type": "Hostname"
                    }
                ],
                "allocatable": {
                    "cpu": "2",
                    "ephemeral-storage": "10836873199",
                    "hugepages-2Mi": "0",
                    "memory": "1908476Ki",
                    "pods": "110"
                },
                "capacity": {
                    "cpu": "2",
                    "ephemeral-storage": "11758760Ki",
                    "hugepages-2Mi": "0",
                    "memory": "2010876Ki",
                    "pods": "110"
                },
                "conditions": [
                    {
                        "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                        "lastTransitionTime": "2025-05-28T12:49:52Z",
                        "message": "Weave pod has set this",
                        "reason": "WeaveIsUp",
                        "status": "False",
                        "type": "NetworkUnavailable"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has sufficient memory available",
                        "reason": "KubeletHasSufficientMemory",
                        "status": "False",
                        "type": "MemoryPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has no disk pressure",
                        "reason": "KubeletHasNoDiskPressure",
                        "status": "False",
                        "type": "DiskPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-27T22:20:05Z",
                        "message": "kubelet has sufficient PID available",
                        "reason": "KubeletHasSufficientPID",
                        "status": "False",
                        "type": "PIDPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:30Z",
                        "lastTransitionTime": "2025-05-28T12:35:57Z",
                        "message": "kubelet is posting ready status",
                        "reason": "KubeletReady",
                        "status": "True",
                        "type": "Ready"
                    }
                ],
                "daemonEndpoints": {
                    "kubeletEndpoint": {
                        "Port": 10250
                    }
                },
                "images": [
                    {
                        "names": [
                            "registry.k8s.io/etcd@sha256:c6a9d11cc5c04b114ccdef39a9265eeef818e3d02f5359be035ae784097fdec5",
                            "registry.k8s.io/etcd:3.5.16-0"
                        ],
                        "sizeBytes": 57680541
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                            "docker.io/rajchaudhuri/weave-kube:2.9.0"
                        ],
                        "sizeBytes": 37163311
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                            "registry.k8s.io/kube-proxy:v1.32.5"
                        ],
                        "sizeBytes": 30891891
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-apiserver@sha256:0bee1bf751fe06009678c0cde7545443ba3a8d2edf71cea4c69cbb5774b9bf47",
                            "registry.k8s.io/kube-apiserver:v1.32.5"
                        ],
                        "sizeBytes": 28794611
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-controller-manager@sha256:79bcf2f5e614c336c02dcea9dfcdf485d7297aed6a21239a99c87f7164f9baca",
                            "registry.k8s.io/kube-controller-manager:v1.32.5"
                        ],
                        "sizeBytes": 26384363
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-scheduler@sha256:f0f39d8b9808c407cacb3a46a5a9ce4d4a4a7cf3b674ba4bd221f5bc90051d2a",
                            "registry.k8s.io/kube-scheduler:v1.32.5"
                        ],
                        "sizeBytes": 20777921
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                            "docker.io/rajchaudhuri/weave-npc:2.9.0"
                        ],
                        "sizeBytes": 18834204
                    },
                    {
                        "names": [
                            "registry.k8s.io/coredns/coredns@sha256:9caabbf6238b189a65d0d6e6ac138de60d6a1c419e5a341fbbb7c78382559c6e",
                            "registry.k8s.io/coredns/coredns:v1.11.3"
                        ],
                        "sizeBytes": 18562039
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a",
                            "registry.k8s.io/pause:3.10"
                        ],
                        "sizeBytes": 320368
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                            "registry.k8s.io/pause:3.8"
                        ],
                        "sizeBytes": 311286
                    }
                ],
                "nodeInfo": {
                    "architecture": "amd64",
                    "bootID": "b2d9d6b0-d348-4135-8d11-0229e84037fa",
                    "containerRuntimeVersion": "containerd://1.7.27",
                    "kernelVersion": "5.15.0-140-generic",
                    "kubeProxyVersion": "v1.32.5",
                    "kubeletVersion": "v1.32.5",
                    "machineID": "61af482aeb01497cabf71b9509d80e9a",
                    "operatingSystem": "linux",
                    "osImage": "Ubuntu 22.04.5 LTS",
                    "systemUUID": "70b18ffc-8d96-a04a-b976-e3e9849d9333"
                }
            }
        },
        {
            "apiVersion": "v1",
            "kind": "Node",
            "metadata": {
                "annotations": {
                    "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                    "node.alpha.kubernetes.io/ttl": "0",
                    "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                },
                "creationTimestamp": "2025-05-28T11:53:46Z",
                "labels": {
                    "beta.kubernetes.io/arch": "amd64",
                    "beta.kubernetes.io/os": "linux",
                    "kubernetes.io/arch": "amd64",
                    "kubernetes.io/hostname": "k8s-worker-01",
                    "kubernetes.io/os": "linux"
                },
                "managedFields": [
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:node.alpha.kubernetes.io/ttl": {}
                                }
                            }
                        },
                        "manager": "kube-controller-manager",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                }
                            }
                        },
                        "manager": "kubeadm",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:metadata": {
                                "f:annotations": {
                                    ".": {},
                                    "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                },
                                "f:labels": {
                                    ".": {},
                                    "f:beta.kubernetes.io/arch": {},
                                    "f:beta.kubernetes.io/os": {},
                                    "f:kubernetes.io/arch": {},
                                    "f:kubernetes.io/hostname": {},
                                    "f:kubernetes.io/os": {}
                                }
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "time": "2025-05-28T11:53:46Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"NetworkUnavailable\"}": {
                                        ".": {},
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {},
                                        "f:type": {}
                                    }
                                }
                            }
                        },
                        "manager": "kube-utils",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T12:49:52Z"
                    },
                    {
                        "apiVersion": "v1",
                        "fieldsType": "FieldsV1",
                        "fieldsV1": {
                            "f:status": {
                                "f:conditions": {
                                    "k:{\"type\":\"DiskPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"MemoryPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"PIDPressure\"}": {
                                        "f:lastHeartbeatTime": {}
                                    },
                                    "k:{\"type\":\"Ready\"}": {
                                        "f:lastHeartbeatTime": {},
                                        "f:lastTransitionTime": {},
                                        "f:message": {},
                                        "f:reason": {},
                                        "f:status": {}
                                    }
                                },
                                "f:images": {}
                            }
                        },
                        "manager": "kubelet",
                        "operation": "Update",
                        "subresource": "status",
                        "time": "2025-05-28T13:00:05Z"
                    }
                ],
                "name": "k8s-worker-01",
                "resourceVersion": "17021",
                "uid": "3a8c1725-8d5f-4a8d-8d12-c7de58b1d1a4"
            },
            "spec": {},
            "status": {
                "addresses": [
                    {
                        "address": "192.168.57.5",
                        "type": "InternalIP"
                    },
                    {
                        "address": "k8s-worker-01",
                        "type": "Hostname"
                    }
                ],
                "allocatable": {
                    "cpu": "2",
                    "ephemeral-storage": "10836873199",
                    "hugepages-2Mi": "0",
                    "memory": "1908476Ki",
                    "pods": "110"
                },
                "capacity": {
                    "cpu": "2",
                    "ephemeral-storage": "11758760Ki",
                    "hugepages-2Mi": "0",
                    "memory": "2010876Ki",
                    "pods": "110"
                },
                "conditions": [
                    {
                        "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                        "lastTransitionTime": "2025-05-28T12:49:52Z",
                        "message": "Weave pod has set this",
                        "reason": "WeaveIsUp",
                        "status": "False",
                        "type": "NetworkUnavailable"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has sufficient memory available",
                        "reason": "KubeletHasSufficientMemory",
                        "status": "False",
                        "type": "MemoryPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has no disk pressure",
                        "reason": "KubeletHasNoDiskPressure",
                        "status": "False",
                        "type": "DiskPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T11:53:46Z",
                        "message": "kubelet has sufficient PID available",
                        "reason": "KubeletHasSufficientPID",
                        "status": "False",
                        "type": "PIDPressure"
                    },
                    {
                        "lastHeartbeatTime": "2025-05-28T13:00:05Z",
                        "lastTransitionTime": "2025-05-28T12:36:06Z",
                        "message": "kubelet is posting ready status",
                        "reason": "KubeletReady",
                        "status": "True",
                        "type": "Ready"
                    }
                ],
                "daemonEndpoints": {
                    "kubeletEndpoint": {
                        "Port": 10250
                    }
                },
                "images": [
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                            "docker.io/rajchaudhuri/weave-kube:2.9.0"
                        ],
                        "sizeBytes": 37163311
                    },
                    {
                        "names": [
                            "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                            "registry.k8s.io/kube-proxy:v1.32.5"
                        ],
                        "sizeBytes": 30891891
                    },
                    {
                        "names": [
                            "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                            "docker.io/rajchaudhuri/weave-npc:2.9.0"
                        ],
                        "sizeBytes": 18834204
                    },
                    {
                        "names": [
                            "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                            "registry.k8s.io/pause:3.8"
                        ],
                        "sizeBytes": 311286
                    }
                ],
                "nodeInfo": {
                    "architecture": "amd64",
                    "bootID": "35ce9634-e5e1-42bd-ba6c-146ed9a05af7",
                    "containerRuntimeVersion": "containerd://1.7.27",
                    "kernelVersion": "5.15.0-140-generic",
                    "kubeProxyVersion": "v1.32.5",
                    "kubeletVersion": "v1.32.5",
                    "machineID": "61af482aeb01497cabf71b9509d80e9a",
                    "operatingSystem": "linux",
                    "osImage": "Ubuntu 22.04.5 LTS",
                    "systemUUID": "160ee565-8887-f745-88a2-04510d4f73af"
                }
            }
        }
    ]
}
2025-05-28 16:04:01,460 p=9619 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 16:04:01,460 p=9619 u=root n=ansible INFO| master-01                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 16:04:01,461 p=9619 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 16:07:10,618 p=9737 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 16:07:10,945 p=9737 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 16:07:11,007 p=9737 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 16:07:16,743 p=9737 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:07:16,744 p=9737 u=root n=ansible INFO| ok: [worker-01]
2025-05-28 16:07:16,946 p=9737 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 16:07:16,947 p=9737 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:07:16,995 p=9737 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-28 16:07:20,089 p=9737 u=root n=ansible INFO| An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible_collections.kubernetes.core.plugins.module_utils.k8s.exceptions.CoreException: Could not create API client: Invalid kube-config file. No configuration found.
2025-05-28 16:07:20,090 p=9737 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"changed": false, "msg": "Could not create API client: Invalid kube-config file. No configuration found."}
2025-05-28 16:07:20,270 p=9737 u=root n=ansible INFO| ok: [master-01]
2025-05-28 16:07:20,317 p=9737 u=root n=ansible INFO| TASK [cluster_status : debug] *******************************************************************************************************
2025-05-28 16:07:20,450 p=9737 u=root n=ansible INFO| ok: [master-01] => {
    "nodes_list": {
        "api_found": true,
        "changed": false,
        "failed": false,
        "resources": [
            {
                "apiVersion": "v1",
                "kind": "Node",
                "metadata": {
                    "annotations": {
                        "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                        "node.alpha.kubernetes.io/ttl": "0",
                        "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                    },
                    "creationTimestamp": "2025-05-27T22:20:08Z",
                    "labels": {
                        "beta.kubernetes.io/arch": "amd64",
                        "beta.kubernetes.io/os": "linux",
                        "kubernetes.io/arch": "amd64",
                        "kubernetes.io/hostname": "k8s-master-01",
                        "kubernetes.io/os": "linux",
                        "node-role.kubernetes.io/control-plane": "",
                        "node.kubernetes.io/exclude-from-external-load-balancers": ""
                    },
                    "managedFields": [
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        ".": {},
                                        "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                    },
                                    "f:labels": {
                                        ".": {},
                                        "f:beta.kubernetes.io/arch": {},
                                        "f:beta.kubernetes.io/os": {},
                                        "f:kubernetes.io/arch": {},
                                        "f:kubernetes.io/hostname": {},
                                        "f:kubernetes.io/os": {}
                                    }
                                }
                            },
                            "manager": "kubelet",
                            "operation": "Update",
                            "time": "2025-05-27T22:20:07Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                    },
                                    "f:labels": {
                                        "f:node-role.kubernetes.io/control-plane": {},
                                        "f:node.kubernetes.io/exclude-from-external-load-balancers": {}
                                    }
                                }
                            },
                            "manager": "kubeadm",
                            "operation": "Update",
                            "time": "2025-05-27T22:20:12Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        "f:node.alpha.kubernetes.io/ttl": {}
                                    }
                                },
                                "f:spec": {
                                    "f:taints": {}
                                }
                            },
                            "manager": "kube-controller-manager",
                            "operation": "Update",
                            "time": "2025-05-28T12:36:01Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:status": {
                                    "f:conditions": {
                                        "k:{\"type\":\"NetworkUnavailable\"}": {
                                            ".": {},
                                            "f:lastHeartbeatTime": {},
                                            "f:lastTransitionTime": {},
                                            "f:message": {},
                                            "f:reason": {},
                                            "f:status": {},
                                            "f:type": {}
                                        }
                                    }
                                }
                            },
                            "manager": "kube-utils",
                            "operation": "Update",
                            "subresource": "status",
                            "time": "2025-05-28T12:49:52Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:status": {
                                    "f:allocatable": {
                                        "f:memory": {}
                                    },
                                    "f:capacity": {
                                        "f:memory": {}
                                    },
                                    "f:conditions": {
                                        "k:{\"type\":\"DiskPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"MemoryPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"PIDPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"Ready\"}": {
                                            "f:lastHeartbeatTime": {},
                                            "f:lastTransitionTime": {},
                                            "f:message": {},
                                            "f:reason": {},
                                            "f:status": {}
                                        }
                                    },
                                    "f:images": {},
                                    "f:nodeInfo": {
                                        "f:bootID": {}
                                    }
                                }
                            },
                            "manager": "kubelet",
                            "operation": "Update",
                            "subresource": "status",
                            "time": "2025-05-28T13:05:36Z"
                        }
                    ],
                    "name": "k8s-master-01",
                    "resourceVersion": "17480",
                    "uid": "261b64aa-acc9-4ade-b1e4-2f5aebf9ecff"
                },
                "spec": {
                    "taints": [
                        {
                            "effect": "NoSchedule",
                            "key": "node-role.kubernetes.io/control-plane"
                        }
                    ]
                },
                "status": {
                    "addresses": [
                        {
                            "address": "192.168.57.3",
                            "type": "InternalIP"
                        },
                        {
                            "address": "k8s-master-01",
                            "type": "Hostname"
                        }
                    ],
                    "allocatable": {
                        "cpu": "2",
                        "ephemeral-storage": "10836873199",
                        "hugepages-2Mi": "0",
                        "memory": "1908476Ki",
                        "pods": "110"
                    },
                    "capacity": {
                        "cpu": "2",
                        "ephemeral-storage": "11758760Ki",
                        "hugepages-2Mi": "0",
                        "memory": "2010876Ki",
                        "pods": "110"
                    },
                    "conditions": [
                        {
                            "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                            "lastTransitionTime": "2025-05-28T12:49:52Z",
                            "message": "Weave pod has set this",
                            "reason": "WeaveIsUp",
                            "status": "False",
                            "type": "NetworkUnavailable"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:36Z",
                            "lastTransitionTime": "2025-05-27T22:20:05Z",
                            "message": "kubelet has sufficient memory available",
                            "reason": "KubeletHasSufficientMemory",
                            "status": "False",
                            "type": "MemoryPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:36Z",
                            "lastTransitionTime": "2025-05-27T22:20:05Z",
                            "message": "kubelet has no disk pressure",
                            "reason": "KubeletHasNoDiskPressure",
                            "status": "False",
                            "type": "DiskPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:36Z",
                            "lastTransitionTime": "2025-05-27T22:20:05Z",
                            "message": "kubelet has sufficient PID available",
                            "reason": "KubeletHasSufficientPID",
                            "status": "False",
                            "type": "PIDPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:36Z",
                            "lastTransitionTime": "2025-05-28T12:35:57Z",
                            "message": "kubelet is posting ready status",
                            "reason": "KubeletReady",
                            "status": "True",
                            "type": "Ready"
                        }
                    ],
                    "daemonEndpoints": {
                        "kubeletEndpoint": {
                            "Port": 10250
                        }
                    },
                    "images": [
                        {
                            "names": [
                                "registry.k8s.io/etcd@sha256:c6a9d11cc5c04b114ccdef39a9265eeef818e3d02f5359be035ae784097fdec5",
                                "registry.k8s.io/etcd:3.5.16-0"
                            ],
                            "sizeBytes": 57680541
                        },
                        {
                            "names": [
                                "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                                "docker.io/rajchaudhuri/weave-kube:2.9.0"
                            ],
                            "sizeBytes": 37163311
                        },
                        {
                            "names": [
                                "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                                "registry.k8s.io/kube-proxy:v1.32.5"
                            ],
                            "sizeBytes": 30891891
                        },
                        {
                            "names": [
                                "registry.k8s.io/kube-apiserver@sha256:0bee1bf751fe06009678c0cde7545443ba3a8d2edf71cea4c69cbb5774b9bf47",
                                "registry.k8s.io/kube-apiserver:v1.32.5"
                            ],
                            "sizeBytes": 28794611
                        },
                        {
                            "names": [
                                "registry.k8s.io/kube-controller-manager@sha256:79bcf2f5e614c336c02dcea9dfcdf485d7297aed6a21239a99c87f7164f9baca",
                                "registry.k8s.io/kube-controller-manager:v1.32.5"
                            ],
                            "sizeBytes": 26384363
                        },
                        {
                            "names": [
                                "registry.k8s.io/kube-scheduler@sha256:f0f39d8b9808c407cacb3a46a5a9ce4d4a4a7cf3b674ba4bd221f5bc90051d2a",
                                "registry.k8s.io/kube-scheduler:v1.32.5"
                            ],
                            "sizeBytes": 20777921
                        },
                        {
                            "names": [
                                "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                                "docker.io/rajchaudhuri/weave-npc:2.9.0"
                            ],
                            "sizeBytes": 18834204
                        },
                        {
                            "names": [
                                "registry.k8s.io/coredns/coredns@sha256:9caabbf6238b189a65d0d6e6ac138de60d6a1c419e5a341fbbb7c78382559c6e",
                                "registry.k8s.io/coredns/coredns:v1.11.3"
                            ],
                            "sizeBytes": 18562039
                        },
                        {
                            "names": [
                                "registry.k8s.io/pause@sha256:ee6521f290b2168b6e0935a181d4cff9be1ac3f505666ef0e3c98fae8199917a",
                                "registry.k8s.io/pause:3.10"
                            ],
                            "sizeBytes": 320368
                        },
                        {
                            "names": [
                                "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                                "registry.k8s.io/pause:3.8"
                            ],
                            "sizeBytes": 311286
                        }
                    ],
                    "nodeInfo": {
                        "architecture": "amd64",
                        "bootID": "b2d9d6b0-d348-4135-8d11-0229e84037fa",
                        "containerRuntimeVersion": "containerd://1.7.27",
                        "kernelVersion": "5.15.0-140-generic",
                        "kubeProxyVersion": "v1.32.5",
                        "kubeletVersion": "v1.32.5",
                        "machineID": "61af482aeb01497cabf71b9509d80e9a",
                        "operatingSystem": "linux",
                        "osImage": "Ubuntu 22.04.5 LTS",
                        "systemUUID": "70b18ffc-8d96-a04a-b976-e3e9849d9333"
                    }
                }
            },
            {
                "apiVersion": "v1",
                "kind": "Node",
                "metadata": {
                    "annotations": {
                        "kubeadm.alpha.kubernetes.io/cri-socket": "unix:///var/run/containerd/containerd.sock",
                        "node.alpha.kubernetes.io/ttl": "0",
                        "volumes.kubernetes.io/controller-managed-attach-detach": "true"
                    },
                    "creationTimestamp": "2025-05-28T11:53:46Z",
                    "labels": {
                        "beta.kubernetes.io/arch": "amd64",
                        "beta.kubernetes.io/os": "linux",
                        "kubernetes.io/arch": "amd64",
                        "kubernetes.io/hostname": "k8s-worker-01",
                        "kubernetes.io/os": "linux"
                    },
                    "managedFields": [
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        "f:node.alpha.kubernetes.io/ttl": {}
                                    }
                                }
                            },
                            "manager": "kube-controller-manager",
                            "operation": "Update",
                            "time": "2025-05-28T11:53:46Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        "f:kubeadm.alpha.kubernetes.io/cri-socket": {}
                                    }
                                }
                            },
                            "manager": "kubeadm",
                            "operation": "Update",
                            "time": "2025-05-28T11:53:46Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:metadata": {
                                    "f:annotations": {
                                        ".": {},
                                        "f:volumes.kubernetes.io/controller-managed-attach-detach": {}
                                    },
                                    "f:labels": {
                                        ".": {},
                                        "f:beta.kubernetes.io/arch": {},
                                        "f:beta.kubernetes.io/os": {},
                                        "f:kubernetes.io/arch": {},
                                        "f:kubernetes.io/hostname": {},
                                        "f:kubernetes.io/os": {}
                                    }
                                }
                            },
                            "manager": "kubelet",
                            "operation": "Update",
                            "time": "2025-05-28T11:53:46Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:status": {
                                    "f:conditions": {
                                        "k:{\"type\":\"NetworkUnavailable\"}": {
                                            ".": {},
                                            "f:lastHeartbeatTime": {},
                                            "f:lastTransitionTime": {},
                                            "f:message": {},
                                            "f:reason": {},
                                            "f:status": {},
                                            "f:type": {}
                                        }
                                    }
                                }
                            },
                            "manager": "kube-utils",
                            "operation": "Update",
                            "subresource": "status",
                            "time": "2025-05-28T12:49:52Z"
                        },
                        {
                            "apiVersion": "v1",
                            "fieldsType": "FieldsV1",
                            "fieldsV1": {
                                "f:status": {
                                    "f:conditions": {
                                        "k:{\"type\":\"DiskPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"MemoryPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"PIDPressure\"}": {
                                            "f:lastHeartbeatTime": {}
                                        },
                                        "k:{\"type\":\"Ready\"}": {
                                            "f:lastHeartbeatTime": {},
                                            "f:lastTransitionTime": {},
                                            "f:message": {},
                                            "f:reason": {},
                                            "f:status": {}
                                        }
                                    },
                                    "f:images": {}
                                }
                            },
                            "manager": "kubelet",
                            "operation": "Update",
                            "subresource": "status",
                            "time": "2025-05-28T13:05:11Z"
                        }
                    ],
                    "name": "k8s-worker-01",
                    "resourceVersion": "17444",
                    "uid": "3a8c1725-8d5f-4a8d-8d12-c7de58b1d1a4"
                },
                "spec": {},
                "status": {
                    "addresses": [
                        {
                            "address": "192.168.57.5",
                            "type": "InternalIP"
                        },
                        {
                            "address": "k8s-worker-01",
                            "type": "Hostname"
                        }
                    ],
                    "allocatable": {
                        "cpu": "2",
                        "ephemeral-storage": "10836873199",
                        "hugepages-2Mi": "0",
                        "memory": "1908476Ki",
                        "pods": "110"
                    },
                    "capacity": {
                        "cpu": "2",
                        "ephemeral-storage": "11758760Ki",
                        "hugepages-2Mi": "0",
                        "memory": "2010876Ki",
                        "pods": "110"
                    },
                    "conditions": [
                        {
                            "lastHeartbeatTime": "2025-05-28T12:49:52Z",
                            "lastTransitionTime": "2025-05-28T12:49:52Z",
                            "message": "Weave pod has set this",
                            "reason": "WeaveIsUp",
                            "status": "False",
                            "type": "NetworkUnavailable"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:11Z",
                            "lastTransitionTime": "2025-05-28T11:53:46Z",
                            "message": "kubelet has sufficient memory available",
                            "reason": "KubeletHasSufficientMemory",
                            "status": "False",
                            "type": "MemoryPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:11Z",
                            "lastTransitionTime": "2025-05-28T11:53:46Z",
                            "message": "kubelet has no disk pressure",
                            "reason": "KubeletHasNoDiskPressure",
                            "status": "False",
                            "type": "DiskPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:11Z",
                            "lastTransitionTime": "2025-05-28T11:53:46Z",
                            "message": "kubelet has sufficient PID available",
                            "reason": "KubeletHasSufficientPID",
                            "status": "False",
                            "type": "PIDPressure"
                        },
                        {
                            "lastHeartbeatTime": "2025-05-28T13:05:11Z",
                            "lastTransitionTime": "2025-05-28T12:36:06Z",
                            "message": "kubelet is posting ready status",
                            "reason": "KubeletReady",
                            "status": "True",
                            "type": "Ready"
                        }
                    ],
                    "daemonEndpoints": {
                        "kubeletEndpoint": {
                            "Port": 10250
                        }
                    },
                    "images": [
                        {
                            "names": [
                                "docker.io/rajchaudhuri/weave-kube@sha256:c52fa366cc2e4f5b270290833f70c1fe786432aa029957f758dcd31c97baa34a",
                                "docker.io/rajchaudhuri/weave-kube:2.9.0"
                            ],
                            "sizeBytes": 37163311
                        },
                        {
                            "names": [
                                "registry.k8s.io/kube-proxy@sha256:9dc6553459c3319525ba4090a780db1a133d5dee68c08e07f9b9d6ba83b42a0b",
                                "registry.k8s.io/kube-proxy:v1.32.5"
                            ],
                            "sizeBytes": 30891891
                        },
                        {
                            "names": [
                                "docker.io/rajchaudhuri/weave-npc@sha256:f78aba60931f1d3e649f8f35fdf5278b0945f9a560fb9965dc0a6af4eb1e816a",
                                "docker.io/rajchaudhuri/weave-npc:2.9.0"
                            ],
                            "sizeBytes": 18834204
                        },
                        {
                            "names": [
                                "registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d",
                                "registry.k8s.io/pause:3.8"
                            ],
                            "sizeBytes": 311286
                        }
                    ],
                    "nodeInfo": {
                        "architecture": "amd64",
                        "bootID": "35ce9634-e5e1-42bd-ba6c-146ed9a05af7",
                        "containerRuntimeVersion": "containerd://1.7.27",
                        "kernelVersion": "5.15.0-140-generic",
                        "kubeProxyVersion": "v1.32.5",
                        "kubeletVersion": "v1.32.5",
                        "machineID": "61af482aeb01497cabf71b9509d80e9a",
                        "operatingSystem": "linux",
                        "osImage": "Ubuntu 22.04.5 LTS",
                        "systemUUID": "160ee565-8887-f745-88a2-04510d4f73af"
                    }
                }
            }
        ]
    }
}
2025-05-28 16:07:20,501 p=9737 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 16:07:20,501 p=9737 u=root n=ansible INFO| master-01                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 16:07:20,501 p=9737 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 16:58:48,772 p=10094 u=root n=ansible INFO| - Role roles/ha_proxy_lb was created successfully
2025-05-28 17:23:28,460 p=11210 u=root n=ansible ERROR| ERROR! Attempting to decrypt but no vault secrets found
2025-05-28 17:23:43,916 p=11227 u=root n=ansible INFO| PLAY [Initial server setup for Ansible] *********************************************************************************************
2025-05-28 17:23:43,947 p=11227 u=root n=ansible INFO| TASK [Check if we can connect using provided credentials] ***************************************************************************
2025-05-28 17:23:45,521 p=11227 u=root n=ansible WARNING| [WARNING]: Platform linux on host server1 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 17:23:45,521 p=11227 u=root n=ansible INFO| ok: [server1]
2025-05-28 17:23:45,523 p=11227 u=root n=ansible INFO| TASK [Create ansible user] **********************************************************************************************************
2025-05-28 17:23:46,303 p=11227 u=root n=ansible INFO| changed: [server1]
2025-05-28 17:23:46,305 p=11227 u=root n=ansible INFO| TASK [Set authorized key for ansible user] ******************************************************************************************
2025-05-28 17:23:46,871 p=11227 u=root n=ansible INFO| changed: [server1]
2025-05-28 17:23:46,873 p=11227 u=root n=ansible INFO| TASK [Allow passwordless sudo for ansible user] *************************************************************************************
2025-05-28 17:23:47,708 p=11227 u=root n=ansible INFO| changed: [server1]
2025-05-28 17:23:47,709 p=11227 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 17:23:47,710 p=11227 u=root n=ansible INFO| server1                    : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 17:25:41,287 p=11461 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 17:25:41,387 p=11461 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 17:25:41,397 p=11461 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 17:25:44,043 p=11461 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 17:25:44,043 p=11461 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 17:25:44,052 p=11461 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-28 17:26:18,039 p=11461 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:26:18,050 p=11461 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-28 17:26:18,947 p=11461 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:26:18,957 p=11461 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-28 17:26:18,967 p=11461 u=root n=ansible INFO| RUNNING HANDLER [ha_proxy_lb : Restart service haproxy] *****************************************************************************
2025-05-28 17:26:19,776 p=11461 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:26:19,788 p=11461 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 17:26:19,788 p=11461 u=root n=ansible INFO| lb-01                      : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 17:33:53,396 p=12216 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 17:33:53,492 p=12216 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 17:33:53,501 p=12216 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 17:33:55,702 p=12216 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 17:33:55,702 p=12216 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 17:33:55,711 p=12216 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-28 17:33:58,062 p=12216 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 17:33:58,073 p=12216 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-28 17:33:58,875 p=12216 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:33:58,885 p=12216 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-28 17:33:58,896 p=12216 u=root n=ansible INFO| RUNNING HANDLER [ha_proxy_lb : Restart service haproxy] *****************************************************************************
2025-05-28 17:33:59,657 p=12216 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:33:59,668 p=12216 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 17:33:59,669 p=12216 u=root n=ansible INFO| lb-01                      : ok=4    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 17:58:44,835 p=13928 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 17:58:44,939 p=13928 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 17:58:44,964 p=13928 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 17:58:47,287 p=13928 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 17:58:47,288 p=13928 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 17:58:47,298 p=13928 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 17:58:47,677 p=13928 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 17:58:47,687 p=13928 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 17:59:37,906 p=13928 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 17:59:37,917 p=13928 u=root n=ansible INFO| TASK [common : add cluster nodes to /etc/hosts file to resolve hostnames] ***********************************************************
2025-05-28 17:59:38,954 p=13928 u=root n=ansible INFO| fatal: [lb-01]: FAILED! => {"changed": false, "checksum": "7101c6935aba7cacc85fdb68fb3c390fa5ac08db", "msg": "Unsupported parameters for (ansible.legacy.copy) module: append. Supported parameters include: _original_basename, attributes, backup, checksum, content, dest, directory_mode, follow, force, group, local_follow, mode, owner, remote_src, selevel, serole, setype, seuser, src, unsafe_writes, validate (attr)."}
2025-05-28 17:59:38,956 p=13928 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 17:59:38,956 p=13928 u=root n=ansible INFO| lb-01                      : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 18:14:30,413 p=14071 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 18:14:30,568 p=14071 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 18:14:30,600 p=14071 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 18:14:36,619 p=14071 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 18:14:36,620 p=14071 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:14:36,658 p=14071 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 18:14:37,490 p=14071 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:14:37,512 p=14071 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 18:14:39,789 p=14071 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:14:39,844 p=14071 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-28 18:14:39,929 p=14071 u=root n=ansible INFO| fatal: [lb-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'cluster_nodes_hosts' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/common/tasks/main.yml': line 11, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Append local file content to remote file (idempotent)\n  ^ here\n"}
2025-05-28 18:14:39,936 p=14071 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 18:14:39,938 p=14071 u=root n=ansible INFO| lb-01                      : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 18:16:19,240 p=14170 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 18:16:19,407 p=14170 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 18:16:19,438 p=14170 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 18:16:23,798 p=14170 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 18:16:23,799 p=14170 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:16:23,818 p=14170 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 18:16:24,606 p=14170 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:16:24,644 p=14170 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 18:16:26,983 p=14170 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:16:27,012 p=14170 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-28 18:16:27,053 p=14170 u=root n=ansible INFO| fatal: [lb-01]: FAILED! => {"msg": "lookup plugin (cluster_nodes_hosts) not found"}
2025-05-28 18:16:27,055 p=14170 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 18:16:27,055 p=14170 u=root n=ansible INFO| lb-01                      : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-28 18:18:31,175 p=14268 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 18:18:31,321 p=14268 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 18:18:31,352 p=14268 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 18:18:37,416 p=14268 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 18:18:37,417 p=14268 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:18:37,436 p=14268 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 18:18:38,121 p=14268 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:18:38,139 p=14268 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 18:18:40,088 p=14268 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:18:40,104 p=14268 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-28 18:18:40,848 p=14268 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 18:18:40,871 p=14268 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-28 18:18:58,885 p=14268 u=root n=ansible INFO| changed: [lb-01]
2025-05-28 18:18:58,937 p=14268 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-28 18:19:04,701 p=14268 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:04,729 p=14268 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-28 18:19:06,239 p=14268 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:06,255 p=14268 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-28 18:19:06,271 p=14268 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 18:19:06,272 p=14268 u=root n=ansible INFO| lb-01                      : ok=7    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 18:19:45,153 p=14601 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-28 18:19:45,482 p=14601 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-28 18:19:45,541 p=14601 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-28 18:19:50,451 p=14601 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-28 18:19:50,452 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:50,478 p=14601 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-28 18:19:51,421 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:51,448 p=14601 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-28 18:19:54,800 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:54,832 p=14601 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-28 18:19:56,093 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:56,134 p=14601 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-28 18:19:58,569 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:19:58,644 p=14601 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-28 18:20:03,787 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:20:03,815 p=14601 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-28 18:20:05,593 p=14601 u=root n=ansible INFO| ok: [lb-01]
2025-05-28 18:20:05,616 p=14601 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-28 18:20:05,638 p=14601 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-28 18:20:05,638 p=14601 u=root n=ansible INFO| lb-01                      : ok=7    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-28 19:11:03,213 p=15011 u=root n=ansible INFO| - Role roles/k8s_admin was created successfully
2025-05-28 19:18:56,273 p=15116 u=root n=ansible INFO| - Role roles/cluster_join was created successfully
2025-05-29 16:32:29,533 p=3611 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-29 16:33:55,879 p=3893 u=root n=ansible ERROR| ERROR! Attempting to decrypt but no vault secrets found
2025-05-29 16:34:09,080 p=3908 u=root n=ansible INFO| PLAY [Initial server setup for Ansible] *********************************************************************************************
2025-05-29 16:34:09,295 p=3908 u=root n=ansible INFO| TASK [Check if we can connect using provided credentials] ***************************************************************************
2025-05-29 16:34:13,277 p=3908 u=root n=ansible WARNING| [WARNING]: Platform linux on host server1 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 16:34:13,278 p=3908 u=root n=ansible INFO| ok: [server1]
2025-05-29 16:34:13,286 p=3908 u=root n=ansible INFO| TASK [Create ansible user] **********************************************************************************************************
2025-05-29 16:34:15,355 p=3908 u=root n=ansible INFO| changed: [server1]
2025-05-29 16:34:15,365 p=3908 u=root n=ansible INFO| TASK [Set authorized key for ansible user] ******************************************************************************************
2025-05-29 16:34:17,272 p=3908 u=root n=ansible INFO| changed: [server1]
2025-05-29 16:34:17,304 p=3908 u=root n=ansible INFO| TASK [Allow passwordless sudo for ansible user] *************************************************************************************
2025-05-29 16:34:20,022 p=3908 u=root n=ansible INFO| changed: [server1]
2025-05-29 16:34:20,029 p=3908 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 16:34:20,030 p=3908 u=root n=ansible INFO| server1                    : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 16:34:37,139 p=4075 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 16:34:37,676 p=4075 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 16:34:37,756 p=4075 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 16:34:45,355 p=4075 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 16:34:45,356 p=4075 u=root n=ansible INFO| ok: [master-02]
2025-05-29 16:34:49,768 p=4075 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 16:34:49,768 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:34:50,430 p=4075 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 16:34:50,431 p=4075 u=root n=ansible INFO| ok: [master-01]
2025-05-29 16:34:50,459 p=4075 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 16:34:51,720 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:34:51,875 p=4075 u=root n=ansible INFO| ok: [master-02]
2025-05-29 16:34:51,882 p=4075 u=root n=ansible INFO| ok: [master-01]
2025-05-29 16:34:51,919 p=4075 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 16:34:56,878 p=4075 u=root n=ansible INFO| ok: [master-01]
2025-05-29 16:34:57,646 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:36:52,977 p=4075 u=root n=ansible INFO| changed: [master-02]
2025-05-29 16:36:53,028 p=4075 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 16:36:54,544 p=4075 u=root n=ansible INFO| changed: [master-02]
2025-05-29 16:36:55,954 p=4075 u=root n=ansible INFO| changed: [master-01]
2025-05-29 16:36:56,189 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:36:56,220 p=4075 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 16:37:07,186 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:37:09,003 p=4075 u=root n=ansible INFO| ok: [master-01]
2025-05-29 16:37:19,011 p=4075 u=root n=ansible INFO| changed: [master-02]
2025-05-29 16:37:19,154 p=4075 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 16:37:19,186 p=4075 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 16:37:22,087 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:37:22,120 p=4075 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 16:38:05,626 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:38:05,657 p=4075 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 16:38:09,031 p=4075 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 16:38:09,059 p=4075 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 16:38:09,086 p=4075 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 16:38:09,086 p=4075 u=root n=ansible INFO| lb-01                      : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 16:38:09,087 p=4075 u=root n=ansible INFO| master-01                  : ok=5    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 16:38:09,088 p=4075 u=root n=ansible INFO| master-02                  : ok=5    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 17:24:10,756 p=5522 u=root n=ansible INFO| - Role roles/remove_k8s_cluster was created successfully
2025-05-29 17:52:09,820 p=5703 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 17:52:10,935 p=5703 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 17:52:10,944 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:52:14,173 p=5703 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:52:14,173 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:52:14,433 p=5703 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:52:14,434 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:52:16,271 p=5703 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:52:16,272 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:52:39,827 p=5703 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:52:39,827 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:52:39,837 p=5703 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 17:52:40,418 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:52:40,430 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:52:40,473 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:52:40,475 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:52:40,492 p=5703 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 17:52:42,540 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:52:42,545 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:52:42,624 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:52:43,786 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:52:43,797 p=5703 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 17:52:44,374 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:52:44,400 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:52:44,424 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:52:44,474 p=5703 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 17:52:44,487 p=5703 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 17:52:46,426 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:52:46,759 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:52:46,762 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:53:07,476 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:53:07,518 p=5703 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 17:53:07,529 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:53:08,770 p=5703 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:53:08,781 p=5703 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 17:53:08,798 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:53:10,247 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:53:10,382 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:53:10,771 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:53:10,859 p=5703 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 17:53:10,876 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:53:12,206 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:53:12,254 p=5703 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-29 17:53:12,265 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:53:13,642 p=5703 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:53:13,830 p=5703 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:53:13,911 p=5703 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:53:13,944 p=5703 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 17:53:13,955 p=5703 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:53:14,208 p=5703 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-29 17:54:09,866 p=6179 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 17:54:10,041 p=6179 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 17:54:10,049 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:12,133 p=6179 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:54:12,133 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:12,140 p=6179 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:54:12,140 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:12,310 p=6179 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:54:12,310 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:13,057 p=6179 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 17:54:13,058 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:13,068 p=6179 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 17:54:13,658 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:13,658 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:13,682 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:13,686 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:13,698 p=6179 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 17:54:15,531 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:15,577 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:15,595 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:15,660 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:15,673 p=6179 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 17:54:16,234 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:16,236 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:16,244 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:16,277 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:16,287 p=6179 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 17:54:18,479 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:18,499 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:18,535 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:18,704 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:18,748 p=6179 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 17:54:18,762 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:20,004 p=6179 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 17:54:20,017 p=6179 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 17:54:20,037 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:21,759 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:22,208 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:22,385 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:22,490 p=6179 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 17:54:22,509 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:24,020 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:24,072 p=6179 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-29 17:54:24,085 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:25,621 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:25,690 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:26,548 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:26,582 p=6179 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 17:54:26,594 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:27,734 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:27,746 p=6179 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 17:54:27,759 p=6179 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 17:54:29,333 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:29,375 p=6179 u=root n=ansible INFO| ok: [master-02]
2025-05-29 17:54:29,432 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:29,471 p=6179 u=root n=ansible INFO| TASK [remove_k8s_cluster : Check if kubeadm is installed] ***************************************************************************
2025-05-29 17:54:30,139 p=6179 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"changed": false, "cmd": ["which", "kubeadm"], "delta": "0:00:00.003466", "end": "2025-05-29 14:54:30.057596", "msg": "non-zero return code", "rc": 1, "start": "2025-05-29 14:54:30.054130", "stderr": "", "stderr_lines": [], "stdout": "", "stdout_lines": []}
2025-05-29 17:54:30,140 p=6179 u=root n=ansible INFO| ...ignoring
2025-05-29 17:54:30,144 p=6179 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 17:54:30,163 p=6179 u=root n=ansible INFO| ok: [master-01]
2025-05-29 17:54:30,176 p=6179 u=root n=ansible INFO| TASK [remove_k8s_cluster : revert of changes made to this host by 'kubeadm init' or 'kubeadm join'] *********************************
2025-05-29 17:54:30,201 p=6179 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 17:54:43,402 p=6179 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 17:54:43,855 p=6179 u=root n=ansible INFO| changed: [master-01]
2025-05-29 17:54:43,866 p=6179 u=root n=ansible INFO| TASK [remove_k8s_cluster : Cleanup k8s cluster directories] *************************************************************************
2025-05-29 17:54:43,893 p=6179 u=root n=ansible INFO| skipping: [master-02] => (item=/etc/kubernetes) 
2025-05-29 17:54:43,894 p=6179 u=root n=ansible INFO| skipping: [master-02] => (item=/home/ansible-admin/.kube) 
2025-05-29 17:54:43,902 p=6179 u=root n=ansible INFO| skipping: [master-02] => (item=/var/lib/kubelet) 
2025-05-29 17:54:43,903 p=6179 u=root n=ansible INFO| skipping: [master-02] => (item=/var/lib/etcd) 
2025-05-29 17:54:43,928 p=6179 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 17:54:44,424 p=6179 u=root n=ansible INFO| changed: [worker-01] => (item=/etc/kubernetes)
2025-05-29 17:54:44,473 p=6179 u=root n=ansible INFO| changed: [master-01] => (item=/etc/kubernetes)
2025-05-29 17:54:44,804 p=6179 u=root n=ansible INFO| ok: [worker-01] => (item=/home/ansible-admin/.kube)
2025-05-29 17:54:44,894 p=6179 u=root n=ansible INFO| changed: [master-01] => (item=/home/ansible-admin/.kube)
2025-05-29 17:54:45,159 p=6179 u=root n=ansible INFO| changed: [worker-01] => (item=/var/lib/kubelet)
2025-05-29 17:54:45,254 p=6179 u=root n=ansible INFO| changed: [master-01] => (item=/var/lib/kubelet)
2025-05-29 17:54:45,562 p=6179 u=root n=ansible INFO| ok: [worker-01] => (item=/var/lib/etcd)
2025-05-29 17:54:45,671 p=6179 u=root n=ansible INFO| changed: [master-01] => (item=/var/lib/etcd)
2025-05-29 17:54:45,735 p=6179 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 17:54:45,735 p=6179 u=root n=ansible INFO| lb-01                      : ok=6    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 17:54:45,735 p=6179 u=root n=ansible INFO| master-01                  : ok=12   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 17:54:45,735 p=6179 u=root n=ansible INFO| master-02                  : ok=10   changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=1   
2025-05-29 17:54:45,735 p=6179 u=root n=ansible INFO| worker-01                  : ok=11   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 18:25:11,777 p=7301 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 18:25:11,934 p=7301 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 18:25:11,943 p=7301 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:25:14,767 p=7301 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:25:14,768 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:14,841 p=7301 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:25:14,842 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:14,881 p=7301 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:25:14,881 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:14,949 p=7301 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:25:14,949 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:14,960 p=7301 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 18:25:15,547 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:15,558 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:15,571 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:15,578 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:15,590 p=7301 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 18:25:17,394 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:17,481 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:17,512 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:17,669 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:17,680 p=7301 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 18:25:18,211 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:18,215 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:18,243 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:18,268 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:18,279 p=7301 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 18:25:20,497 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:20,594 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:20,657 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:20,720 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:20,763 p=7301 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 18:25:20,775 p=7301 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:25:22,051 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:22,062 p=7301 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 18:25:37,261 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:37,271 p=7301 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 18:25:38,047 p=7301 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:25:38,058 p=7301 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 18:25:38,071 p=7301 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 18:25:38,086 p=7301 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:25:39,638 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:40,126 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:40,470 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:25:40,479 p=7301 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 18:25:41,018 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:25:41,033 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:41,038 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:41,049 p=7301 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 18:25:41,438 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:25:41,464 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:25:41,485 p=7301 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 18:25:41,495 p=7301 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 18:25:42,102 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:42,126 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:25:42,132 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:42,182 p=7301 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 18:25:42,743 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:42,802 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:42,816 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:25:42,826 p=7301 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 18:25:44,093 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:44,528 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:25:44,630 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:25:44,641 p=7301 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-29 18:25:45,446 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:25:45,585 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:00,894 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:00,905 p=7301 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-29 18:26:02,428 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:02,449 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:26:27,221 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:27,231 p=7301 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-29 18:26:28,829 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:26:29,091 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:29,240 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:29,251 p=7301 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 18:26:29,268 p=7301 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 18:26:29,283 p=7301 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 18:26:29,331 p=7301 u=root n=ansible INFO| RUNNING HANDLER [containerd : Restart service containerd] ***************************************************************************
2025-05-29 18:26:30,246 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:30,285 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-29 18:26:30,716 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:30,719 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:26:30,724 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:26:30,735 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-29 18:26:31,986 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:26:31,996 p=7301 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 18:26:31,996 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:32,010 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] ***************************************************************************************
2025-05-29 18:26:32,430 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:32,485 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:26:32,540 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:32,551 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] *********************************************************************************************
2025-05-29 18:26:32,980 p=7301 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 18:26:33,008 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:33,012 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:26:33,023 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] *********************************************************************************
2025-05-29 18:26:33,758 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:26:33,819 p=7301 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:26:33,829 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:26:33,840 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ***********************************************************
2025-05-29 18:27:00,342 p=7301 u=root n=ansible INFO| changed: [master-02] => (item=kubectl)
2025-05-29 18:27:14,704 p=7301 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-29 18:27:18,263 p=7301 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-29 18:27:18,430 p=7301 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-29 18:27:21,218 p=7301 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-29 18:27:25,845 p=7301 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-29 18:27:28,553 p=7301 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-29 18:27:34,206 p=7301 u=root n=ansible INFO| changed: [master-02] => (item=kubelet)
2025-05-29 18:27:56,150 p=7301 u=root n=ansible INFO| changed: [master-02] => (item=kubeadm)
2025-05-29 18:27:56,166 p=7301 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] *****************************************************************************************
2025-05-29 18:27:56,667 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:27:56,682 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:27:57,052 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:27:57,087 p=7301 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 18:27:57,103 p=7301 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:27:58,403 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:27:58,437 p=7301 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-29 18:28:16,821 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:28:16,847 p=7301 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 18:28:17,297 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:28:17,310 p=7301 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 18:28:17,654 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:28:17,712 p=7301 u=root n=ansible INFO| TASK [cluster_network : Apply weave net manifest to the cluster.] *******************************************************************
2025-05-29 18:28:21,947 p=7301 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:28:21,997 p=7301 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-29 18:28:22,012 p=7301 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 18:28:22,028 p=7301 u=root n=ansible INFO| TASK [cluster_status : Gather system pods] ******************************************************************************************
2025-05-29 18:28:22,042 p=7301 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 18:28:22,061 p=7301 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 18:28:22,075 p=7301 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:28:23,544 p=7301 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:28:24,665 p=7301 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:28:25,374 p=7301 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:28:25,407 p=7301 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 18:28:25,407 p=7301 u=root n=ansible INFO| lb-01                      : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 18:28:25,408 p=7301 u=root n=ansible INFO| master-01                  : ok=27   changed=7    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-05-29 18:28:25,408 p=7301 u=root n=ansible INFO| master-02                  : ok=23   changed=14   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 18:28:25,408 p=7301 u=root n=ansible INFO| worker-01                  : ok=22   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 18:58:55,829 p=9181 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 18:58:56,075 p=9181 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 18:58:56,083 p=9181 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:58:58,823 p=9181 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:58:58,824 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:58:59,186 p=9181 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:58:59,187 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:58:59,742 p=9181 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:58:59,742 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:01,431 p=9181 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 18:59:01,431 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:01,441 p=9181 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 18:59:01,984 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:02,011 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:02,023 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:02,026 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:02,037 p=9181 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 18:59:03,856 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:03,918 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:05,134 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:05,753 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:05,763 p=9181 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 18:59:06,302 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:06,325 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:06,366 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:06,391 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:06,402 p=9181 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 18:59:08,485 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:08,677 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:08,732 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:11,304 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:11,362 p=9181 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 18:59:11,378 p=9181 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:59:13,433 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:13,455 p=9181 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 18:59:19,054 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:19,105 p=9181 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 18:59:21,417 p=9181 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 18:59:21,450 p=9181 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 18:59:21,487 p=9181 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 18:59:21,544 p=9181 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 18:59:24,772 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:25,323 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:25,352 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:25,379 p=9181 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 18:59:26,825 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:26,871 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:26,940 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:26,970 p=9181 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 18:59:28,094 p=9181 u=root n=ansible INFO| changed: [master-02]
2025-05-29 18:59:28,123 p=9181 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 18:59:28,224 p=9181 u=root n=ansible INFO| changed: [master-01]
2025-05-29 18:59:28,272 p=9181 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 18:59:29,719 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:29,745 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:29,837 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:29,957 p=9181 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 18:59:31,429 p=9181 u=root n=ansible INFO| ok: [master-01]
2025-05-29 18:59:31,464 p=9181 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 18:59:31,487 p=9181 u=root n=ansible INFO| ok: [master-02]
2025-05-29 18:59:31,519 p=9181 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 18:59:33,686 p=9181 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-29 19:00:21,653 p=9858 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 19:00:22,144 p=9858 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 19:00:22,169 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:00:26,418 p=9858 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:00:26,419 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:00:26,883 p=9858 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:00:26,884 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:26,922 p=9858 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:00:26,923 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:00:26,996 p=9858 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:00:26,996 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:00:27,025 p=9858 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 19:00:28,417 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:00:28,437 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:00:28,466 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:28,482 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:00:28,513 p=9858 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 19:00:32,695 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:00:32,776 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:00:32,971 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:33,029 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:00:33,060 p=9858 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 19:00:34,467 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:00:34,489 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:00:34,579 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:34,630 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:00:34,662 p=9858 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 19:00:39,934 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:40,080 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:00:40,286 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:00:40,552 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:00:40,726 p=9858 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 19:00:40,759 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:00:43,778 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:43,805 p=9858 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 19:00:54,907 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:54,942 p=9858 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 19:00:57,164 p=9858 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 19:00:57,206 p=9858 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 19:00:57,249 p=9858 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 19:00:57,295 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:01:01,227 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:01,242 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:01,507 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:01,535 p=9858 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 19:01:03,040 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:03,079 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:03,169 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:03,197 p=9858 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 19:01:04,309 p=9858 u=root n=ansible INFO| changed: [master-02]
2025-05-29 19:01:04,359 p=9858 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 19:01:04,442 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:01:04,483 p=9858 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 19:01:05,931 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:06,030 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:06,055 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:06,170 p=9858 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 19:01:07,580 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:07,718 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:07,737 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:07,768 p=9858 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 19:01:10,132 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:10,140 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:10,473 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:10,518 p=9858 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-29 19:01:12,594 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:12,744 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:12,842 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:12,873 p=9858 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-29 19:01:16,512 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:16,564 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:16,617 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:16,648 p=9858 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-29 19:01:18,593 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:18,617 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:18,639 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:18,666 p=9858 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 19:01:18,713 p=9858 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 19:01:18,759 p=9858 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 19:01:18,914 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-29 19:01:20,158 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:20,215 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:20,225 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:20,255 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-29 19:01:22,886 p=9858 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 19:01:22,888 p=9858 u=root n=ansible INFO| changed: [master-02]
2025-05-29 19:01:22,905 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:01:22,938 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] ***************************************************************************************
2025-05-29 19:01:23,935 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:23,995 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:24,019 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:24,049 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] *********************************************************************************************
2025-05-29 19:01:25,015 p=9858 u=root n=ansible INFO| changed: [master-02]
2025-05-29 19:01:25,099 p=9858 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 19:01:25,109 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:01:25,139 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] *********************************************************************************
2025-05-29 19:01:26,900 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:01:27,029 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:01:27,088 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:01:27,117 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ***********************************************************
2025-05-29 19:01:37,679 p=9858 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-29 19:01:37,729 p=9858 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-29 19:01:46,846 p=9858 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-29 19:01:47,321 p=9858 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-29 19:01:49,532 p=9858 u=root n=ansible INFO| ok: [master-02] => (item=kubectl)
2025-05-29 19:02:10,418 p=9858 u=root n=ansible INFO| ok: [master-02] => (item=kubelet)
2025-05-29 19:02:19,032 p=9858 u=root n=ansible INFO| ok: [master-02] => (item=kubeadm)
2025-05-29 19:02:29,040 p=9858 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-29 19:02:37,506 p=9858 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-29 19:02:37,570 p=9858 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] *****************************************************************************************
2025-05-29 19:02:38,799 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:02:39,064 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:02:39,772 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:39,869 p=9858 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 19:02:39,912 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:02:44,908 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:44,943 p=9858 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-29 19:02:45,795 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:45,869 p=9858 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 19:02:46,798 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:46,838 p=9858 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 19:02:48,094 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:48,192 p=9858 u=root n=ansible INFO| TASK [cluster_network : Apply weave net manifest to the cluster.] *******************************************************************
2025-05-29 19:02:53,968 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:54,036 p=9858 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-29 19:02:54,081 p=9858 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:02:54,119 p=9858 u=root n=ansible INFO| TASK [cluster_status : Gather system pods] ******************************************************************************************
2025-05-29 19:02:54,157 p=9858 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:02:54,211 p=9858 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-29 19:02:54,251 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:02:57,766 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:02:57,787 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:02:57,819 p=9858 u=root n=ansible INFO| TASK [cluster_join_workers : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 19:02:57,888 p=9858 u=root n=ansible INFO| skipping: [worker-01]
2025-05-29 19:03:00,192 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:03:00,238 p=9858 u=root n=ansible INFO| TASK [cluster_join_workers : Join cluster directly (No file needed)] ****************************************************************
2025-05-29 19:03:00,361 p=9858 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:03:07,781 p=9858 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 19:03:07,873 p=9858 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 19:03:07,917 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:03:11,701 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:03:12,096 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:03:12,125 p=9858 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 19:03:12,190 p=9858 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:03:13,596 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:03:13,632 p=9858 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 19:03:13,702 p=9858 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:03:17,200 p=9858 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:03:17,252 p=9858 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 19:03:17,314 p=9858 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:03:17,361 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:03:17,394 p=9858 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 19:03:17,487 p=9858 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:03:17,519 p=9858 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:03:17,551 p=9858 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 19:03:17,649 p=9858 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:03:18,568 p=9858 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "lb-api-01.k8s.local:6443", "--token", "0k6v13.zq9hyjh48wicx18d", "--discovery-token-ca-cert-hash", "sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf", "--control-plane", "--certificate-key", "4e3006bf873e957d085fac7db5113f5c7f1480195f621787641c558a725334db", "#", "Now", "uses", "ONLY", "the", "key"], "delta": "0:00:00.089675", "end": "2025-05-29 16:03:18.382212", "msg": "non-zero return code", "rc": 1, "start": "2025-05-29 16:03:18.292537", "stderr": "accepts at most 1 arg(s), received 7\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["accepts at most 1 arg(s), received 7", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "", "stdout_lines": []}
2025-05-29 19:03:18,635 p=9858 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 19:03:18,646 p=9858 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 19:03:18,691 p=9858 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:03:22,035 p=9858 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:03:22,252 p=9858 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:03:22,327 p=9858 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 19:03:22,328 p=9858 u=root n=ansible INFO| lb-01                      : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 19:03:22,328 p=9858 u=root n=ansible INFO| master-01                  : ok=33   changed=6    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-05-29 19:03:22,329 p=9858 u=root n=ansible INFO| master-02                  : ok=23   changed=3    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-05-29 19:03:22,330 p=9858 u=root n=ansible INFO| worker-01                  : ok=24   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-29 19:06:50,713 p=11582 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 19:06:51,074 p=11582 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 19:06:51,133 p=11582 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:06:57,771 p=11582 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:06:57,773 p=11582 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:06:57,784 p=11582 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:06:57,785 p=11582 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:06:57,817 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 19:06:57,893 p=11582 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:06:59,341 p=11582 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:06:59,369 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 19:06:59,439 p=11582 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:07:02,337 p=11582 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:07:02,369 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 19:07:02,434 p=11582 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:07:02,483 p=11582 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:07:02,516 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 19:07:02,612 p=11582 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:07:02,646 p=11582 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:07:02,714 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : debug] *************************************************************************************************
2025-05-29 19:07:02,824 p=11582 u=root n=ansible INFO| ok: [master-02] => {
    "msg": "Master join command: kubeadm join lb-api-01.k8s.local:6443 --token ctimt9.bszlfds46q19ib2a --discovery-token-ca-cert-hash sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf  --control-plane --certificate-key b99011b2830b4e68ab8bf46de29f0be3aa6272c8f21246534e513fbfb41ea54d  # Now uses ONLY the key"
}
2025-05-29 19:07:02,858 p=11582 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:07:02,902 p=11582 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 19:07:03,023 p=11582 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:07:04,002 p=11582 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "lb-api-01.k8s.local:6443", "--token", "ctimt9.bszlfds46q19ib2a", "--discovery-token-ca-cert-hash", "sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf", "--control-plane", "--certificate-key", "b99011b2830b4e68ab8bf46de29f0be3aa6272c8f21246534e513fbfb41ea54d", "#", "Now", "uses", "ONLY", "the", "key"], "delta": "0:00:00.103833", "end": "2025-05-29 16:07:03.910389", "msg": "non-zero return code", "rc": 1, "start": "2025-05-29 16:07:03.806556", "stderr": "accepts at most 1 arg(s), received 7\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["accepts at most 1 arg(s), received 7", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "", "stdout_lines": []}
2025-05-29 19:07:04,046 p=11582 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 19:07:04,057 p=11582 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 19:07:04,099 p=11582 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:07:07,533 p=11582 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:07:10,470 p=11582 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:07:10,472 p=11582 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:07:10,528 p=11582 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 19:07:10,528 p=11582 u=root n=ansible INFO| master-01                  : ok=5    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 19:07:10,529 p=11582 u=root n=ansible INFO| master-02                  : ok=3    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-05-29 19:07:10,529 p=11582 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 19:07:59,601 p=11869 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 19:07:59,963 p=11869 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 19:08:00,018 p=11869 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:08:04,213 p=11869 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:08:04,214 p=11869 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:08:04,470 p=11869 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:08:04,471 p=11869 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:08:04,502 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 19:08:04,561 p=11869 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:08:06,104 p=11869 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:08:06,138 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 19:08:06,204 p=11869 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:08:09,266 p=11869 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:08:09,326 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 19:08:09,418 p=11869 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:08:09,465 p=11869 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:08:09,500 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 19:08:09,603 p=11869 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:08:09,649 p=11869 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:08:09,679 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : debug] *************************************************************************************************
2025-05-29 19:08:09,748 p=11869 u=root n=ansible INFO| ok: [master-02] => {
    "msg": "Master join command: kubeadm join lb-api-01.k8s.local:6443 --token bs6isc.0buzlyny7j6gnpxl --discovery-token-ca-cert-hash sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf  --control-plane --certificate-key 8779db095e1be6467afb4c021f995b2a8060279bf79346ee2c51c3881eb256df  "
}
2025-05-29 19:08:09,781 p=11869 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:08:09,819 p=11869 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 19:08:09,918 p=11869 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:12:50,703 p=11869 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"changed": true, "cmd": ["kubeadm", "join", "lb-api-01.k8s.local:6443", "--token", "bs6isc.0buzlyny7j6gnpxl", "--discovery-token-ca-cert-hash", "sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf", "--control-plane", "--certificate-key", "8779db095e1be6467afb4c021f995b2a8060279bf79346ee2c51c3881eb256df"], "delta": "0:04:39.733652", "end": "2025-05-29 16:12:50.303336", "msg": "non-zero return code", "rc": 1, "start": "2025-05-29 16:08:10.569684", "stderr": "W0529 16:08:11.691404   12746 checks.go:846] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm.It is recommended to use \"registry.k8s.io/pause:3.10\" as the CRI sandbox image.\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:50.272219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:50.781241Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:51.278105Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:51.775820Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:52.275254Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:52.781369Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:53.299428Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:53.775286Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:54.565844Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:54.776883Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:55.375416Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:55.861699Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:56.274643Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:56.778513Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:57.274958Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:57.773808Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:58.273780Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:58.773267Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:59.280359Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:59.772195Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:00.274014Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:00.772149Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:01.272935Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:01.771863Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:02.317590Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:02.772724Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:03.352642Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:03.787714Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:04.287678Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:04.828551Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:05.273433Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:05.779934Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:06.273978Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:06.775427Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:07.274811Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:07.834521Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:08.329913Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:08.772604Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:09.278002Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:09.776380Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:10.275207Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:10.815605Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:11.274942Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:11.796077Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:12.277050Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:12.772729Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:13.273933Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:13.774824Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:14.271356Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:14.772649Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:15.274709Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:15.773554Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:16.272318Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:16.772325Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:17.271922Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:17.771905Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:18.273326Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:18.773246Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:19.273890Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:19.829790Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:20.274622Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:20.772158Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:21.272262Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:21.771283Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:22.271072Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:22.772337Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:23.271434Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:23.773710Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:24.272773Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:24.771881Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:25.413653Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:25.772133Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:26.272157Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:26.772405Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:27.273383Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:27.772424Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:28.272703Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:28.772016Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:29.272548Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:29.772029Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:30.308813Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:30.772011Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:31.273605Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:31.772621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:32.276877Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:32.773370Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:33.273392Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:33.772154Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:34.276256Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:34.770839Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:35.271930Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:35.772455Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:36.272751Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:36.771796Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:37.273690Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:37.780054Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:38.273011Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:38.771621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:39.271738Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:39.771346Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:40.272677Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:40.780895Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:41.275858Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:41.773378Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:42.274561Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:42.777139Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:43.274760Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:43.773238Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:44.273640Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:44.775593Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:45.274391Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:45.775119Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:46.272165Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:46.772818Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:47.272606Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:47.773845Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:48.274738Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:48.773730Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:49.272507Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:49.773880Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:50.273940Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:50.773826Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:51.273114Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:51.774417Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:52.274092Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:52.773114Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:53.273796Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:53.868009Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:54.285577Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:54.773365Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:55.273222Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:55.772260Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:56.273427Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:56.779992Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:57.276675Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:57.774633Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:58.298109Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:58.771621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:59.296347Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:59.772544Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:00.272884Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:00.772024Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:01.272276Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:01.772885Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:02.272637Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:02.773283Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:03.273017Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:03.773098Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:04.276120Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:04.773460Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:05.292350Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:05.774369Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:06.277359Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:06.774511Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:07.274294Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:07.774100Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:08.275522Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:08.773932Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:09.274347Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:09.773677Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:10.274257Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:10.774144Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:11.276360Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:11.774378Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:12.276478Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:12.787695Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:13.272462Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:13.773635Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:14.274082Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:14.774725Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:15.273028Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:15.773155Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:16.273962Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:16.773477Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:17.273382Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:17.775816Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:18.273791Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:18.775256Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:19.274597Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:19.774387Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:20.281598Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:20.776419Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:21.273803Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:21.775514Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:22.274619Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:22.797469Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:23.273867Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:23.773694Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:24.273517Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:24.773881Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:25.274060Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:25.782334Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:26.275449Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:26.774127Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:27.273969Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:27.773668Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:28.275237Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:28.796219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:29.273475Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:29.774898Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:30.276142Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:30.778331Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:31.276219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:31.773577Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:32.275248Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:32.776374Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:33.273202Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:33.773262Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:34.276055Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:34.775988Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:35.273718Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:35.774547Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:36.293975Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:36.773704Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:37.273559Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:37.773670Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:38.273711Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:38.774478Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:39.275054Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:39.773196Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:40.273319Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:40.773562Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:41.273866Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:41.775715Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:42.278531Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:42.772532Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:43.273833Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:43.773626Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:44.273622Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:44.772598Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:45.272428Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:45.774023Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:46.273844Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:46.773429Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:47.273356Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:47.774826Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:48.274227Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:48.773444Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:49.275635Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:49.774008Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\n{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:50.286990Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}\nerror execution phase control-plane-join/etcd: error creating local etcd static pod manifest file: etcdserver: can only promote a learner member which is in sync with leader\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["W0529 16:08:11.691404   12746 checks.go:846] detected that the sandbox image \"registry.k8s.io/pause:3.8\" of the container runtime is inconsistent with that used by kubeadm.It is recommended to use \"registry.k8s.io/pause:3.10\" as the CRI sandbox image.", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:50.272219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:50.781241Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:51.278105Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:51.775820Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:52.275254Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:52.781369Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:53.299428Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:53.775286Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:54.565844Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:54.776883Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:55.375416Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:55.861699Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:56.274643Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:56.778513Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:57.274958Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:57.773808Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:58.273780Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:58.773267Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:59.280359Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:10:59.772195Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:00.274014Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:00.772149Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:01.272935Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:01.771863Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:02.317590Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:02.772724Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:03.352642Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:03.787714Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:04.287678Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:04.828551Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:05.273433Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:05.779934Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:06.273978Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:06.775427Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:07.274811Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:07.834521Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:08.329913Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:08.772604Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:09.278002Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:09.776380Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:10.275207Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:10.815605Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:11.274942Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:11.796077Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:12.277050Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:12.772729Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:13.273933Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:13.774824Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:14.271356Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:14.772649Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:15.274709Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:15.773554Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:16.272318Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:16.772325Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:17.271922Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:17.771905Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:18.273326Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:18.773246Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:19.273890Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:19.829790Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:20.274622Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:20.772158Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:21.272262Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:21.771283Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:22.271072Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:22.772337Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:23.271434Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:23.773710Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:24.272773Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:24.771881Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:25.413653Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:25.772133Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:26.272157Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:26.772405Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:27.273383Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:27.772424Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:28.272703Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:28.772016Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:29.272548Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:29.772029Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:30.308813Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:30.772011Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:31.273605Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:31.772621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:32.276877Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:32.773370Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:33.273392Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:33.772154Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:34.276256Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:34.770839Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:35.271930Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:35.772455Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:36.272751Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:36.771796Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:37.273690Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:37.780054Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:38.273011Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:38.771621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:39.271738Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:39.771346Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:40.272677Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:40.780895Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:41.275858Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:41.773378Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:42.274561Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:42.777139Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:43.274760Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:43.773238Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:44.273640Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:44.775593Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:45.274391Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:45.775119Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:46.272165Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:46.772818Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:47.272606Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:47.773845Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:48.274738Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:48.773730Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:49.272507Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:49.773880Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:50.273940Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:50.773826Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:51.273114Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:51.774417Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:52.274092Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:52.773114Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:53.273796Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:53.868009Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:54.285577Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:54.773365Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:55.273222Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:55.772260Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:56.273427Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:56.779992Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:57.276675Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:57.774633Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:58.298109Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:58.771621Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:59.296347Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:11:59.772544Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:00.272884Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:00.772024Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:01.272276Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:01.772885Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:02.272637Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:02.773283Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:03.273017Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:03.773098Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:04.276120Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:04.773460Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:05.292350Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:05.774369Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:06.277359Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:06.774511Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:07.274294Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:07.774100Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:08.275522Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:08.773932Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:09.274347Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:09.773677Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:10.274257Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:10.774144Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:11.276360Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:11.774378Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:12.276478Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:12.787695Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:13.272462Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:13.773635Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:14.274082Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:14.774725Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:15.273028Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:15.773155Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:16.273962Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:16.773477Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:17.273382Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:17.775816Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:18.273791Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:18.775256Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:19.274597Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:19.774387Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:20.281598Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:20.776419Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:21.273803Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:21.775514Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:22.274619Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:22.797469Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:23.273867Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:23.773694Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:24.273517Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:24.773881Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:25.274060Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:25.782334Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:26.275449Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:26.774127Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:27.273969Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:27.773668Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:28.275237Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:28.796219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:29.273475Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:29.774898Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:30.276142Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:30.778331Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:31.276219Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:31.773577Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:32.275248Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:32.776374Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:33.273202Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:33.773262Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:34.276055Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:34.775988Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:35.273718Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:35.774547Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:36.293975Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:36.773704Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:37.273559Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:37.773670Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:38.273711Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:38.774478Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:39.275054Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:39.773196Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:40.273319Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:40.773562Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:41.273866Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:41.775715Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:42.278531Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:42.772532Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:43.273833Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:43.773626Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:44.273622Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:44.772598Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:45.272428Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:45.774023Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:46.273844Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:46.773429Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:47.273356Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:47.774826Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:48.274227Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:48.773444Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:49.275635Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:49.774008Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "{\"level\":\"warn\",\"ts\":\"2025-05-29T16:12:50.286990Z\",\"logger\":\"etcd-client\",\"caller\":\"v3@v3.5.16/retry_interceptor.go:63\",\"msg\":\"retrying of unary invoker failed\",\"target\":\"etcd-endpoints://0xc00044ed20/192.168.57.3:2379\",\"attempt\":0,\"error\":\"rpc error: code = FailedPrecondition desc = etcdserver: can only promote a learner member which is in sync with leader\"}", "error execution phase control-plane-join/etcd: error creating local etcd static pod manifest file: etcdserver: can only promote a learner member which is in sync with leader", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[preflight] Running pre-flight checks\n[preflight] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.\n[preflight] Running pre-flight checks before initializing the new control plane instance\n[preflight] Pulling images required for setting up a Kubernetes cluster\n[preflight] This might take a minute or two, depending on the speed of your internet connection\n[preflight] You can also perform this action beforehand using 'kubeadm config images pull'\n[download-certs] Downloading the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace\n[download-certs] Saving the certificates to the folder: \"/etc/kubernetes/pki\"\n[certs] Using certificateDir folder \"/etc/kubernetes/pki\"\n[certs] Generating \"front-proxy-client\" certificate and key\n[certs] Generating \"etcd/healthcheck-client\" certificate and key\n[certs] Generating \"apiserver-etcd-client\" certificate and key\n[certs] Generating \"etcd/server\" certificate and key\n[certs] etcd/server serving cert is signed for DNS names [k8s-master-02 localhost] and IPs [192.168.1.14 127.0.0.1 ::1]\n[certs] Generating \"etcd/peer\" certificate and key\n[certs] etcd/peer serving cert is signed for DNS names [k8s-master-02 localhost] and IPs [192.168.1.14 127.0.0.1 ::1]\n[certs] Generating \"apiserver\" certificate and key\n[certs] apiserver serving cert is signed for DNS names [k8s-master-02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lb-api-01.k8s.local] and IPs [10.96.0.1 192.168.1.14]\n[certs] Generating \"apiserver-kubelet-client\" certificate and key\n[certs] Valid certificates and keys now exist in \"/etc/kubernetes/pki\"\n[certs] Using the existing \"sa\" key\n[kubeconfig] Generating kubeconfig files\n[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"\n[kubeconfig] Writing \"admin.conf\" kubeconfig file\n[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file\n[kubeconfig] Writing \"scheduler.conf\" kubeconfig file\n[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"\n[control-plane] Creating static Pod manifest for \"kube-apiserver\"\n[control-plane] Creating static Pod manifest for \"kube-controller-manager\"\n[control-plane] Creating static Pod manifest for \"kube-scheduler\"\n[check-etcd] Checking that the etcd cluster is healthy\n[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet-start] Starting the kubelet\n[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s\n[kubelet-check] The kubelet is healthy after 6.511409714s\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap\n[etcd] Announced new etcd member joining to the existing etcd cluster\n[etcd] Creating static Pod manifest for \"etcd\"", "stdout_lines": ["[preflight] Running pre-flight checks", "[preflight] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[preflight] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.", "[preflight] Running pre-flight checks before initializing the new control plane instance", "[preflight] Pulling images required for setting up a Kubernetes cluster", "[preflight] This might take a minute or two, depending on the speed of your internet connection", "[preflight] You can also perform this action beforehand using 'kubeadm config images pull'", "[download-certs] Downloading the certificates in Secret \"kubeadm-certs\" in the \"kube-system\" Namespace", "[download-certs] Saving the certificates to the folder: \"/etc/kubernetes/pki\"", "[certs] Using certificateDir folder \"/etc/kubernetes/pki\"", "[certs] Generating \"front-proxy-client\" certificate and key", "[certs] Generating \"etcd/healthcheck-client\" certificate and key", "[certs] Generating \"apiserver-etcd-client\" certificate and key", "[certs] Generating \"etcd/server\" certificate and key", "[certs] etcd/server serving cert is signed for DNS names [k8s-master-02 localhost] and IPs [192.168.1.14 127.0.0.1 ::1]", "[certs] Generating \"etcd/peer\" certificate and key", "[certs] etcd/peer serving cert is signed for DNS names [k8s-master-02 localhost] and IPs [192.168.1.14 127.0.0.1 ::1]", "[certs] Generating \"apiserver\" certificate and key", "[certs] apiserver serving cert is signed for DNS names [k8s-master-02 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local lb-api-01.k8s.local] and IPs [10.96.0.1 192.168.1.14]", "[certs] Generating \"apiserver-kubelet-client\" certificate and key", "[certs] Valid certificates and keys now exist in \"/etc/kubernetes/pki\"", "[certs] Using the existing \"sa\" key", "[kubeconfig] Generating kubeconfig files", "[kubeconfig] Using kubeconfig folder \"/etc/kubernetes\"", "[kubeconfig] Writing \"admin.conf\" kubeconfig file", "[kubeconfig] Writing \"controller-manager.conf\" kubeconfig file", "[kubeconfig] Writing \"scheduler.conf\" kubeconfig file", "[control-plane] Using manifest folder \"/etc/kubernetes/manifests\"", "[control-plane] Creating static Pod manifest for \"kube-apiserver\"", "[control-plane] Creating static Pod manifest for \"kube-controller-manager\"", "[control-plane] Creating static Pod manifest for \"kube-scheduler\"", "[check-etcd] Checking that the etcd cluster is healthy", "[kubelet-start] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"", "[kubelet-start] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"", "[kubelet-start] Starting the kubelet", "[kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s", "[kubelet-check] The kubelet is healthy after 6.511409714s", "[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap", "[etcd] Announced new etcd member joining to the existing etcd cluster", "[etcd] Creating static Pod manifest for \"etcd\""]}
2025-05-29 19:12:50,772 p=11869 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 19:12:50,791 p=11869 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 19:12:50,826 p=11869 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:12:55,767 p=11869 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:12:56,449 p=11869 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:12:56,450 p=11869 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:12:56,516 p=11869 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 19:12:56,517 p=11869 u=root n=ansible INFO| master-01                  : ok=5    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 19:12:56,517 p=11869 u=root n=ansible INFO| master-02                  : ok=3    changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
2025-05-29 19:12:56,517 p=11869 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 19:39:33,382 p=14445 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 19:39:33,723 p=14445 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 19:39:33,780 p=14445 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:39:38,603 p=14445 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:39:38,604 p=14445 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:39:39,452 p=14445 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:39:39,453 p=14445 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:39:39,493 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 19:39:39,559 p=14445 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:39:41,063 p=14445 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:39:41,112 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 19:39:41,191 p=14445 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:39:44,865 p=14445 u=root n=ansible INFO| changed: [master-01]
2025-05-29 19:39:44,904 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 19:39:44,962 p=14445 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 19:39:45,013 p=14445 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:39:45,048 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 19:39:45,154 p=14445 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:39:45,197 p=14445 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:39:45,237 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : debug] *************************************************************************************************
2025-05-29 19:39:45,299 p=14445 u=root n=ansible INFO| ok: [master-02] => {
    "msg": "Master join command: kubeadm join lb-api-01.k8s.local:6443 --token wftf7r.ak0v4z6kq90rp35f --discovery-token-ca-cert-hash sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf  --control-plane --certificate-key b32244879da87f5fda8517b1479d3d27b001c1018692eb6772a387c1523b610d  "
}
2025-05-29 19:39:45,325 p=14445 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:39:45,360 p=14445 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 19:39:45,462 p=14445 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 19:39:46,268 p=14445 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:39:46,349 p=14445 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 19:39:46,390 p=14445 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:39:49,568 p=14445 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:39:49,600 p=14445 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 19:39:51,003 p=14445 u=root n=ansible INFO| changed: [master-02]
2025-05-29 19:39:51,047 p=14445 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 19:39:52,275 p=14445 u=root n=ansible INFO| changed: [master-02]
2025-05-29 19:39:52,327 p=14445 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 19:39:52,362 p=14445 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 19:39:55,774 p=14445 u=root n=ansible INFO| ok: [master-02]
2025-05-29 19:39:55,947 p=14445 u=root n=ansible INFO| ok: [master-01]
2025-05-29 19:39:58,426 p=14445 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 19:39:58,426 p=14445 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 19:39:58,527 p=14445 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 19:39:58,527 p=14445 u=root n=ansible INFO| master-01                  : ok=5    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 19:39:58,528 p=14445 u=root n=ansible INFO| master-02                  : ok=8    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 19:39:58,529 p=14445 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:23:34,199 p=15160 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 20:23:34,320 p=15160 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 20:23:34,342 p=15160 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:23:36,861 p=15160 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:23:36,861 p=15160 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:23:37,336 p=15160 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:23:37,336 p=15160 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:23:37,349 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 20:23:37,378 p=15160 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:23:37,889 p=15160 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:23:37,901 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 20:23:37,922 p=15160 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:23:39,575 p=15160 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:23:39,587 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 20:23:39,611 p=15160 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:23:39,626 p=15160 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:23:39,638 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 20:23:39,669 p=15160 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:23:39,685 p=15160 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:23:39,701 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : debug] *************************************************************************************************
2025-05-29 20:23:39,726 p=15160 u=root n=ansible INFO| ok: [master-02] => {
    "msg": "Master join command: kubeadm join lb-api-01.k8s.local:6443 --token qqv7y7.cg18y1qzlq6jfl5c --discovery-token-ca-cert-hash sha256:540469eeddff3faee2196c3147963913dcce3e872a8865294bcef8e7ce35fbaf  --control-plane --certificate-key b9bad011c88fa8908fe4ebf518f52ce643ec13bfa8310d99ebe37a28852592d3 --apiserver-advertise-address 192.168.57.4  "
}
2025-05-29 20:23:39,736 p=15160 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:23:39,752 p=15160 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 20:23:39,787 p=15160 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:23:56,548 p=15160 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:23:56,575 p=15160 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 20:23:56,589 p=15160 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:23:58,460 p=15160 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:23:58,479 p=15160 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 20:23:59,139 p=15160 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:23:59,155 p=15160 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 20:23:59,866 p=15160 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:23:59,880 p=15160 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 20:23:59,895 p=15160 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:24:01,870 p=15160 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:24:02,193 p=15160 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:24:02,823 p=15160 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:24:02,823 p=15160 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:24:02,858 p=15160 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 20:24:02,859 p=15160 u=root n=ansible INFO| master-01                  : ok=5    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 20:24:02,859 p=15160 u=root n=ansible INFO| master-02                  : ok=8    changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 20:24:02,859 p=15160 u=root n=ansible INFO| worker-01                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:26:06,958 p=15532 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 20:26:07,135 p=15532 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 20:26:07,143 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:10,021 p=15532 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:26:10,021 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:10,152 p=15532 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:26:10,152 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:10,171 p=15532 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:26:10,171 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:10,376 p=15532 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:26:10,376 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:10,386 p=15532 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 20:26:10,914 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:10,936 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:10,975 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:10,979 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:10,990 p=15532 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 20:26:12,754 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:12,836 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:13,130 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:15,115 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:15,129 p=15532 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 20:26:15,704 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:15,738 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:15,743 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:15,906 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:15,916 p=15532 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 20:26:17,869 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:17,972 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:19,027 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:22,697 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:22,746 p=15532 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 20:26:22,763 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:23,957 p=15532 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:26:23,969 p=15532 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 20:26:23,989 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:25,571 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:25,598 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:25,796 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:25,897 p=15532 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 20:26:25,916 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:27,308 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:27,357 p=15532 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-29 20:26:27,371 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:28,739 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:28,864 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:28,889 p=15532 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 20:26:28,904 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:30,463 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:30,474 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:30,501 p=15532 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 20:26:30,515 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:31,948 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:31,961 p=15532 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 20:26:31,975 p=15532 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:26:33,529 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:33,533 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:33,600 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:33,613 p=15532 u=root n=ansible INFO| TASK [remove_k8s_cluster : Check if kubeadm is installed] ***************************************************************************
2025-05-29 20:26:34,135 p=15532 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:26:34,138 p=15532 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:26:34,152 p=15532 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:26:34,165 p=15532 u=root n=ansible INFO| TASK [remove_k8s_cluster : revert of changes made to this host by 'kubeadm init' or 'kubeadm join'] *********************************
2025-05-29 20:26:39,403 p=15532 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:26:45,510 p=15532 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:26:49,904 p=15532 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:26:49,918 p=15532 u=root n=ansible INFO| TASK [remove_k8s_cluster : Cleanup k8s cluster directories] *************************************************************************
2025-05-29 20:26:50,482 p=15532 u=root n=ansible INFO| changed: [worker-01] => (item=/etc/kubernetes)
2025-05-29 20:26:50,505 p=15532 u=root n=ansible INFO| changed: [master-02] => (item=/etc/kubernetes)
2025-05-29 20:26:50,527 p=15532 u=root n=ansible INFO| changed: [master-01] => (item=/etc/kubernetes)
2025-05-29 20:26:50,876 p=15532 u=root n=ansible INFO| ok: [worker-01] => (item=/home/ansible-admin/.kube)
2025-05-29 20:26:50,931 p=15532 u=root n=ansible INFO| changed: [master-02] => (item=/home/ansible-admin/.kube)
2025-05-29 20:26:50,964 p=15532 u=root n=ansible INFO| changed: [master-01] => (item=/home/ansible-admin/.kube)
2025-05-29 20:26:51,256 p=15532 u=root n=ansible INFO| changed: [worker-01] => (item=/var/lib/kubelet)
2025-05-29 20:26:51,359 p=15532 u=root n=ansible INFO| changed: [master-02] => (item=/var/lib/kubelet)
2025-05-29 20:26:51,366 p=15532 u=root n=ansible INFO| changed: [master-01] => (item=/var/lib/kubelet)
2025-05-29 20:26:51,618 p=15532 u=root n=ansible INFO| ok: [worker-01] => (item=/var/lib/etcd)
2025-05-29 20:26:51,751 p=15532 u=root n=ansible INFO| changed: [master-01] => (item=/var/lib/etcd)
2025-05-29 20:26:51,755 p=15532 u=root n=ansible INFO| changed: [master-02] => (item=/var/lib/etcd)
2025-05-29 20:26:51,797 p=15532 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 20:26:51,798 p=15532 u=root n=ansible INFO| lb-01                      : ok=6    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:26:51,798 p=15532 u=root n=ansible INFO| master-01                  : ok=13   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:26:51,798 p=15532 u=root n=ansible INFO| master-02                  : ok=12   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:26:51,798 p=15532 u=root n=ansible INFO| worker-01                  : ok=11   changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:34:05,851 p=16287 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 20:34:06,118 p=16287 u=root n=ansible WARNING| [WARNING]:  * Failed to parse /root/ansible/build_k8s_cluster/hosts with yaml plugin: We were unable to read either as JSON nor
YAML, these are the errors we got from each: JSON: Expecting value: line 1 column 2 (char 1)  Syntax Error while loading YAML.   did
not find expected <document start>. did not find expected <document start>   in "<unicode string>", line 2, column 1  The error
appears to be in '/root/ansible/build_k8s_cluster/hosts': line 2, column 1, but may be elsewhere in the file depending on the exact
syntax problem.  The offending line appears to be:  [super-master] master-01 ansible_host=192.168.1.15 ansible_user=ansible-admin
node_IP=192.168.57.3 ^ here

2025-05-29 20:34:06,118 p=16287 u=root n=ansible WARNING| [WARNING]:  * Failed to parse /root/ansible/build_k8s_cluster/hosts with ini plugin: /root/ansible/build_k8s_cluster/hosts:19:
Expected key=value, got: HOME_USER: "{{ ansible_user }}"     # existing username not root  or  {{ ansible_user }}

2025-05-29 20:34:06,118 p=16287 u=root n=ansible WARNING| [WARNING]: Unable to parse /root/ansible/build_k8s_cluster/hosts as an inventory source

2025-05-29 20:34:06,119 p=16287 u=root n=ansible WARNING| [WARNING]: No inventory was parsed, only implicit localhost is available

2025-05-29 20:34:06,122 p=16287 u=root n=ansible WARNING| [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

2025-05-29 20:34:06,298 p=16287 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 20:34:06,298 p=16287 u=root n=ansible INFO| skipping: no hosts matched
2025-05-29 20:34:06,300 p=16287 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 20:34:06,308 p=16287 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:34:08,484 p=16287 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:34:08,485 p=16287 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:34:08,494 p=16287 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 20:34:18,611 p=16287 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:34:18,623 p=16287 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 20:34:19,369 p=16287 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:34:19,379 p=16287 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 20:34:19,391 p=16287 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 20:34:19,399 p=16287 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:34:21,666 p=16287 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:34:21,667 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:22,099 p=16287 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:34:22,099 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:22,523 p=16287 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:34:22,524 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:22,535 p=16287 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 20:34:23,010 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:23,068 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:23,073 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:23,086 p=16287 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 20:34:23,508 p=16287 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:34:23,520 p=16287 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:34:23,547 p=16287 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:34:23,559 p=16287 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 20:34:24,034 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:24,051 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:24,055 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:24,099 p=16287 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 20:34:24,633 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:24,693 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:24,707 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:24,719 p=16287 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 20:34:25,667 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:25,992 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:26,166 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:26,178 p=16287 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-29 20:34:26,888 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:27,029 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:27,052 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:27,064 p=16287 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-29 20:34:28,583 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:28,688 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:28,752 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:28,765 p=16287 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-29 20:34:29,500 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:29,582 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:29,642 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:29,656 p=16287 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:34:29,670 p=16287 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:34:29,684 p=16287 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:34:29,732 p=16287 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-29 20:34:30,123 p=16287 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:34:30,161 p=16287 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:34:30,213 p=16287 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:34:30,225 p=16287 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-29 20:34:30,251 p=16287 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:34:30,272 p=16287 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:34:30,282 p=16287 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:34:30,283 p=16287 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 20:34:30,283 p=16287 u=root n=ansible INFO| lb-01                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:34:30,284 p=16287 u=root n=ansible INFO| master-01                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:34:30,284 p=16287 u=root n=ansible INFO| master-02                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:34:30,284 p=16287 u=root n=ansible INFO| worker-01                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:37:44,452 p=16769 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 20:37:44,456 p=16769 u=root n=ansible WARNING| [WARNING]:  * Failed to parse /root/ansible/build_k8s_cluster/hosts with yaml plugin: We were unable to read either as JSON nor
YAML, these are the errors we got from each: JSON: Expecting value: line 1 column 2 (char 1)  Syntax Error while loading YAML.   did
not find expected <document start>. did not find expected <document start>   in "<unicode string>", line 2, column 1  The error
appears to be in '/root/ansible/build_k8s_cluster/hosts': line 2, column 1, but may be elsewhere in the file depending on the exact
syntax problem.  The offending line appears to be:  [super-master] master-01 ansible_host=192.168.1.15 ansible_user=ansible-admin
node_IP=192.168.57.3 ^ here

2025-05-29 20:37:44,456 p=16769 u=root n=ansible WARNING| [WARNING]:  * Failed to parse /root/ansible/build_k8s_cluster/hosts with ini plugin: /root/ansible/build_k8s_cluster/hosts:19:
Expected key=value, got: HOME_USER: "{{ ansible_user }}"     # existing username not root  or  {{ ansible_user }}

2025-05-29 20:37:44,456 p=16769 u=root n=ansible WARNING| [WARNING]: Unable to parse /root/ansible/build_k8s_cluster/hosts as an inventory source

2025-05-29 20:37:44,456 p=16769 u=root n=ansible WARNING| [WARNING]: No inventory was parsed, only implicit localhost is available

2025-05-29 20:37:44,460 p=16769 u=root n=ansible WARNING| [WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

2025-05-29 20:37:44,633 p=16769 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 20:37:44,633 p=16769 u=root n=ansible INFO| skipping: no hosts matched
2025-05-29 20:37:44,634 p=16769 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 20:37:44,642 p=16769 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:37:47,143 p=16769 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:37:47,143 p=16769 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:37:47,153 p=16769 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 20:37:49,862 p=16769 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:37:49,873 p=16769 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 20:37:50,638 p=16769 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:37:50,649 p=16769 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 20:37:50,660 p=16769 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 20:37:50,668 p=16769 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:37:52,969 p=16769 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:37:52,969 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:53,066 p=16769 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:37:53,067 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:53,149 p=16769 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:37:53,149 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:53,160 p=16769 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 20:37:53,680 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:53,680 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:53,693 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:53,706 p=16769 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 20:37:54,101 p=16769 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:37:54,150 p=16769 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:37:54,157 p=16769 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:37:54,170 p=16769 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 20:37:54,638 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:54,654 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:54,659 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:54,703 p=16769 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 20:37:55,208 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:55,268 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:55,277 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:55,289 p=16769 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 20:37:56,328 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:56,328 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:56,342 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:56,354 p=16769 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-29 20:37:57,130 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:57,172 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:57,223 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:57,234 p=16769 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-29 20:37:58,655 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:58,875 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:58,889 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:58,901 p=16769 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-29 20:37:59,638 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:37:59,704 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:37:59,720 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:37:59,731 p=16769 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:37:59,744 p=16769 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:37:59,755 p=16769 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:37:59,795 p=16769 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-29 20:38:00,189 p=16769 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:00,227 p=16769 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:00,238 p=16769 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:00,250 p=16769 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-29 20:38:00,272 p=16769 u=root n=ansible INFO| fatal: [master-02]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:38:00,294 p=16769 u=root n=ansible INFO| fatal: [master-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:38:00,304 p=16769 u=root n=ansible INFO| fatal: [worker-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubernetes_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/k8s_packages/tasks/main.yml': line 10, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Download Kubernetes GPG key\n  ^ here\n"}
2025-05-29 20:38:00,305 p=16769 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 20:38:00,305 p=16769 u=root n=ansible INFO| lb-01                      : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:38:00,305 p=16769 u=root n=ansible INFO| master-01                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:38:00,305 p=16769 u=root n=ansible INFO| master-02                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:38:00,305 p=16769 u=root n=ansible INFO| worker-01                  : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-29 20:38:35,735 p=17172 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-29 20:38:35,910 p=17172 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-29 20:38:35,918 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:38:37,824 p=17172 u=root n=ansible WARNING| [WARNING]: Platform linux on host lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation
of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:38:37,825 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:37,919 p=17172 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:38:37,919 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:37,986 p=17172 u=root n=ansible WARNING| [WARNING]: Platform linux on host master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:38:37,986 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:38,459 p=17172 u=root n=ansible WARNING| [WARNING]: Platform linux on host worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-29 20:38:38,459 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:38,469 p=17172 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-29 20:38:39,011 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:39,024 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:39,031 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:39,049 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:39,060 p=17172 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-29 20:38:40,778 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:40,789 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:40,869 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:40,967 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:40,978 p=17172 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-29 20:38:41,540 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:41,545 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:41,577 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:41,581 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:41,591 p=17172 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-29 20:38:43,689 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:43,770 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:43,803 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:43,813 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:43,859 p=17172 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-29 20:38:43,870 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:38:45,093 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:45,103 p=17172 u=root n=ansible INFO| TASK [ha_proxy_lb : Update repositories cache and install "k8s" package] ************************************************************
2025-05-29 20:38:47,420 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:47,431 p=17172 u=root n=ansible INFO| TASK [ha_proxy_lb : Copy file with owner and permissions] ***************************************************************************
2025-05-29 20:38:48,193 p=17172 u=root n=ansible INFO| ok: [lb-01]
2025-05-29 20:38:48,205 p=17172 u=root n=ansible INFO| TASK [ha_proxy_lb : Force all notified handlers to run at this point, not waiting for normal sync points] ***************************
2025-05-29 20:38:48,217 p=17172 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-29 20:38:48,235 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:38:49,707 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:49,786 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:49,846 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:49,857 p=17172 u=root n=ansible INFO| TASK [swap_manage : Turn off all active swap] ***************************************************************************************
2025-05-29 20:38:50,381 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:50,406 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:50,417 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:50,429 p=17172 u=root n=ansible INFO| TASK [swap_manage : Create ansible_swap_OFF  file] **********************************************************************************
2025-05-29 20:38:50,824 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:38:50,857 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:38:50,898 p=17172 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:38:50,910 p=17172 u=root n=ansible INFO| TASK [swap_manage : Remove ALL swap entries from fstab (bulletproof)] ***************************************************************
2025-05-29 20:38:51,453 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:51,483 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:51,483 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:51,533 p=17172 u=root n=ansible INFO| TASK [containerd : ansible.posix.sysctl] ********************************************************************************************
2025-05-29 20:38:52,104 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:52,130 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:52,149 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:52,167 p=17172 u=root n=ansible INFO| TASK [containerd : Add Docker GPG key] **********************************************************************************************
2025-05-29 20:38:53,015 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:53,106 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:53,106 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:53,118 p=17172 u=root n=ansible INFO| TASK [containerd : Add Docker repository (Debian/Ubuntu)] ***************************************************************************
2025-05-29 20:38:53,868 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:53,957 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:53,961 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:53,973 p=17172 u=root n=ansible INFO| TASK [containerd : Install containerd (Debian/Ubuntu)] ******************************************************************************
2025-05-29 20:38:55,570 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:55,597 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:55,603 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:55,615 p=17172 u=root n=ansible INFO| TASK [containerd : Copy file with owner and permissions] ****************************************************************************
2025-05-29 20:38:56,385 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:56,447 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:56,470 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:56,484 p=17172 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:38:56,495 p=17172 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:38:56,508 p=17172 u=root n=ansible INFO| TASK [containerd : Force all notified handlers to run at this point, not waiting for normal sync points] ****************************
2025-05-29 20:38:56,556 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Create keyrings directory] *************************************************************************************
2025-05-29 20:38:57,001 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:57,005 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:57,012 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:57,026 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Download Kubernetes GPG key] ***********************************************************************************
2025-05-29 20:38:58,031 p=17172 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:38:58,047 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:38:58,073 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:38:58,085 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Convert and install key] ***************************************************************************************
2025-05-29 20:38:58,508 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:58,551 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:58,564 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:58,577 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Cleanup temp file] *********************************************************************************************
2025-05-29 20:38:59,006 p=17172 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:38:59,021 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:38:59,043 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:38:59,055 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Overwrite entire file content] *********************************************************************************
2025-05-29 20:38:59,863 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:38:59,873 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:38:59,887 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:38:59,900 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Update repositories cache and install "k8s" package] ***********************************************************
2025-05-29 20:39:15,370 p=17172 u=root n=ansible INFO| ok: [worker-01] => (item=kubectl)
2025-05-29 20:39:18,661 p=17172 u=root n=ansible INFO| ok: [master-01] => (item=kubectl)
2025-05-29 20:39:21,332 p=17172 u=root n=ansible INFO| ok: [master-01] => (item=kubelet)
2025-05-29 20:39:22,352 p=17172 u=root n=ansible INFO| ok: [worker-01] => (item=kubelet)
2025-05-29 20:39:24,250 p=17172 u=root n=ansible INFO| ok: [master-02] => (item=kubectl)
2025-05-29 20:39:25,764 p=17172 u=root n=ansible INFO| ok: [master-01] => (item=kubeadm)
2025-05-29 20:39:26,700 p=17172 u=root n=ansible INFO| ok: [worker-01] => (item=kubeadm)
2025-05-29 20:39:27,485 p=17172 u=root n=ansible INFO| ok: [master-02] => (item=kubelet)
2025-05-29 20:39:30,085 p=17172 u=root n=ansible INFO| ok: [master-02] => (item=kubeadm)
2025-05-29 20:39:30,099 p=17172 u=root n=ansible INFO| TASK [k8s_packages : Hold kubeadm properly] *****************************************************************************************
2025-05-29 20:39:30,617 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:39:30,649 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:39:30,658 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:39:30,696 p=17172 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-29 20:39:30,713 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:39:32,007 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:39:32,018 p=17172 u=root n=ansible INFO| TASK [cluster_init : Run command with arguments] ************************************************************************************
2025-05-29 20:39:52,732 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:39:52,761 p=17172 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 20:39:53,080 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:39:53,093 p=17172 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 20:39:53,590 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:39:53,615 p=17172 u=root n=ansible INFO| TASK [cluster_network : Apply weave net manifest to the cluster.] *******************************************************************
2025-05-29 20:39:56,611 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:39:56,645 p=17172 u=root n=ansible INFO| TASK [cluster_status : Gather cluster status] ***************************************************************************************
2025-05-29 20:39:56,664 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:39:56,680 p=17172 u=root n=ansible INFO| TASK [cluster_status : Gather system pods] ******************************************************************************************
2025-05-29 20:39:56,694 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:39:56,712 p=17172 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-29 20:39:56,726 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:39:58,362 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:39:58,538 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:39:58,552 p=17172 u=root n=ansible INFO| TASK [cluster_join_workers : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 20:39:58,576 p=17172 u=root n=ansible INFO| skipping: [worker-01]
2025-05-29 20:39:59,372 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:39:59,385 p=17172 u=root n=ansible INFO| TASK [cluster_join_workers : Join cluster directly (No file needed)] ****************************************************************
2025-05-29 20:39:59,426 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:40:03,435 p=17172 u=root n=ansible INFO| changed: [worker-01]
2025-05-29 20:40:03,463 p=17172 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-29 20:40:03,478 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:40:05,092 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:40:07,694 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:40:07,705 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : Run kubeadm token create and capture output] ***********************************************************
2025-05-29 20:40:07,728 p=17172 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:40:08,473 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:40:08,487 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : Get raw certificate key output] ************************************************************************
2025-05-29 20:40:08,514 p=17172 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:40:15,535 p=17172 u=root n=ansible INFO| changed: [master-01]
2025-05-29 20:40:15,550 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : Extract ONLY the certificate key (last line)] **********************************************************
2025-05-29 20:40:15,577 p=17172 u=root n=ansible INFO| skipping: [master-02]
2025-05-29 20:40:15,596 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:40:15,610 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : Construct master join command] *************************************************************************
2025-05-29 20:40:15,654 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:40:15,665 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:40:15,682 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : debug] *************************************************************************************************
2025-05-29 20:40:15,711 p=17172 u=root n=ansible INFO| ok: [master-02] => {
    "msg": "Master join command: kubeadm join lb-api-01.k8s.local:6443 --token v8mk1a.knyn1cag7xifd9my --discovery-token-ca-cert-hash sha256:948321a13b76717e398ee640b49c8be1641830d75dc15052414526f463582c2b  --control-plane --certificate-key d5395c6eb986464576d5088dc26fd1c69be7411957db96e35994fa2dbe753994 --apiserver-advertise-address 192.168.57.4  "
}
2025-05-29 20:40:15,721 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:40:15,737 p=17172 u=root n=ansible INFO| TASK [cluster_join_masters : Join master nodes] *************************************************************************************
2025-05-29 20:40:15,781 p=17172 u=root n=ansible INFO| skipping: [master-01]
2025-05-29 20:40:37,316 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:40:37,346 p=17172 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-29 20:40:37,365 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:40:46,691 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:40:46,708 p=17172 u=root n=ansible INFO| TASK [k8s_admin : Create a .kube directory] *****************************************************************************************
2025-05-29 20:40:47,219 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:40:47,231 p=17172 u=root n=ansible INFO| TASK [k8s_admin : Copy file admin.conf to .kube directory] **************************************************************************
2025-05-29 20:40:47,564 p=17172 u=root n=ansible INFO| changed: [master-02]
2025-05-29 20:40:47,578 p=17172 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-05-29 20:40:47,593 p=17172 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-29 20:40:49,151 p=17172 u=root n=ansible INFO| ok: [worker-01]
2025-05-29 20:40:49,189 p=17172 u=root n=ansible INFO| ok: [master-02]
2025-05-29 20:40:58,083 p=17172 u=root n=ansible INFO| ok: [master-01]
2025-05-29 20:40:58,118 p=17172 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-29 20:40:58,119 p=17172 u=root n=ansible INFO| lb-01                      : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-29 20:40:58,119 p=17172 u=root n=ansible INFO| master-01                  : ok=33   changed=10   unreachable=0    failed=0    skipped=6    rescued=0    ignored=0   
2025-05-29 20:40:58,119 p=17172 u=root n=ansible INFO| master-02                  : ok=29   changed=6    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-05-29 20:40:58,119 p=17172 u=root n=ansible INFO| worker-01                  : ok=24   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-31 00:01:12,752 p=2502 u=root n=ansible INFO| - Role roles/update_k8s_cluster was created successfully
2025-05-31 00:45:42,169 p=3240 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 00:45:50,969 p=3240 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 00:45:51,996 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:46:11,050 p=3240 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:46:11,051 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:46:29,156 p=3240 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:46:29,156 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:46:41,592 p=3240 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:46:41,593 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:46:42,170 p=3240 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:46:42,170 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:46:42,183 p=3240 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 00:46:42,902 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:46:42,926 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:46:42,962 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:46:42,975 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:46:42,988 p=3240 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 00:46:45,876 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:46:45,907 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:46:46,058 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:46:46,161 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:46:46,172 p=3240 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 00:46:46,831 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:46:46,876 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:46:46,903 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:46:46,910 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:46:46,925 p=3240 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 00:47:04,745 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:47:06,627 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:47:13,272 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:14,503 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:47:14,567 p=3240 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 00:47:14,586 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:15,891 p=3240 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:47:15,904 p=3240 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 00:47:15,926 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:17,460 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:47:17,576 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:47:17,653 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:17,790 p=3240 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 00:47:17,811 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:19,409 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:19,492 p=3240 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 00:47:19,509 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:21,150 p=3240 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:47:21,183 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:21,216 p=3240 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 00:47:21,237 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:22,813 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:47:22,919 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:22,949 p=3240 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 00:47:22,967 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:24,603 p=3240 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:47:24,621 p=3240 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 00:47:24,646 p=3240 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:47:26,240 p=3240 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:47:26,336 p=3240 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 00:47:27,024 p=3240 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubectl", "drain", "k8s-master-01", "--ignore-daemonsets", "--delete-local-data"], "delta": "0:00:00.126358", "end": "2025-05-30 21:47:26.979083", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 21:47:26.852725", "stderr": "error: unknown flag: --delete-local-data\nSee 'kubectl drain --help' for usage.", "stderr_lines": ["error: unknown flag: --delete-local-data", "See 'kubectl drain --help' for usage."], "stdout": "", "stdout_lines": []}
2025-05-31 00:47:27,024 p=3240 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:47:27,025 p=3240 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:47:27,025 p=3240 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 00:47:27,026 p=3240 u=root n=ansible INFO| k8s-lb-01                  : ok=6    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:47:27,026 p=3240 u=root n=ansible INFO| k8s-master-01              : ok=10   changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 00:47:27,026 p=3240 u=root n=ansible INFO| k8s-master-02              : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:47:27,026 p=3240 u=root n=ansible INFO| k8s-worker-01              : ok=7    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:48:45,601 p=4015 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 00:48:45,707 p=4015 u=root n=ansible ERROR| ERROR! 'gatherfacts' is not a valid attribute for a Play

The error appears to be in '/root/ansible/build_k8s_cluster/site.yml': line 9, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: prepere lb for kubernetes cluster masters
  ^ here

2025-05-31 00:50:34,991 p=4041 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 00:50:35,239 p=4041 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 00:50:35,250 p=4041 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:50:37,777 p=4041 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:50:37,777 p=4041 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:50:37,968 p=4041 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:50:37,969 p=4041 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:50:38,249 p=4041 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:50:38,249 p=4041 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:50:39,001 p=4041 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:50:39,001 p=4041 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:50:39,012 p=4041 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 00:50:39,534 p=4041 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:50:39,553 p=4041 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:50:39,571 p=4041 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:50:39,595 p=4041 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:50:39,607 p=4041 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 00:50:41,428 p=4041 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:50:41,435 p=4041 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:50:41,516 p=4041 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:50:41,556 p=4041 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:50:41,567 p=4041 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 00:50:42,153 p=4041 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:50:42,178 p=4041 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:50:42,181 p=4041 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:50:42,205 p=4041 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:50:42,221 p=4041 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 00:50:44,489 p=4041 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:50:44,509 p=4041 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:50:44,526 p=4041 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:50:44,626 p=4041 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:50:44,682 p=4041 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 00:50:44,699 p=4041 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 00:50:44,825 p=4041 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 00:50:44,883 p=4041 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 00:50:44,921 p=4041 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 00:50:44,951 p=4041 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 00:50:44,969 p=4041 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 00:50:44,987 p=4041 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 00:50:45,707 p=4041 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubectl", "drain", "k8s-master-01", "--ignore-daemonsets"], "delta": "0:00:00.243609", "end": "2025-05-30 21:50:45.654221", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 21:50:45.410612", "stderr": "E0530 21:50:45.632577   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:50:45.637865   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:50:45.641723   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:50:45.644622   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["E0530 21:50:45.632577   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:50:45.637865   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:50:45.641723   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:50:45.644622   17409 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
2025-05-31 00:50:45,708 p=4041 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:50:45,708 p=4041 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:50:45,708 p=4041 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 00:50:45,709 p=4041 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:50:45,709 p=4041 u=root n=ansible INFO| k8s-master-01              : ok=5    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 00:50:45,709 p=4041 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:50:45,709 p=4041 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:56:54,370 p=4899 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 00:56:54,934 p=4899 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 00:56:54,960 p=4899 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:57:01,317 p=4899 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:57:01,318 p=4899 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:57:01,434 p=4899 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:57:01,435 p=4899 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:57:01,564 p=4899 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:57:01,565 p=4899 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:57:01,787 p=4899 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:57:01,787 p=4899 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:57:01,817 p=4899 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 00:57:03,295 p=4899 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:57:03,298 p=4899 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:57:03,338 p=4899 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:57:03,347 p=4899 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:57:03,383 p=4899 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 00:57:07,823 p=4899 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:57:07,882 p=4899 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:57:07,899 p=4899 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:57:07,917 p=4899 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:57:07,949 p=4899 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 00:57:09,477 p=4899 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:57:09,505 p=4899 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:57:09,535 p=4899 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:57:09,607 p=4899 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:57:09,636 p=4899 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 00:57:14,792 p=4899 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:57:15,324 p=4899 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:57:15,390 p=4899 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:57:15,431 p=4899 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:57:15,577 p=4899 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 00:57:15,617 p=4899 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 00:57:15,915 p=4899 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 00:57:16,059 p=4899 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 00:57:16,135 p=4899 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 00:57:16,220 p=4899 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 00:57:16,276 p=4899 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 00:57:16,321 p=4899 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 00:57:18,026 p=4899 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubectl", "drain", "k8s-master-01", "--ignore-daemonsets"], "delta": "0:00:00.211105", "end": "2025-05-30 21:57:17.882000", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 21:57:17.670895", "stderr": "E0530 21:57:17.863817   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:57:17.866840   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:57:17.870001   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:57:17.872829   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["E0530 21:57:17.863817   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:57:17.866840   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:57:17.870001   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:57:17.872829   18190 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
2025-05-31 00:57:18,028 p=4899 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:57:18,029 p=4899 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:57:18,034 p=4899 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 00:57:18,036 p=4899 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:57:18,037 p=4899 u=root n=ansible INFO| k8s-master-01              : ok=5    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 00:57:18,037 p=4899 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:57:18,039 p=4899 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:58:16,940 p=5280 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 00:58:17,534 p=5280 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 00:58:17,589 p=5280 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:58:23,826 p=5280 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:58:23,827 p=5280 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:58:24,097 p=5280 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:58:24,098 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:24,314 p=5280 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:58:24,315 p=5280 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:58:24,341 p=5280 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 00:58:24,341 p=5280 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:58:24,370 p=5280 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 00:58:25,794 p=5280 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:58:25,844 p=5280 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:58:25,845 p=5280 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:58:25,913 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:25,942 p=5280 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 00:58:30,466 p=5280 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:58:30,590 p=5280 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:58:30,664 p=5280 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:58:30,804 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:30,839 p=5280 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 00:58:32,385 p=5280 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:58:32,459 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:32,480 p=5280 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:58:32,511 p=5280 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:58:32,554 p=5280 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 00:58:37,983 p=5280 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 00:58:37,999 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:38,138 p=5280 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 00:58:38,418 p=5280 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 00:58:38,566 p=5280 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 00:58:38,606 p=5280 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 00:58:38,933 p=5280 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 00:58:39,075 p=5280 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 00:58:39,151 p=5280 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 00:58:39,238 p=5280 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 00:58:39,288 p=5280 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 00:58:39,328 p=5280 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 00:58:42,796 p=5280 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 00:58:42,843 p=5280 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 00:58:44,528 p=5280 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubectl", "drain", "k8s-master-01", "--ignore-daemonsets"], "delta": "0:00:00.248300", "end": "2025-05-30 21:58:44.427065", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 21:58:44.178765", "stderr": "E0530 21:58:44.412013   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:58:44.415153   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:58:44.417850   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 21:58:44.420362   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["E0530 21:58:44.412013   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:58:44.415153   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:58:44.417850   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 21:58:44.420362   18616 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
2025-05-31 00:58:44,530 p=5280 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:58:44,531 p=5280 u=root n=ansible INFO| NO MORE HOSTS LEFT ******************************************************************************************************************
2025-05-31 00:58:44,534 p=5280 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 00:58:44,536 p=5280 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:58:44,537 p=5280 u=root n=ansible INFO| k8s-master-01              : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 00:58:44,538 p=5280 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 00:58:44,539 p=5280 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:01:45,005 p=5815 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:01:45,628 p=5815 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 01:01:45,660 p=5815 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:01:51,945 p=5815 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:01:51,946 p=5815 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:01:52,061 p=5815 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:01:52,063 p=5815 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:01:52,325 p=5815 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:01:52,326 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:01:52,449 p=5815 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:01:52,450 p=5815 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:01:52,483 p=5815 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 01:01:53,894 p=5815 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:01:53,938 p=5815 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:01:54,068 p=5815 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:01:54,078 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:01:54,109 p=5815 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 01:01:58,540 p=5815 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:01:58,599 p=5815 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:01:58,675 p=5815 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:01:58,780 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:01:58,817 p=5815 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 01:02:00,312 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:02:00,314 p=5815 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:02:00,380 p=5815 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:02:00,429 p=5815 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:02:00,462 p=5815 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 01:02:05,839 p=5815 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:02:06,120 p=5815 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:02:06,205 p=5815 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:02:06,300 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:02:06,451 p=5815 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:02:06,500 p=5815 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:02:06,816 p=5815 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:02:06,980 p=5815 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:02:07,032 p=5815 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:02:07,109 p=5815 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:02:07,165 p=5815 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:02:07,214 p=5815 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:02:10,749 p=5815 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:02:10,785 p=5815 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:02:12,337 p=5815 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubectl", "drain", "k8s-master-01", "--ignore-daemonsets"], "delta": "0:00:00.194076", "end": "2025-05-30 22:02:12.241906", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 22:02:12.047830", "stderr": "E0530 22:02:12.228457   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 22:02:12.230910   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 22:02:12.233447   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0530 22:02:12.235904   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["E0530 22:02:12.228457   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 22:02:12.230910   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 22:02:12.233447   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0530 22:02:12.235904   19071 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
2025-05-31 01:02:12,340 p=5815 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:02:12,341 p=5815 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:02:12,342 p=5815 u=root n=ansible INFO| k8s-master-01              : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:02:12,343 p=5815 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:02:12,344 p=5815 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:04:23,620 p=6315 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:04:24,223 p=6315 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 01:04:24,252 p=6315 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:04:30,843 p=6315 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:04:30,844 p=6315 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:04:30,901 p=6315 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:04:30,902 p=6315 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:04:31,108 p=6315 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:04:31,109 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:31,256 p=6315 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:04:31,257 p=6315 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:04:31,285 p=6315 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 01:04:32,702 p=6315 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:04:32,751 p=6315 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:04:32,771 p=6315 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:04:32,819 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:32,858 p=6315 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 01:04:37,274 p=6315 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:04:37,314 p=6315 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:04:37,585 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:37,588 p=6315 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:04:37,618 p=6315 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 01:04:39,184 p=6315 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:04:39,232 p=6315 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:04:39,275 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:39,283 p=6315 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:04:39,318 p=6315 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 01:04:45,019 p=6315 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:04:45,180 p=6315 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:04:45,253 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:45,267 p=6315 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:04:45,417 p=6315 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:04:45,460 p=6315 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:04:45,782 p=6315 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:04:45,927 p=6315 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:04:46,003 p=6315 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:04:46,087 p=6315 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:04:46,138 p=6315 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:04:46,183 p=6315 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:04:49,548 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:04:49,610 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:04:51,339 p=6315 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:04:51,402 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:04:54,497 p=6315 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:04:54,538 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:05:06,712 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:05:06,790 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:05:45,686 p=6315 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl)
2025-05-31 01:05:54,922 p=6315 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet)
2025-05-31 01:06:02,446 p=6315 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm)
2025-05-31 01:06:02,496 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-05-31 01:06:04,000 p=6315 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:06:04,041 p=6315 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-05-31 01:06:12,573 p=6315 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "upgrade", "apply", "v1.33"], "delta": "0:00:07.552980", "end": "2025-05-30 22:06:12.412076", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 22:06:04.859096", "stderr": "error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[upgrade] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.\n[upgrade/preflight] Running preflight checks\n[upgrade] Running cluster health checks", "stdout_lines": ["[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[upgrade] Use 'kubeadm init phase upload-config --config your-config.yaml' to re-upload it.", "[upgrade/preflight] Running preflight checks", "[upgrade] Running cluster health checks"]}
2025-05-31 01:06:12,576 p=6315 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:06:12,577 p=6315 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:06:12,577 p=6315 u=root n=ansible INFO| k8s-master-01              : ok=11   changed=2    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:06:12,578 p=6315 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:06:12,578 p=6315 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:09:31,071 p=7050 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:09:31,657 p=7050 u=root n=ansible INFO| PLAY [manage kubernetes cluster] ****************************************************************************************************
2025-05-31 01:09:31,680 p=7050 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:09:38,469 p=7050 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:09:38,470 p=7050 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:09:38,481 p=7050 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-lb-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:09:38,482 p=7050 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:09:38,861 p=7050 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:09:38,862 p=7050 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:09:40,974 p=7050 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:09:40,975 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:09:41,005 p=7050 u=root n=ansible INFO| TASK [common : Example from an Ansible Playbook] ************************************************************************************
2025-05-31 01:09:42,563 p=7050 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:09:42,615 p=7050 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:09:42,619 p=7050 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:09:42,689 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:09:42,720 p=7050 u=root n=ansible INFO| TASK [common : Install pip (if missing)] ********************************************************************************************
2025-05-31 01:09:47,334 p=7050 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:09:47,377 p=7050 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:09:47,543 p=7050 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:09:47,616 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:09:47,650 p=7050 u=root n=ansible INFO| TASK [common : Append local file content to remote file (idempotent)] ***************************************************************
2025-05-31 01:09:49,285 p=7050 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:09:49,296 p=7050 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:09:49,330 p=7050 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:09:49,377 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:09:49,408 p=7050 u=root n=ansible INFO| TASK [common : Install kubernetes package] ******************************************************************************************
2025-05-31 01:09:55,061 p=7050 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-05-31 01:09:55,405 p=7050 u=root n=ansible INFO| ok: [k8s-lb-01]
2025-05-31 01:09:55,594 p=7050 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 01:09:56,705 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:09:56,831 p=7050 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:09:56,863 p=7050 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:09:57,177 p=7050 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:09:57,324 p=7050 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:09:57,403 p=7050 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:09:57,486 p=7050 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:09:57,537 p=7050 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:09:57,584 p=7050 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:10:01,096 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:10:01,125 p=7050 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:10:10,768 p=7050 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:10:10,806 p=7050 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:10:14,374 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:10:14,411 p=7050 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:10:15,731 p=7050 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:10:15,772 p=7050 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:10:36,584 p=7050 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubectl='1.33') => {"ansible_loop_var": "item", "cache_update_time": 1748643022, "cache_updated": true, "changed": false, "item": "kubectl='1.33'", "msg": "no available installation candidate for kubectl='1.33'"}
2025-05-31 01:10:44,595 p=7050 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubelet='1.33') => {"ansible_loop_var": "item", "cache_update_time": 1748643042, "cache_updated": true, "changed": false, "item": "kubelet='1.33'", "msg": "no available installation candidate for kubelet='1.33'"}
2025-05-31 01:10:50,996 p=7050 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubeadm='1.33') => {"ansible_loop_var": "item", "cache_update_time": 1748643049, "cache_updated": true, "changed": false, "item": "kubeadm='1.33'", "msg": "no available installation candidate for kubeadm='1.33'"}
2025-05-31 01:10:51,004 p=7050 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:10:51,005 p=7050 u=root n=ansible INFO| k8s-lb-01                  : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:10:51,006 p=7050 u=root n=ansible INFO| k8s-master-01              : ok=9    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:10:51,007 p=7050 u=root n=ansible INFO| k8s-master-02              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:10:51,008 p=7050 u=root n=ansible INFO| k8s-worker-01              : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 01:11:53,148 p=7712 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:11:53,735 p=7712 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:11:53,770 p=7712 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:11:53,825 p=7712 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:11:53,859 p=7712 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:11:53,882 p=7712 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:11:53,904 p=7712 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:11:53,918 p=7712 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:11:53,941 p=7712 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:12:00,366 p=7712 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:12:00,367 p=7712 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:12:00,403 p=7712 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:12:01,977 p=7712 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:12:02,017 p=7712 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:12:04,515 p=7712 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:12:04,578 p=7712 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:12:06,030 p=7712 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:12:06,067 p=7712 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:12:13,170 p=7712 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubectl='1.33.1-1.1') => {"ansible_loop_var": "item", "cache_update_time": 1748643131, "cache_updated": true, "changed": false, "item": "kubectl='1.33.1-1.1'", "msg": "no available installation candidate for kubectl='1.33.1-1.1'"}
2025-05-31 01:12:19,524 p=7712 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubelet='1.33.1-1.1') => {"ansible_loop_var": "item", "cache_update_time": 1748643137, "cache_updated": true, "changed": false, "item": "kubelet='1.33.1-1.1'", "msg": "no available installation candidate for kubelet='1.33.1-1.1'"}
2025-05-31 01:12:25,938 p=7712 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubeadm='1.33.1-1.1') => {"ansible_loop_var": "item", "cache_update_time": 1748643144, "cache_updated": true, "changed": false, "item": "kubeadm='1.33.1-1.1'", "msg": "no available installation candidate for kubeadm='1.33.1-1.1'"}
2025-05-31 01:12:25,943 p=7712 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:12:25,944 p=7712 u=root n=ansible INFO| k8s-master-01              : ok=4    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:14:15,474 p=7934 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:14:16,020 p=7934 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:14:16,055 p=7934 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:14:16,110 p=7934 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:14:16,142 p=7934 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:14:16,165 p=7934 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:14:16,187 p=7934 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:14:16,202 p=7934 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:14:16,220 p=7934 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:14:22,492 p=7934 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:14:22,493 p=7934 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:14:22,538 p=7934 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:14:24,356 p=7934 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:14:24,413 p=7934 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:14:26,971 p=7934 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:14:27,012 p=7934 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:14:28,330 p=7934 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:14:28,370 p=7934 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:14:35,504 p=7934 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubectl=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643273, "cache_updated": true, "changed": false, "item": "kubectl=1.33", "msg": "no available installation candidate for kubectl=1.33"}
2025-05-31 01:14:42,092 p=7934 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubelet=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643280, "cache_updated": true, "changed": false, "item": "kubelet=1.33", "msg": "no available installation candidate for kubelet=1.33"}
2025-05-31 01:14:48,893 p=7934 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubeadm=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643287, "cache_updated": true, "changed": false, "item": "kubeadm=1.33", "msg": "no available installation candidate for kubeadm=1.33"}
2025-05-31 01:14:48,902 p=7934 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:14:48,903 p=7934 u=root n=ansible INFO| k8s-master-01              : ok=4    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:25:03,032 p=8709 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:25:03,628 p=8709 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:25:03,662 p=8709 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:25:03,717 p=8709 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:25:03,747 p=8709 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:25:03,770 p=8709 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:25:03,793 p=8709 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:25:03,809 p=8709 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:25:03,826 p=8709 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:25:09,994 p=8709 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:25:09,995 p=8709 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:25:10,029 p=8709 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:25:11,623 p=8709 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:25:11,680 p=8709 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:25:14,307 p=8709 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:25:14,348 p=8709 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:25:15,502 p=8709 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:25:15,539 p=8709 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:25:22,827 p=8709 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubectl=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643921, "cache_updated": true, "changed": false, "item": "kubectl=1.33", "msg": "no available installation candidate for kubectl=1.33"}
2025-05-31 01:25:29,353 p=8709 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubelet=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643927, "cache_updated": true, "changed": false, "item": "kubelet=1.33", "msg": "no available installation candidate for kubelet=1.33"}
2025-05-31 01:25:35,832 p=8709 u=root n=ansible INFO| failed: [k8s-master-01] (item=kubeadm=1.33) => {"ansible_loop_var": "item", "cache_update_time": 1748643934, "cache_updated": true, "changed": false, "item": "kubeadm=1.33", "msg": "no available installation candidate for kubeadm=1.33"}
2025-05-31 01:25:35,840 p=8709 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:25:35,841 p=8709 u=root n=ansible INFO| k8s-master-01              : ok=4    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:26:08,299 p=8953 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:26:08,850 p=8953 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:26:08,885 p=8953 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:26:08,936 p=8953 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:26:08,967 p=8953 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:26:08,991 p=8953 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:26:09,013 p=8953 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:26:09,027 p=8953 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:26:09,043 p=8953 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:26:13,805 p=8953 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:26:13,806 p=8953 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:26:13,847 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:26:15,448 p=8953 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:26:15,491 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:26:18,048 p=8953 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:26:18,090 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:26:19,439 p=8953 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:26:19,479 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:26:56,399 p=8953 u=root n=ansible INFO| changed: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 01:27:54,979 p=8953 u=root n=ansible INFO| changed: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 01:28:35,389 p=8953 u=root n=ansible INFO| changed: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 01:28:35,435 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-05-31 01:28:37,280 p=8953 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:28:37,319 p=8953 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-05-31 01:28:44,851 p=8953 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "upgrade", "apply", "v1.33"], "delta": "0:00:06.576260", "end": "2025-05-30 22:28:44.705989", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 22:28:38.129729", "stderr": "error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.\n[upgrade/preflight] Running preflight checks\n[upgrade] Running cluster health checks", "stdout_lines": ["[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.", "[upgrade/preflight] Running preflight checks", "[upgrade] Running cluster health checks"]}
2025-05-31 01:28:44,854 p=8953 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:28:44,855 p=8953 u=root n=ansible INFO| k8s-master-01              : ok=6    changed=2    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:30:06,873 p=9250 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:30:07,429 p=9250 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:30:07,474 p=9250 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:30:07,532 p=9250 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:30:07,563 p=9250 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:30:07,591 p=9250 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:30:07,618 p=9250 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:30:07,633 p=9250 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:30:07,655 p=9250 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:30:16,177 p=9250 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:30:16,178 p=9250 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:30:16,217 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:30:22,607 p=9250 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:30:22,649 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:30:25,329 p=9250 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:30:25,369 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:30:28,575 p=9250 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:30:28,613 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:30:50,198 p=9250 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 01:30:57,718 p=9250 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 01:31:05,433 p=9250 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 01:31:05,477 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-05-31 01:31:06,808 p=9250 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:31:06,845 p=9250 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-05-31 01:31:16,228 p=9250 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "upgrade", "apply", "v1.33", "--kubeconfig", "/home/ansible-admin/.kube/config"], "delta": "0:00:08.460356", "end": "2025-05-30 22:31:16.081775", "msg": "non-zero return code", "rc": 1, "start": "2025-05-30 22:31:07.621419", "stderr": "error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: version \"v1.33\" doesn't match patterns for neither semantic version nor labels (stable, latest, ...)", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.\n[upgrade/preflight] Running preflight checks\n[upgrade] Running cluster health checks", "stdout_lines": ["[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.", "[upgrade/preflight] Running preflight checks", "[upgrade] Running cluster health checks"]}
2025-05-31 01:31:16,231 p=9250 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 01:31:16,232 p=9250 u=root n=ansible INFO| k8s-master-01              : ok=6    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 01:35:40,916 p=9624 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:35:41,524 p=9624 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:35:41,552 p=9624 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:35:41,612 p=9624 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:35:41,654 p=9624 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:35:41,677 p=9624 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:35:41,701 p=9624 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:35:41,727 p=9624 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:35:41,745 p=9624 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:35:50,106 p=9624 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:35:50,107 p=9624 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:35:50,143 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:35:51,928 p=9624 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:35:51,970 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:35:54,584 p=9624 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:35:54,661 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:35:58,264 p=9624 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:35:58,316 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:36:20,340 p=9624 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 01:36:27,795 p=9624 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 01:36:35,442 p=9624 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 01:36:35,483 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-05-31 01:36:36,916 p=9624 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:36:36,962 p=9624 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-05-31 01:55:50,332 p=9624 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-31 01:55:57,650 p=11410 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 01:55:58,232 p=11410 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 01:55:58,266 p=11410 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 01:55:58,321 p=11410 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 01:55:58,352 p=11410 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 01:55:58,376 p=11410 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 01:55:58,399 p=11410 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 01:55:58,415 p=11410 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 01:55:58,434 p=11410 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 01:56:02,971 p=11410 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 01:56:02,972 p=11410 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:56:03,010 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-05-31 01:56:04,554 p=11410 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 01:56:04,600 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-05-31 01:56:07,307 p=11410 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:56:07,369 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-05-31 01:56:10,082 p=11410 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:56:10,121 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-05-31 01:56:32,588 p=11410 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 01:56:40,582 p=11410 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 01:56:48,545 p=11410 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 01:56:48,605 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-05-31 01:56:50,076 p=11410 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 01:56:50,133 p=11410 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-05-31 02:37:11,243 p=11410 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-05-31 22:37:39,871 p=3979 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 22:37:42,546 p=3979 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************************************
2025-05-31 22:37:42,726 p=3979 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************************************
2025-05-31 22:37:42,797 p=3979 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************************************
2025-05-31 22:37:42,830 p=3979 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************************************
2025-05-31 22:37:42,864 p=3979 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************************************
2025-05-31 22:37:42,891 p=3979 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************************************
2025-05-31 22:37:42,907 p=3979 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************************************
2025-05-31 22:37:42,941 p=3979 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************************************
2025-05-31 22:37:55,772 p=3979 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of another Python
interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-core/2.18/reference_appendices/interpreter_discovery.html for more
information.

2025-05-31 22:37:55,773 p=3979 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:37:55,850 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************************************
2025-05-31 22:38:06,156 p=3979 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 22:38:06,226 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************************************
2025-05-31 22:38:09,246 p=3979 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:38:09,287 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************************************
2025-05-31 22:38:15,750 p=3979 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:38:15,775 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************************************
2025-05-31 22:39:03,344 p=3979 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 22:39:13,593 p=3979 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 22:39:21,389 p=3979 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 22:39:21,449 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************************************
2025-05-31 22:39:22,917 p=3979 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:39:22,960 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************************************
2025-05-31 22:44:36,534 p=3979 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 22:44:36,571 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************************************
2025-05-31 22:44:36,614 p=3979 u=root n=ansible INFO| skipping: [k8s-master-01]
2025-05-31 22:44:36,650 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : uncordon node after update] *****************************************************************************************************
2025-05-31 22:44:48,636 p=3979 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 22:44:48,690 p=3979 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************************************
2025-05-31 22:44:48,714 p=3979 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************************************
2025-05-31 22:45:00,696 p=3979 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of another Python
interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-core/2.18/reference_appendices/interpreter_discovery.html for more
information.

2025-05-31 22:45:00,697 p=3979 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 22:45:00,745 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************************************
2025-05-31 22:45:16,450 p=3979 u=root n=ansible INFO| changed: [k8s-master-02]
2025-05-31 22:45:16,498 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************************************
2025-05-31 22:45:20,849 p=3979 u=root n=ansible INFO| changed: [k8s-master-02]
2025-05-31 22:45:20,899 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************************************
2025-05-31 22:45:37,066 p=3979 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 22:45:37,150 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************************************
2025-05-31 22:47:01,649 p=3979 u=root n=ansible INFO| changed: [k8s-master-02] => (item=kubectl=1.33.1-1.1 )
2025-05-31 22:47:51,604 p=3979 u=root n=ansible INFO| changed: [k8s-master-02] => (item=kubelet=1.33.1-1.1 )
2025-05-31 22:48:30,643 p=3979 u=root n=ansible INFO| changed: [k8s-master-02] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 22:48:30,699 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************************************
2025-05-31 22:48:32,123 p=3979 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 22:48:32,165 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************************************
2025-05-31 22:48:32,217 p=3979 u=root n=ansible INFO| skipping: [k8s-master-02]
2025-05-31 22:48:32,264 p=3979 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************************************
2025-05-31 22:48:33,366 p=3979 u=root n=ansible INFO| fatal: [k8s-master-02]: FAILED! => {"changed": true, "cmd": ["kubeadm", "upgrade", "k8s-master-02", "--kubeconfig", "/home/ansible-admin/.kube/config"], "delta": "0:00:00.107666", "end": "2025-05-31 19:48:33.259448", "msg": "non-zero return code", "rc": 1, "start": "2025-05-31 19:48:33.151782", "stderr": "unknown flag: --kubeconfig\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["unknown flag: --kubeconfig", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "", "stdout_lines": []}
2025-05-31 22:48:33,370 p=3979 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************************************
2025-05-31 22:48:33,371 p=3979 u=root n=ansible INFO| k8s-master-01              : ok=8    changed=3    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-05-31 22:48:33,372 p=3979 u=root n=ansible INFO| k8s-master-02              : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-05-31 22:58:05,681 p=5185 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 22:58:06,212 p=5185 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************************************
2025-05-31 22:58:06,264 p=5185 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************************************
2025-05-31 22:58:06,325 p=5185 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************************************
2025-05-31 22:58:06,363 p=5185 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************************************
2025-05-31 22:58:06,383 p=5185 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************************************
2025-05-31 22:58:06,403 p=5185 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************************************
2025-05-31 22:58:06,417 p=5185 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************************************
2025-05-31 22:58:06,432 p=5185 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************************************
2025-05-31 22:58:18,777 p=5185 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future installation of another Python
interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-core/2.18/reference_appendices/interpreter_discovery.html for more
information.

2025-05-31 22:58:18,778 p=5185 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:58:18,816 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************************************
2025-05-31 22:58:30,515 p=5185 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 22:58:30,556 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************************************
2025-05-31 22:58:33,486 p=5185 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:58:33,528 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************************************
2025-05-31 22:58:37,980 p=5185 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:58:38,050 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************************************
2025-05-31 22:59:05,472 p=5185 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-05-31 22:59:13,841 p=5185 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubelet=1.33.1-1.1 )
2025-05-31 22:59:38,748 p=5185 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubeadm=1.33.1-1.1 )
2025-05-31 22:59:38,833 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************************************
2025-05-31 22:59:40,833 p=5185 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 22:59:40,910 p=5185 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************************************
2025-05-31 23:00:03,275 p=5185 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": ["kubeadm", "upgrade", "apply", "v1.33.1", "--kubeconfig", "/home/ansible-admin/.kube/config", "--yes"], "delta": "0:00:21.269653", "end": "2025-05-31 20:00:03.070249", "msg": "non-zero return code", "rc": 1, "start": "2025-05-31 19:59:41.800596", "stderr": "error execution phase preflight: [preflight] Some fatal errors occurred:\n\t[ERROR CreateJob]: Job \"upgrade-health-check-1748721587793\" in the namespace \"kube-system\" did not complete in 15s: no condition of type Complete\n[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`\nTo see the stack trace of this error execute with --v=5 or higher", "stderr_lines": ["error execution phase preflight: [preflight] Some fatal errors occurred:", "\t[ERROR CreateJob]: Job \"upgrade-health-check-1748721587793\" in the namespace \"kube-system\" did not complete in 15s: no condition of type Complete", "[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`", "To see the stack trace of this error execute with --v=5 or higher"], "stdout": "[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...\n[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.\n[upgrade/preflight] Running preflight checks\n[upgrade] Running cluster health checks", "stdout_lines": ["[upgrade] Reading configuration from the \"kubeadm-config\" ConfigMap in namespace \"kube-system\"...", "[upgrade] Use 'kubeadm init phase upload-config --config your-config-file' to re-upload it.", "[upgrade/preflight] Running preflight checks", "[upgrade] Running cluster health checks"]}
2025-05-31 23:00:03,281 p=5185 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************************************
2025-05-31 23:00:03,282 p=5185 u=root n=ansible INFO| k8s-master-01              : ok=6    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:11:50,030 p=6164 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:11:50,602 p=6164 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:11:50,638 p=6164 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:11:50,683 p=6164 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:11:50,716 p=6164 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:11:50,738 p=6164 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:11:50,759 p=6164 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:11:50,771 p=6164 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:11:50,786 p=6164 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:11:57,960 p=6164 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:11:57,961 p=6164 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:11:58,003 p=6164 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Get kubeadm version] ************************************************************************************
2025-05-31 23:11:59,595 p=6164 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:11:59,637 p=6164 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion from kubeadm output] *****************************************************************
2025-05-31 23:11:59,724 p=6164 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'dict object' has no attribute 'GitVersion'\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/upgrade_k8s_cluster/tasks/main.yml': line 9, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Extract GitVersion from kubeadm output\n  ^ here\n"}
2025-05-31 23:11:59,726 p=6164 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:11:59,727 p=6164 u=root n=ansible INFO| k8s-master-01              : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:14:13,961 p=6270 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:14:14,546 p=6270 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:14:14,583 p=6270 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:14:14,644 p=6270 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:14:14,687 p=6270 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:14:14,711 p=6270 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:14:14,736 p=6270 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:14:14,751 p=6270 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:14:14,769 p=6270 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:14:21,396 p=6270 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:14:21,397 p=6270 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:14:21,434 p=6270 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Get kubeadm version] ************************************************************************************
2025-05-31 23:14:22,842 p=6270 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:14:22,889 p=6270 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion using regex] *************************************************************************
2025-05-31 23:14:22,968 p=6270 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"msg": "Unexpected templating type error occurred on ({{ kubeadm_version_output.stdout | regex_search('GitVersion:\"([^\"]+)\"', '\\\\1') | first }}): 'NoneType' object is not iterable. 'NoneType' object is not iterable"}
2025-05-31 23:14:22,971 p=6270 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:14:22,972 p=6270 u=root n=ansible INFO| k8s-master-01              : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:18:11,890 p=6359 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:18:12,381 p=6359 u=root n=ansible ERROR| ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected key. while parsing a block mapping
  in "<unicode string>", line 10, column 5
did not find expected key
  in "<unicode string>", line 10, column 78

The error appears to be in '/root/ansible/build_k8s_cluster/roles/upgrade_k8s_cluster/tasks/main.yml': line 10, column 78, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  set_fact:
    kubeadm_version: "{{ kubeadm_output.stdout | regex_search('GitVersion:\\"(v[0-9.]+)\\"', '\\1') }}"
                                                                             ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

2025-05-31 23:19:33,941 p=6400 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:19:34,573 p=6400 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:19:34,610 p=6400 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:19:34,661 p=6400 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:19:34,690 p=6400 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:19:34,715 p=6400 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:19:34,737 p=6400 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:19:34,752 p=6400 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:19:34,774 p=6400 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:19:41,199 p=6400 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:19:41,200 p=6400 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:19:41,277 p=6400 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-05-31 23:19:42,761 p=6400 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 23:19:42,805 p=6400 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion] *************************************************************************************
2025-05-31 23:19:42,908 p=6400 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:19:43,016 p=6400 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-05-31 23:19:43,073 p=6400 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"msg": "The conditional check 'kubeadm_git_version == kubeadm_version' failed. The error was: error while evaluating conditional (kubeadm_git_version == kubeadm_version): 'kubeadm_git_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/upgrade_k8s_cluster/tasks/main.yml': line 12, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Fail if versions are already the same\n  ^ here\n"}
2025-05-31 23:19:43,076 p=6400 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:19:43,077 p=6400 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:21:19,054 p=6491 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:21:19,582 p=6491 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:21:19,616 p=6491 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:21:19,681 p=6491 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:21:19,712 p=6491 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:21:19,735 p=6491 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:21:19,758 p=6491 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:21:19,774 p=6491 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:21:19,794 p=6491 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:21:26,321 p=6491 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:21:26,321 p=6491 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:21:26,352 p=6491 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-05-31 23:21:27,810 p=6491 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 23:21:27,856 p=6491 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion] *************************************************************************************
2025-05-31 23:21:27,941 p=6491 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:21:27,982 p=6491 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-05-31 23:21:28,047 p=6491 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"msg": "The task includes an option with an undefined variable.. 'kubeadm_git_version' is undefined\n\nThe error appears to be in '/root/ansible/build_k8s_cluster/roles/upgrade_k8s_cluster/tasks/main.yml': line 12, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n- name: Fail if versions are already the same\n  ^ here\n"}
2025-05-31 23:21:28,052 p=6491 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:21:28,053 p=6491 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:21:59,137 p=6582 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:21:59,745 p=6582 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:21:59,778 p=6582 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:21:59,831 p=6582 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:21:59,862 p=6582 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:21:59,885 p=6582 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:21:59,906 p=6582 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:21:59,924 p=6582 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:21:59,948 p=6582 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:22:04,711 p=6582 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:22:04,712 p=6582 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:22:04,749 p=6582 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-05-31 23:22:06,160 p=6582 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 23:22:06,202 p=6582 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion] *************************************************************************************
2025-05-31 23:22:06,292 p=6582 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:22:06,331 p=6582 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-05-31 23:22:06,396 p=6582 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": false, "msg": "kubeadm version ['v1.33.1'] already matches required version ['v1.33.1'] - no need to upgrade"}
2025-05-31 23:22:06,398 p=6582 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:22:06,399 p=6582 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-05-31 23:27:43,654 p=6676 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-05-31 23:27:44,306 p=6676 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-05-31 23:27:44,337 p=6676 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-05-31 23:27:44,388 p=6676 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-05-31 23:27:44,423 p=6676 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-05-31 23:27:44,444 p=6676 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-05-31 23:27:44,458 p=6676 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-05-31 23:27:44,474 p=6676 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:27:44,491 p=6676 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:27:51,185 p=6676 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:27:51,186 p=6676 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:27:51,220 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-05-31 23:27:52,605 p=6676 u=root n=ansible INFO| changed: [k8s-master-01]
2025-05-31 23:27:52,648 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion] *************************************************************************************
2025-05-31 23:27:52,725 p=6676 u=root n=ansible INFO| ok: [k8s-master-01]
2025-05-31 23:27:52,759 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-05-31 23:27:52,806 p=6676 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:27:52,827 p=6676 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:28:00,829 p=6676 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-05-31 23:28:00,830 p=6676 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 23:28:00,870 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-05-31 23:28:01,932 p=6676 u=root n=ansible INFO| changed: [k8s-master-02]
2025-05-31 23:28:01,978 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Extract GitVersion] *************************************************************************************
2025-05-31 23:28:02,070 p=6676 u=root n=ansible INFO| ok: [k8s-master-02]
2025-05-31 23:28:02,116 p=6676 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-05-31 23:28:02,177 p=6676 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-05-31 23:28:02,198 p=6676 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-05-31 23:28:05,401 p=6676 u=root n=ansible INFO| fatal: [k8s-worker-01]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: ssh: connect to host 192.168.1.16 port 22: No route to host", "unreachable": true}
2025-05-31 23:28:05,405 p=6676 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-05-31 23:28:05,406 p=6676 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 23:28:05,408 p=6676 u=root n=ansible INFO| k8s-master-02              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-05-31 23:28:05,410 p=6676 u=root n=ansible INFO| k8s-worker-01              : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
2025-06-01 00:10:40,292 p=8635 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-06-01 00:10:40,503 p=8635 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-06-01 00:10:40,514 p=8635 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-06-01 00:10:40,536 p=8635 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-06-01 00:10:40,545 p=8635 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-06-01 00:10:40,553 p=8635 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-06-01 00:10:40,559 p=8635 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-06-01 00:10:40,564 p=8635 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:10:40,569 p=8635 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:10:45,083 p=8635 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:10:45,083 p=8635 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:10:45,096 p=8635 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:10:45,642 p=8635 u=root n=ansible INFO| fatal: [k8s-master-01]: FAILED! => {"changed": true, "cmd": "kubectl get node k8s-master-02 -o jsonpath='{.status.nodeInfo.kubeletVersion}'", "delta": "0:00:00.108157", "end": "2025-05-31 21:10:45.613061", "msg": "non-zero return code", "rc": 1, "start": "2025-05-31 21:10:45.504904", "stderr": "E0531 21:10:45.597803   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0531 21:10:45.601429   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0531 21:10:45.604417   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0531 21:10:45.606649   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nE0531 21:10:45.609144   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?", "stderr_lines": ["E0531 21:10:45.597803   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0531 21:10:45.601429   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0531 21:10:45.604417   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0531 21:10:45.606649   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "E0531 21:10:45.609144   11606 memcache.go:265] \"Unhandled Error\" err=\"couldn't get current server API group list: Get \\\"http://localhost:8080/api?timeout=32s\\\": dial tcp 127.0.0.1:8080: connect: connection refused\"", "The connection to the server localhost:8080 was refused - did you specify the right host or port?"], "stdout": "", "stdout_lines": []}
2025-06-01 00:10:45,643 p=8635 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-06-01 00:10:45,643 p=8635 u=root n=ansible INFO| k8s-master-01              : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-06-01 00:11:19,656 p=8716 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-06-01 00:11:19,858 p=8716 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-06-01 00:11:19,869 p=8716 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-06-01 00:11:19,889 p=8716 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-06-01 00:11:19,899 p=8716 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-06-01 00:11:19,906 p=8716 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-06-01 00:11:19,913 p=8716 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-06-01 00:11:19,921 p=8716 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:11:19,928 p=8716 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:11:21,876 p=8716 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:11:21,877 p=8716 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:11:21,890 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:11:22,416 p=8716 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:11:22,429 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:11:22,443 p=8716 u=root n=ansible INFO| skipping: [k8s-master-01]
2025-06-01 00:11:22,454 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-06-01 00:11:22,951 p=8716 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:11:22,964 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-06-01 00:11:24,013 p=8716 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:11:24,026 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-06-01 00:11:25,722 p=8716 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:11:25,734 p=8716 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-06-01 00:11:32,377 p=8716 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-06-01 00:13:26,899 p=8895 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-06-01 00:13:27,089 p=8895 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-06-01 00:13:27,100 p=8895 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-06-01 00:13:27,118 p=8895 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-06-01 00:13:27,128 p=8895 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-06-01 00:13:27,135 p=8895 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-06-01 00:13:27,142 p=8895 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-06-01 00:13:27,147 p=8895 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:13:27,154 p=8895 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:13:30,710 p=8895 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:13:30,711 p=8895 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:13:30,724 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:13:31,243 p=8895 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:13:31,269 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:13:31,289 p=8895 u=root n=ansible INFO| ok: [k8s-master-01] => {
    "kubeadm_output.stdout": "v1.32.5"
}
2025-06-01 00:13:31,302 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:13:31,327 p=8895 u=root n=ansible INFO| skipping: [k8s-master-01]
2025-06-01 00:13:31,342 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-06-01 00:13:31,931 p=8895 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:13:31,945 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-06-01 00:13:32,941 p=8895 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:13:32,955 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-06-01 00:13:33,402 p=8895 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:13:33,415 p=8895 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-06-01 00:13:40,713 p=8895 u=root n=ansible INFO| ok: [k8s-master-01] => (item=kubectl=1.33.1-1.1 )
2025-06-01 00:13:46,469 p=8895 u=root n=ansible ERROR|  [ERROR]: User interrupted execution

2025-06-01 00:14:49,184 p=9070 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-06-01 00:14:49,375 p=9070 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-06-01 00:14:49,386 p=9070 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-06-01 00:14:49,404 p=9070 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-06-01 00:14:49,413 p=9070 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-06-01 00:14:49,420 p=9070 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-06-01 00:14:49,427 p=9070 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-06-01 00:14:49,431 p=9070 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:14:49,437 p=9070 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:14:53,440 p=9070 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:14:53,440 p=9070 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:14:53,453 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:14:54,088 p=9070 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:14:54,108 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:14:54,132 p=9070 u=root n=ansible INFO| ok: [k8s-master-01] => {
    "kubeadm_output.stdout": "v1.33.1"
}
2025-06-01 00:14:54,146 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:14:54,170 p=9070 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:14:54,178 p=9070 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:14:57,604 p=9070 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:14:57,604 p=9070 u=root n=ansible INFO| ok: [k8s-master-02]
2025-06-01 00:14:57,616 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:14:58,067 p=9070 u=root n=ansible INFO| changed: [k8s-master-02]
2025-06-01 00:14:58,080 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:14:58,102 p=9070 u=root n=ansible INFO| ok: [k8s-master-02] => {
    "kubeadm_output.stdout": "v1.32.5"
}
2025-06-01 00:14:58,115 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:14:58,129 p=9070 u=root n=ansible INFO| skipping: [k8s-master-02]
2025-06-01 00:14:58,145 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-06-01 00:14:58,799 p=9070 u=root n=ansible INFO| changed: [k8s-master-02]
2025-06-01 00:14:58,813 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-06-01 00:14:59,946 p=9070 u=root n=ansible INFO| ok: [k8s-master-02]
2025-06-01 00:14:59,959 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-06-01 00:15:01,653 p=9070 u=root n=ansible INFO| ok: [k8s-master-02]
2025-06-01 00:15:01,666 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-06-01 00:15:18,861 p=9070 u=root n=ansible INFO| ok: [k8s-master-02] => (item=kubectl=1.33.1-1.1 )
2025-06-01 00:15:27,220 p=9070 u=root n=ansible INFO| ok: [k8s-master-02] => (item=kubelet=1.33.1-1.1 )
2025-06-01 00:15:34,694 p=9070 u=root n=ansible INFO| ok: [k8s-master-02] => (item=kubeadm=1.33.1-1.1 )
2025-06-01 00:15:34,711 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-06-01 00:15:35,195 p=9070 u=root n=ansible INFO| ok: [k8s-master-02]
2025-06-01 00:15:35,208 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-06-01 00:15:35,224 p=9070 u=root n=ansible INFO| skipping: [k8s-master-02]
2025-06-01 00:15:35,238 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-06-01 00:22:13,774 p=9070 u=root n=ansible INFO| changed: [k8s-master-02]
2025-06-01 00:22:13,787 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : uncordon node after update] *****************************************************************************
2025-06-01 00:23:01,604 p=9070 u=root n=ansible INFO| changed: [k8s-master-02]
2025-06-01 00:23:01,621 p=9070 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:23:01,627 p=9070 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:23:34,746 p=9070 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:23:34,747 p=9070 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-06-01 00:23:34,763 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:24:19,029 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:24:19,048 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:24:19,071 p=9070 u=root n=ansible INFO| ok: [k8s-worker-01] => {
    "kubeadm_output.stdout": "v1.32.5"
}
2025-06-01 00:24:19,089 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:24:19,106 p=9070 u=root n=ansible INFO| skipping: [k8s-worker-01]
2025-06-01 00:24:19,122 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : drain node before update] *******************************************************************************
2025-06-01 00:24:39,680 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:24:39,696 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Overwrite entire file content] **************************************************************************
2025-06-01 00:24:41,833 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:24:41,852 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : unhold kubeadm properly] ********************************************************************************
2025-06-01 00:25:41,700 p=9070 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-06-01 00:25:41,715 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Update repositories cache and install "k8s" package] ****************************************************
2025-06-01 00:26:26,538 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01] => (item=kubectl=1.33.1-1.1 )
2025-06-01 00:26:46,047 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01] => (item=kubelet=1.33.1-1.1 )
2025-06-01 00:27:08,873 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01] => (item=kubeadm=1.33.1-1.1 )
2025-06-01 00:27:08,947 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Hold kubeadm properly] **********************************************************************************
2025-06-01 00:27:10,307 p=9070 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-06-01 00:27:10,346 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-06-01 00:27:10,391 p=9070 u=root n=ansible INFO| skipping: [k8s-worker-01]
2025-06-01 00:27:10,429 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : update kubeadm] *****************************************************************************************
2025-06-01 00:27:11,807 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:27:11,866 p=9070 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : uncordon node after update] *****************************************************************************
2025-06-01 00:27:15,157 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:27:15,311 p=9070 u=root n=ansible INFO| RUNNING HANDLER [upgrade_k8s_cluster : Restart service kubelet] *********************************************************************
2025-06-01 00:27:18,360 p=9070 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:27:18,371 p=9070 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-06-01 00:27:18,501 p=9070 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-06-01 00:27:18,502 p=9070 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-06-01 00:27:18,503 p=9070 u=root n=ansible INFO| k8s-master-02              : ok=10   changed=4    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-06-01 00:27:18,504 p=9070 u=root n=ansible INFO| k8s-worker-01              : ok=11   changed=7    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-06-01 00:33:54,566 p=10100 u=root n=ansible WARNING| [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details

2025-06-01 00:33:55,143 p=10100 u=root n=ansible INFO| PLAY [prepere lb for kubernetes cluster masters] ************************************************************************************
2025-06-01 00:33:55,180 p=10100 u=root n=ansible INFO| PLAY [prepere kubernetes nodes workers and masters] *********************************************************************************
2025-06-01 00:33:55,240 p=10100 u=root n=ansible INFO| PLAY [cluster initialization and cluster network] ***********************************************************************************
2025-06-01 00:33:55,272 p=10100 u=root n=ansible INFO| PLAY [join kubernetes cluster] ******************************************************************************************************
2025-06-01 00:33:55,293 p=10100 u=root n=ansible INFO| PLAY [join kubernetes  master to cluster] *******************************************************************************************
2025-06-01 00:33:55,315 p=10100 u=root n=ansible INFO| PLAY [add admin user to kubernetes masters] *****************************************************************************************
2025-06-01 00:33:55,332 p=10100 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:33:55,351 p=10100 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:34:06,268 p=10100 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:34:06,270 p=10100 u=root n=ansible INFO| ok: [k8s-master-01]
2025-06-01 00:34:06,311 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:34:08,151 p=10100 u=root n=ansible INFO| changed: [k8s-master-01]
2025-06-01 00:34:08,193 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:34:08,263 p=10100 u=root n=ansible INFO| ok: [k8s-master-01] => {
    "kubeadm_output.stdout": "v1.33.1"
}
2025-06-01 00:34:08,306 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:34:08,357 p=10100 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:34:08,379 p=10100 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:34:20,977 p=10100 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-master-02 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:34:20,978 p=10100 u=root n=ansible INFO| ok: [k8s-master-02]
2025-06-01 00:34:21,009 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:34:22,547 p=10100 u=root n=ansible INFO| changed: [k8s-master-02]
2025-06-01 00:34:22,632 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:34:22,694 p=10100 u=root n=ansible INFO| ok: [k8s-master-02] => {
    "kubeadm_output.stdout": "v1.33.1"
}
2025-06-01 00:34:22,737 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:34:22,792 p=10100 u=root n=ansible INFO| PLAY [update kubernetes cluster] ****************************************************************************************************
2025-06-01 00:34:22,811 p=10100 u=root n=ansible INFO| TASK [Gathering Facts] **************************************************************************************************************
2025-06-01 00:34:32,370 p=10100 u=root n=ansible WARNING| [WARNING]: Platform linux on host k8s-worker-01 is using the discovered Python interpreter at /usr/bin/python3.10, but future
installation of another Python interpreter could change the meaning of that path. See https://docs.ansible.com/ansible-
core/2.18/reference_appendices/interpreter_discovery.html for more information.

2025-06-01 00:34:32,371 p=10100 u=root n=ansible INFO| ok: [k8s-worker-01]
2025-06-01 00:34:32,423 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Run kubeadm version] ************************************************************************************
2025-06-01 00:34:33,784 p=10100 u=root n=ansible INFO| changed: [k8s-worker-01]
2025-06-01 00:34:33,825 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : debug kubeadm output] ***********************************************************************************
2025-06-01 00:34:33,886 p=10100 u=root n=ansible INFO| ok: [k8s-worker-01] => {
    "kubeadm_output.stdout": "v1.33.1"
}
2025-06-01 00:34:33,931 p=10100 u=root n=ansible INFO| TASK [upgrade_k8s_cluster : Fail if versions are already the same] ******************************************************************
2025-06-01 00:34:33,980 p=10100 u=root n=ansible INFO| PLAY [remove kubernetes cluster] ****************************************************************************************************
2025-06-01 00:34:34,104 p=10100 u=root n=ansible INFO| PLAY RECAP **************************************************************************************************************************
2025-06-01 00:34:34,105 p=10100 u=root n=ansible INFO| k8s-master-01              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-06-01 00:34:34,105 p=10100 u=root n=ansible INFO| k8s-master-02              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-06-01 00:34:34,106 p=10100 u=root n=ansible INFO| k8s-worker-01              : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
